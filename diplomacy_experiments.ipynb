{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a723b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-25 15:34:42,079] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 15:34:46.980238: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-25 15:34:46.980264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-25 15:34:46.981173: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-25 15:34:48.504459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig,PeftModel\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    ")\n",
    "# some experiments for the Llama model on safety\n",
    "import os\n",
    "import sys\n",
    "import socket\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass, asdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17e7f0",
   "metadata": {},
   "source": [
    "## Parse the prompts to check what the fields represents and whether running friction intervention models would even make sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043acff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    " \n",
    "test_path = f\"diplomacy_prompts/sample_1K_denis_testdata_with_prompts.json\"\n",
    "with open(test_path, \"r\") as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e898c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sender': 'ITALY',\n",
       " 'recipient': 'AUSTRIA',\n",
       " 'message': 'Also, seems like there is plenty of risk that Russia could try for Rumania. Why not use Bulg to support Rum, while having Rum and BLS Support Arm to Sev?',\n",
       " 'sender_labels': False,\n",
       " 'phase': 'F1907M',\n",
       " 'units': {'AUSTRIA': ['A BUD', 'A SER', 'A ARM', 'F BLA', 'A BUL', 'A RUM'],\n",
       "  'ENGLAND': ['F ENG', 'F NWY', 'A PIC', 'F NWG'],\n",
       "  'FRANCE': ['F BRE'],\n",
       "  'GERMANY': ['F BEL', 'A PAR', 'A HOL', 'F NTH', 'A MUN', 'A BUR', 'F HEL'],\n",
       "  'ITALY': ['A SMY',\n",
       "   'F AEG',\n",
       "   'A VIE',\n",
       "   'A MAR',\n",
       "   'F MAO',\n",
       "   'F TYS',\n",
       "   'A TYR',\n",
       "   'A GAS',\n",
       "   'F SPA',\n",
       "   'F NAO'],\n",
       "  'RUSSIA': ['A SEV', 'A BOH', 'A UKR', 'A MOS', 'A GAL'],\n",
       "  'TURKEY': []},\n",
       " 'predicted_orders': {'AUSTRIA': {'ENGLAND': ['F NWG - NWY',\n",
       "    'F ENG S A PIC - BEL',\n",
       "    'F NWY - SWE',\n",
       "    'A PIC - BEL'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH - LON',\n",
       "    'F BEL S F HEL - NTH',\n",
       "    'F HEL - NTH',\n",
       "    'A HOL S F BEL',\n",
       "    'A BUR S A PAR',\n",
       "    'A PAR S F BRE',\n",
       "    'A MUN S A BUR'],\n",
       "   'ITALY': ['F NAO - LVP',\n",
       "    'F MAO S A GAS',\n",
       "    'A GAS S A MAR - BUR',\n",
       "    'F SPA/SC S F MAO',\n",
       "    'A MAR - BUR',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A BUD - GAL',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH - VIE',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH - VIE'],\n",
       "   'TURKEY': []},\n",
       "  'ENGLAND': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH C A HOL - YOR',\n",
       "    'F BEL S F ENG',\n",
       "    'F HEL - KIE',\n",
       "    'A HOL - YOR VIA',\n",
       "    'A BUR - GAS',\n",
       "    'A PAR S A PIC - BRE',\n",
       "    'A MUN - TYR'],\n",
       "   'ITALY': ['F NAO C A GAS - LVP',\n",
       "    'F MAO C A GAS - LVP',\n",
       "    'A GAS - LVP VIA',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR H',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A TYR - BOH',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH'],\n",
       "   'TURKEY': []},\n",
       "  'FRANCE': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'ENGLAND': ['F NWG - CLY',\n",
       "    'F ENG C A PIC - WAL',\n",
       "    'F NWY - NWG',\n",
       "    'A PIC - WAL VIA'],\n",
       "   'GERMANY': ['F NTH C A HOL - EDI',\n",
       "    'F BEL - ENG',\n",
       "    'F HEL S F NTH',\n",
       "    'A HOL - EDI VIA',\n",
       "    'A BUR S A PAR',\n",
       "    'A PAR S A BUR',\n",
       "    'A MUN S A BUR'],\n",
       "   'ITALY': ['F NAO C A GAS - LVP',\n",
       "    'F MAO C A GAS - LVP',\n",
       "    'A GAS - LVP VIA',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR H',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A TYR - BOH',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH'],\n",
       "   'TURKEY': []},\n",
       "  'GERMANY': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'ENGLAND': ['F NWG - NWY',\n",
       "    'F ENG S A PIC - BEL',\n",
       "    'F NWY - SWE',\n",
       "    'A PIC - BEL'],\n",
       "   'FRANCE': ['F BRE - MAO'],\n",
       "   'ITALY': ['F NAO C A GAS - LVP',\n",
       "    'F MAO C A GAS - LVP',\n",
       "    'A GAS - LVP VIA',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR H',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A TYR - BOH',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH'],\n",
       "   'TURKEY': []},\n",
       "  'ITALY': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'ENGLAND': ['F NWG - EDI', 'F ENG - LON', 'F NWY - SWE', 'A PIC - BRE'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH C A HOL - YOR',\n",
       "    'F BEL S F NTH',\n",
       "    'F HEL S F NTH',\n",
       "    'A HOL - YOR VIA',\n",
       "    'A BUR S A PAR',\n",
       "    'A PAR S F BRE',\n",
       "    'A MUN S A BUR'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH'],\n",
       "   'TURKEY': []},\n",
       "  'RUSSIA': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER - TRI',\n",
       "    'A BUL - GRE'],\n",
       "   'ENGLAND': ['F NWG - NWY',\n",
       "    'F ENG S A PIC - BEL',\n",
       "    'F NWY - SWE',\n",
       "    'A PIC - BEL'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH C A HOL - YOR',\n",
       "    'F BEL S F NTH',\n",
       "    'F HEL S F NTH',\n",
       "    'A HOL - YOR VIA',\n",
       "    'A BUR S F BEL',\n",
       "    'A PAR S F BRE',\n",
       "    'A MUN S A BUR'],\n",
       "   'ITALY': ['F NAO - LVP',\n",
       "    'F MAO S A GAS - BRE',\n",
       "    'A GAS - BRE',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR - BUR',\n",
       "    'F TYS - WES',\n",
       "    'A TYR S A VIE',\n",
       "    'A VIE S A GAL - BUD',\n",
       "    'F AEG - CON',\n",
       "    'A SMY - ANK'],\n",
       "   'TURKEY': []},\n",
       "  'TURKEY': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'ENGLAND': ['F NWG - NWY',\n",
       "    'F ENG S A PIC - BEL',\n",
       "    'F NWY - SWE',\n",
       "    'A PIC - BEL'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH C A HOL - YOR',\n",
       "    'F BEL S F NTH',\n",
       "    'F HEL S F NTH',\n",
       "    'A HOL - YOR VIA',\n",
       "    'A BUR S F BEL',\n",
       "    'A PAR S F BRE',\n",
       "    'A MUN S A BUR'],\n",
       "   'ITALY': ['F NAO C A GAS - LVP',\n",
       "    'F MAO C A GAS - LVP',\n",
       "    'A GAS - LVP VIA',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR - GAS',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A TYR - BOH',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH']}},\n",
       " 'parsed-amr': '(a / and\\n      :op1 (p / possible-01\\n            :ARG1 (a2 / attack-01\\n                  :ARG0 (c / country :name (n / name :op1 \"Russia\"))\\n                  :ARG1 (p2 / province :name (n2 / name :op1 \"Romania\"))))\\n      :op2 (p3 / propose-01\\n            :ARG0 (c2 / country :name (n3 / name :op1 \"ITALY\"))\\n            :ARG1 (a3 / and\\n                  :op1 (s / support-01\\n                        :ARG0 (c3 / country :name (n4 / name :op1 \"AUSTRIA\"))\\n                        :ARG1 p2\\n                        :instrument (u / unit\\n                              :location (p4 / province :name (n5 / name :op1 \"Bulgaria\"))))\\n                  :op2 (s2 / support-01\\n                        :ARG0 c3\\n                        :ARG1 (m / move-01\\n                              :ARG1 (u2 / unit\\n                                    :location (p5 / province :name (n6 / name :op1 \"Armenia\")))\\n                              :ARG2 (p6 / province :name (n7 / name :op1 \"Sevastopol\")))\\n                        :instrument (a4 / and\\n                              :op1 (u3 / unit\\n                                    :location p2)\\n                              :op2 (f / fleet\\n                                    :location (s3 / sea :name (n8 / name :op1 \"Black\" :op2 \"Sea\"))))))\\n            :ARG3 c3))',\n",
       " 'extracted_moves': [{'country': 'RUSSIA',\n",
       "   'unit': '',\n",
       "   'from': '',\n",
       "   'to': 'Romania',\n",
       "   'action': '-',\n",
       "   'concept': 'attack-01',\n",
       "   'polarity': False,\n",
       "   'question': True,\n",
       "   'emotion': False},\n",
       "  {'support_country': '',\n",
       "   'support_unit': '',\n",
       "   'support_from': 'Bulgaria',\n",
       "   'support_action': 'S',\n",
       "   'country': '',\n",
       "   'unit': '',\n",
       "   'from': '',\n",
       "   'to': '',\n",
       "   'action': '',\n",
       "   'concept': 'support-01',\n",
       "   'polarity': False,\n",
       "   'question': True,\n",
       "   'emotion': False},\n",
       "  {'support_country': '',\n",
       "   'support_unit': 'fleet',\n",
       "   'support_from': 'Romania Black Sea',\n",
       "   'support_action': 'S',\n",
       "   'country': '',\n",
       "   'unit': '',\n",
       "   'from': 'Armenia',\n",
       "   'to': 'Sevastopol',\n",
       "   'action': '-',\n",
       "   'concept': 'support-01',\n",
       "   'polarity': False,\n",
       "   'question': True,\n",
       "   'emotion': False}],\n",
       " 'prev_5_message': [{'message': 'Use Tyrolia to tap Bohemia, Vienna supports Budapest to Galicia, and Rumania taps Ukraine. Unless Bohemia goes to Vienna, that guarantees a move to Galicia.',\n",
       "   'sender': 'AUSTRIA',\n",
       "   'recipient': 'ITALY',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': True,\n",
       "   'parsed-amr': '(a / and\\n      :op1 (p / propose-01\\n            :ARG0 (c / country :name (n / name :op1 \"AUSTRIA\"))\\n            :ARG1 (a2 / and\\n                  :op1 (m / move-01\\n                        :ARG1 (u / unit\\n                              :location (p2 / province :name (n2 / name :op1 \"Tyrolia\"))\\n                              :mod (c2 / country :name (n3 / name :op1 \"ITALY\")))\\n                        :ARG2 (p3 / province :name (n4 / name :op1 \"Bohemia\")))\\n                  :op2 (s / support-01\\n                        :ARG0 c2\\n                        :ARG1 (m2 / move-01\\n                              :ARG1 (u2 / unit\\n                                    :location (p4 / province :name (n5 / name :op1 \"Budapest\")))\\n                              :ARG2 (p5 / province :name (n6 / name :op1 \"Galicia\")))\\n                        :instrument (u3 / unit\\n                              :location (p6 / province :name (n7 / name :op1 \"Vienna\"))))\\n                  :op3 (m3 / move-01\\n                        :ARG1 (u4 / unit\\n                              :location (p7 / province :name (n8 / name :op1 \"Romania\")))\\n                        :ARG2 (p8 / province :name (n9 / name :op1 \"Ukraine\"))))\\n            :ARG3 c2)\\n      :op2 (e / expect-01\\n            :ARG0 c\\n            :ARG1 (m4 / move-01\\n                  :ARG1 (u5 / unit)\\n                  :ARG2 p5)\\n            :condition (m5 / move-01\\n                  :polarity \"-\"\\n                  :ARG1 (u6 / unit\\n                        :location p3)\\n                  :ARG2 p6)))',\n",
       "   'extracted_moves': [{'country': 'ITALY',\n",
       "     'unit': '',\n",
       "     'from': 'Tyrolia ',\n",
       "     'to': 'Bohemia',\n",
       "     'action': '-',\n",
       "     'concept': 'move-01',\n",
       "     'polarity': False,\n",
       "     'question': True,\n",
       "     'emotion': False},\n",
       "    {'support_country': '',\n",
       "     'support_unit': '',\n",
       "     'support_from': 'Vienna',\n",
       "     'support_action': 'S',\n",
       "     'country': '',\n",
       "     'unit': '',\n",
       "     'from': 'Budapest',\n",
       "     'to': 'Galicia',\n",
       "     'action': '-',\n",
       "     'concept': 'support-01',\n",
       "     'polarity': False,\n",
       "     'question': True,\n",
       "     'emotion': False},\n",
       "    {'country': '',\n",
       "     'unit': '',\n",
       "     'from': 'Romania',\n",
       "     'to': 'Ukraine',\n",
       "     'action': '-',\n",
       "     'concept': 'move-01',\n",
       "     'polarity': False,\n",
       "     'question': True,\n",
       "     'emotion': False}]},\n",
       "  {'message': 'Also, for my comfort, do you mind if I pick Trieste back up?',\n",
       "   'sender': 'AUSTRIA',\n",
       "   'recipient': 'ITALY',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': True,\n",
       "   'parsed-amr': '(p / propose-01\\n      :ARG0 (c / country :name (n / name :op1 \"AUSTRIA\"))\\n      :ARG1 (h / have-03\\n            :ARG0 c\\n            :ARG1 (p2 / province :name (n2 / name :op1 \"Trieste\")))\\n      :ARG3 (c2 / country :name (n3 / name :op1 \"ITALY\")))',\n",
       "   'extracted_moves': []},\n",
       "  {'message': 'I like that. I was thinking that you would move Bud back to Tri, but this is much better. It keeps forward momentum. And yes, you should take back Tri now. That will make builds easier as we move forward.',\n",
       "   'sender': 'ITALY',\n",
       "   'recipient': 'AUSTRIA',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': False,\n",
       "   'parsed-amr': '(a / agree-01\\n      :ARG0 (c / country :name (n / name :op1 \"ITALY\"))\\n      :ARG1 (h / have-03\\n            :ARG0 (c2 / country :name (n2 / name :op1 \"AUSTRIA\"))\\n            :ARG1 (p / province :name (n3 / name :op1 \"Trieste\")))\\n      :ARG2 c2)',\n",
       "   'extracted_moves': []},\n",
       "  {'message': \"Also, actually, I don't have anything for Bulgaria to do, and you're guaranteed two dots this turn. Can I take Greece back too? I can bank a build for the future regardless of what happens, and you stay even. You don't really need a build right now.\",\n",
       "   'sender': 'AUSTRIA',\n",
       "   'recipient': 'ITALY',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': True,\n",
       "   'parsed-amr': '(p / propose-01\\n      :ARG0 (c / country :name (n / name :op1 \"AUSTRIA\"))\\n      :ARG1 (h / have-03\\n            :ARG0 c\\n            :ARG1 (p2 / province :name (n2 / name :op1 \"Greece\")))\\n      :ARG2 (c2 / country :name (n3 / name :op1 \"ITALY\")))',\n",
       "   'extracted_moves': []},\n",
       "  {'message': 'Hmmm. I’m cool with you taking Trieste. I’m not sure that taking Greece now is the right move. \\n\\nIn the West, I will take Liverpool, but not Portugal. I need to use my Spanish fleet to support MAO so that I can convoy an army to Liverpool. And I’m just in no hurry to take out France. So if you take Greece, you would be taking an Italian unit off the board and not building one yourself.',\n",
       "   'sender': 'ITALY',\n",
       "   'recipient': 'AUSTRIA',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': False,\n",
       "   'parsed-amr': '(a / amr-empty)',\n",
       "   'extracted_moves': []}],\n",
       " 'proposals': {'ITALY': [], 'AUSTRIA': []},\n",
       " 'friction': False,\n",
       " 'friction_info': {},\n",
       " 'scores': 10,\n",
       " 'Prompt_level1': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are an expert assistant specializing in the Diplomacy board game. Your role is to assist a novice player by analyzing:\\n1. The current board state.\\n2. The recommended orders for the novice player.\\n\\nYour goal is to provide one **concise strategic advice** (max 2 sentences): \\n- The first sentence should directly give the advice.  \\n- The second sentence should briefly justify it, ideally referencing risk, opportunity, or alignment with the board state.\\n\\nAvoid long explanations or generic commentary—be precise and practical.\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n**Board State:**  \\nAUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n**Recommended Orders:**  \\nA ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n**Advice:**  \\nYou are advising the player controlling AUSTRIA. Give them short strategic advice with a brief reason. Speak directly to the player.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n',\n",
       " 'Prompt_level2': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are an expert assistant specializing in the Diplomacy board game. Your role is to assist a novice player by analyzing:\\n1. The current board state.\\n2. The recommended orders for the novice player.\\n3. The potential orders for every power.\\n\\nYour goal is to provide one **concise strategic advice** (max 2 sentences): \\n- The first sentence should directly give the advice.  \\n- The second sentence should briefly justify it, ideally referencing risk, opportunity, or alignment with the board state.\\n\\nAvoid long explanations or generic commentary—be precise and practical.\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n**Board State:**  \\nAUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n**Recommended Orders for AUSTRIA:**  \\nA ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n**Potential Orders for other powers:**\\nENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n**Advice:**  \\nYou are advising the player controlling AUSTRIA. Give them short strategic advice with a brief reason. Speak directly to the player.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n',\n",
       " 'Prompt_level3': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are an expert assistant specializing in the Diplomacy board game. Your role is to assist a novice player by analyzing:\\n1. The current board state.\\n2. The recommended orders for the novice player.\\n3. The potential orders for every power.\\n4. The message history between the novice player and other players.\\n\\nYour goal is to provide one **concise strategic advice** (max 2 sentences): \\n- The first sentence should directly give the advice.  \\n- The second sentence should briefly justify it, ideally referencing risk, opportunity, or alignment with the board state.\\n\\nAvoid long explanations or generic commentary—be precise and practical.\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n**Board State:**  \\nAUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n**Recommended Orders for AUSTRIA:**  \\nA ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n**Potential Orders for other powers:**\\nENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n**Message History:**\\nMessage from AUSTRIA: Use Tyrolia to tap Bohemia, Vienna supports Budapest to Galicia, and Rumania taps Ukraine. Unless Bohemia goes to Vienna, that guarantees a move to Galicia.\\nMessage from AUSTRIA: Also, for my comfort, do you mind if I pick Trieste back up?\\nMessage from ITALY: I like that. I was thinking that you would move Bud back to Tri, but this is much better. It keeps forward momentum. And yes, you should take back Tri now. That will make builds easier as we move forward.\\nMessage from AUSTRIA: Also, actually, I don't have anything for Bulgaria to do, and you're guaranteed two dots this turn. Can I take Greece back too? I can bank a build for the future regardless of what happens, and you stay even. You don't really need a build right now.\\nMessage from ITALY: Hmmm. I’m cool with you taking Trieste. I’m not sure that taking Greece now is the right move. \\n\\nIn the West, I will take Liverpool, but not Portugal. I need to use my Spanish fleet to support MAO so that I can convoy an army to Liverpool. And I’m just in no hurry to take out France. So if you take Greece, you would be taking an Italian unit off the board and not building one yourself.\\nMessage from ITALY: Also, seems like there is plenty of risk that Russia could try for Rumania. Why not use Bulg to support Rum, while having Rum and BLS Support Arm to Sev?\\n\\n**Advice:**  \\nYou are advising the player controlling AUSTRIA. Give them short strategic advice with a brief reason. Speak directly to the player.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f353f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "selected_validation_dataset = load_from_disk(\"selected_validation_dataset_friction_mixed_with_original\") # Test set for WTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd58d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['friction_statement', 'rationale', 'task_state', 'belief_state', 'context', 'dialog_id', 'friction_participant', 'type', 'P1_personality_type', 'P1_facet', 'P2_personality_type', 'P2_facet', 'P3_personality_type', 'P3_facet', 'unique_id', 'message_id', 'original_wtd_friction_data', '__index_level_0__'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9953a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ee1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_diplomacy_for_friction(test_data):\n",
    "\n",
    "    processed_messages = []  # Create a list to store all processed messages\n",
    "    count = 0\n",
    "    for message in test_data:\n",
    "        count = count+1\n",
    "        sender = message['sender']\n",
    "        recipient = message['recipient']\n",
    "\n",
    "        if message['recipient'] == 'ALL' or message['recipient'] == message['sender'] or message[\"phase\"].endswith('A') or message[\"phase\"].endswith('R'):\n",
    "            continue\n",
    "        else:\n",
    "            #board states format\n",
    "            formatted_board = \"\"\n",
    "            for country, units in message['units'].items():\n",
    "                formatted_board += f\"{country}: {', '.join(units)}\\n\"\n",
    "            formatted_board = formatted_board.strip()\n",
    "            #predicted orders for opponent\n",
    "            opponent_orders = \"\"\n",
    "            for country, units in message['predicted_orders'][message['recipient']].items():\n",
    "                opponent_orders += f\"{country}: {', '.join(units)}\\n\"\n",
    "            formatted_opponent_orders = opponent_orders.strip()\n",
    "            #message history\n",
    "            message_history = \"\"\n",
    "            start_index = max(0, len(message['prev_5_message']) - 5)\n",
    "            for msg_info in message['prev_5_message'][start_index:]:\n",
    "                sender = msg_info['sender']\n",
    "                text = msg_info['message']\n",
    "                message_history += f\"Message from {sender}: {text}\\n\"\n",
    "            message_history += f\"Message from {message['sender']}: {message['message']}\"\n",
    "            #recommended orders for myself.\n",
    "            recommended_orders = message['predicted_orders'][message['sender']][message['recipient']]\n",
    "            formatted_recommended_orders = \",\\n\".join(recommended_orders)\n",
    "\n",
    "                # Modify the prompts for friction interventions\n",
    "            Prompt_level1 = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
    "        1. The current board state.\n",
    "        2. The recommended orders for the player.\n",
    "\n",
    "        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\n",
    "\n",
    "        <belief_state>\n",
    "        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\n",
    "        </belief_state>\n",
    "\n",
    "        <rationale>\n",
    "        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\n",
    "        </rationale>\n",
    "\n",
    "        <friction>\n",
    "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\n",
    "        </friction>\n",
    "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        **Board State:**  \n",
    "        {formatted_board}\n",
    "\n",
    "        **Recommended Orders:**  \n",
    "        {formatted_recommended_orders}\n",
    "\n",
    "        **Advice Request:**  \n",
    "        You are advising the player controlling {message['recipient']}. Identify potential friction points and provide constructive intervention.\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "\n",
    "            Prompt_level2 = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
    "        1. The current board state.\n",
    "        2. The recommended orders for the player.\n",
    "        3. The potential orders for every power.\n",
    "        \n",
    "\n",
    "        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\n",
    "\n",
    "        <belief_state>\n",
    "        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\n",
    "        </belief_state>\n",
    "\n",
    "        <rationale>\n",
    "        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\n",
    "        </rationale>\n",
    "\n",
    "        <friction>\n",
    "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\n",
    "        </friction>\n",
    "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        **Board State:**  \n",
    "        {formatted_board}\n",
    "\n",
    "        **Recommended Orders for {message['recipient']}:**  \n",
    "        {formatted_recommended_orders}\n",
    "\n",
    "        **Potential Orders for other powers:**\n",
    "        {formatted_opponent_orders}\n",
    "\n",
    "        **Advice Request:**  \n",
    "        You are advising the player controlling {message['recipient']}. Identify potential friction points and provide constructive intervention.\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "\n",
    "            Prompt_level3 = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
    "        1. The current board state.\n",
    "        2. The recommended orders for the player.\n",
    "        3. The potential orders for every power.\n",
    "        4. The message history between the player and other players.\n",
    "\n",
    "        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\n",
    "\n",
    "        <belief_state>\n",
    "        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\n",
    "        </belief_state>\n",
    "\n",
    "        <rationale>\n",
    "        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\n",
    "        </rationale>\n",
    "\n",
    "        <friction>\n",
    "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\n",
    "        </friction>\n",
    "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        **Board State:**  \n",
    "        {formatted_board}\n",
    "\n",
    "        **Recommended Orders for {message['recipient']}:**  \n",
    "        {formatted_recommended_orders}\n",
    "\n",
    "        **Potential Orders for other powers:**\n",
    "        {formatted_opponent_orders}\n",
    "\n",
    "        **Message History:**\n",
    "        {message_history}\n",
    "\n",
    "        **Advice Request:**  \n",
    "        You are advising the player controlling {message['recipient']}. Identify potential friction points and provide constructive intervention.\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "            \n",
    "            processed_message = message.copy()\n",
    "         # Add the prompts to the copied message\n",
    "            processed_message['Prompt_level1'] = Prompt_level1\n",
    "            processed_message['Prompt_level2'] = Prompt_level2\n",
    "            processed_message['Prompt_level3'] = Prompt_level3\n",
    "             # Add this processed message to our list\n",
    "            processed_messages.append(processed_message)\n",
    "\n",
    "    return processed_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d074d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = process_diplomacy_for_friction(test_data[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b661ade6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the board state and recommended orders, your strategy appears focused on attacking Sevastopol while also moving into Galicia. However, this leaves you vulnerable to a critical threat: Russia plans to attack Vienna (A BOH - VIE with support from A GAL). \\n\\nWhile Italy currently controls Vienna and their orders show support for your A BUD - GAL move, this leaves Vienna exposed. Losing Vienna, a home center, would be devastating to your position and ability to build new units.\\n\\nYour eastern offensive against Russia in Sevastopol diverts resources from this more urgent defensive need. Consider redirecting forces to secure Vienna - perhaps keeping A BUD in position or moving A SER to Trieste to provide support. Remember that in Diplomacy, protecting home centers takes priority over gaining new territories when your core position is under threat.\\n\\nThe recommended shift is to \"Modify your orders to focus on securing Vienna instead of attacking Sevastopol\" because Russia\\'s coordinated attack with support from Galicia represents an immediate threat to your power base, while Sevastopol can be targeted later from a position of greater security.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diplomacy_detailed_explanation = \"\"\"\n",
    "Based on the board state and recommended orders, your strategy appears focused on attacking Sevastopol while also moving into Galicia. However, this leaves you vulnerable to a critical threat: Russia plans to attack Vienna (A BOH - VIE with support from A GAL). \n",
    "\n",
    "While Italy currently controls Vienna and their orders show support for your A BUD - GAL move, this leaves Vienna exposed. Losing Vienna, a home center, would be devastating to your position and ability to build new units.\n",
    "\n",
    "Your eastern offensive against Russia in Sevastopol diverts resources from this more urgent defensive need. Consider redirecting forces to secure Vienna - perhaps keeping A BUD in position or moving A SER to Trieste to provide support. Remember that in Diplomacy, protecting home centers takes priority over gaining new territories when your core position is under threat.\n",
    "\n",
    "The recommended shift is to \"Modify your orders to focus on securing Vienna instead of attacking Sevastopol\" because Russia's coordinated attack with support from Galicia represents an immediate threat to your power base, while Sevastopol can be targeted later from a position of greater security.\n",
    "\"\"\"\n",
    "diplomacy_detailed_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f6e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c9fe74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sender': 'ITALY',\n",
       " 'recipient': 'AUSTRIA',\n",
       " 'message': 'Also, seems like there is plenty of risk that Russia could try for Rumania. Why not use Bulg to support Rum, while having Rum and BLS Support Arm to Sev?',\n",
       " 'sender_labels': False,\n",
       " 'phase': 'F1907M',\n",
       " 'units': {'AUSTRIA': ['A BUD', 'A SER', 'A ARM', 'F BLA', 'A BUL', 'A RUM'],\n",
       "  'ENGLAND': ['F ENG', 'F NWY', 'A PIC', 'F NWG'],\n",
       "  'FRANCE': ['F BRE'],\n",
       "  'GERMANY': ['F BEL', 'A PAR', 'A HOL', 'F NTH', 'A MUN', 'A BUR', 'F HEL'],\n",
       "  'ITALY': ['A SMY',\n",
       "   'F AEG',\n",
       "   'A VIE',\n",
       "   'A MAR',\n",
       "   'F MAO',\n",
       "   'F TYS',\n",
       "   'A TYR',\n",
       "   'A GAS',\n",
       "   'F SPA',\n",
       "   'F NAO'],\n",
       "  'RUSSIA': ['A SEV', 'A BOH', 'A UKR', 'A MOS', 'A GAL'],\n",
       "  'TURKEY': []},\n",
       " 'predicted_orders': {'AUSTRIA': {'ENGLAND': ['F NWG - NWY',\n",
       "    'F ENG S A PIC - BEL',\n",
       "    'F NWY - SWE',\n",
       "    'A PIC - BEL'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH - LON',\n",
       "    'F BEL S F HEL - NTH',\n",
       "    'F HEL - NTH',\n",
       "    'A HOL S F BEL',\n",
       "    'A BUR S A PAR',\n",
       "    'A PAR S F BRE',\n",
       "    'A MUN S A BUR'],\n",
       "   'ITALY': ['F NAO - LVP',\n",
       "    'F MAO S A GAS',\n",
       "    'A GAS S A MAR - BUR',\n",
       "    'F SPA/SC S F MAO',\n",
       "    'A MAR - BUR',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A BUD - GAL',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH - VIE',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH - VIE'],\n",
       "   'TURKEY': []},\n",
       "  'ENGLAND': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH C A HOL - YOR',\n",
       "    'F BEL S F ENG',\n",
       "    'F HEL - KIE',\n",
       "    'A HOL - YOR VIA',\n",
       "    'A BUR - GAS',\n",
       "    'A PAR S A PIC - BRE',\n",
       "    'A MUN - TYR'],\n",
       "   'ITALY': ['F NAO C A GAS - LVP',\n",
       "    'F MAO C A GAS - LVP',\n",
       "    'A GAS - LVP VIA',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR H',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A TYR - BOH',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH'],\n",
       "   'TURKEY': []},\n",
       "  'FRANCE': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'ENGLAND': ['F NWG - CLY',\n",
       "    'F ENG C A PIC - WAL',\n",
       "    'F NWY - NWG',\n",
       "    'A PIC - WAL VIA'],\n",
       "   'GERMANY': ['F NTH C A HOL - EDI',\n",
       "    'F BEL - ENG',\n",
       "    'F HEL S F NTH',\n",
       "    'A HOL - EDI VIA',\n",
       "    'A BUR S A PAR',\n",
       "    'A PAR S A BUR',\n",
       "    'A MUN S A BUR'],\n",
       "   'ITALY': ['F NAO C A GAS - LVP',\n",
       "    'F MAO C A GAS - LVP',\n",
       "    'A GAS - LVP VIA',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR H',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A TYR - BOH',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH'],\n",
       "   'TURKEY': []},\n",
       "  'GERMANY': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'ENGLAND': ['F NWG - NWY',\n",
       "    'F ENG S A PIC - BEL',\n",
       "    'F NWY - SWE',\n",
       "    'A PIC - BEL'],\n",
       "   'FRANCE': ['F BRE - MAO'],\n",
       "   'ITALY': ['F NAO C A GAS - LVP',\n",
       "    'F MAO C A GAS - LVP',\n",
       "    'A GAS - LVP VIA',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR H',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A TYR - BOH',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH'],\n",
       "   'TURKEY': []},\n",
       "  'ITALY': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'ENGLAND': ['F NWG - EDI', 'F ENG - LON', 'F NWY - SWE', 'A PIC - BRE'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH C A HOL - YOR',\n",
       "    'F BEL S F NTH',\n",
       "    'F HEL S F NTH',\n",
       "    'A HOL - YOR VIA',\n",
       "    'A BUR S A PAR',\n",
       "    'A PAR S F BRE',\n",
       "    'A MUN S A BUR'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH'],\n",
       "   'TURKEY': []},\n",
       "  'RUSSIA': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER - TRI',\n",
       "    'A BUL - GRE'],\n",
       "   'ENGLAND': ['F NWG - NWY',\n",
       "    'F ENG S A PIC - BEL',\n",
       "    'F NWY - SWE',\n",
       "    'A PIC - BEL'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH C A HOL - YOR',\n",
       "    'F BEL S F NTH',\n",
       "    'F HEL S F NTH',\n",
       "    'A HOL - YOR VIA',\n",
       "    'A BUR S F BEL',\n",
       "    'A PAR S F BRE',\n",
       "    'A MUN S A BUR'],\n",
       "   'ITALY': ['F NAO - LVP',\n",
       "    'F MAO S A GAS - BRE',\n",
       "    'A GAS - BRE',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR - BUR',\n",
       "    'F TYS - WES',\n",
       "    'A TYR S A VIE',\n",
       "    'A VIE S A GAL - BUD',\n",
       "    'F AEG - CON',\n",
       "    'A SMY - ANK'],\n",
       "   'TURKEY': []},\n",
       "  'TURKEY': {'AUSTRIA': ['A ARM S A RUM - SEV',\n",
       "    'F BLA S A RUM - SEV',\n",
       "    'A RUM - SEV',\n",
       "    'A BUD - GAL',\n",
       "    'A SER S A BUL - RUM',\n",
       "    'A BUL - RUM'],\n",
       "   'ENGLAND': ['F NWG - NWY',\n",
       "    'F ENG S A PIC - BEL',\n",
       "    'F NWY - SWE',\n",
       "    'A PIC - BEL'],\n",
       "   'FRANCE': ['F BRE H'],\n",
       "   'GERMANY': ['F NTH C A HOL - YOR',\n",
       "    'F BEL S F NTH',\n",
       "    'F HEL S F NTH',\n",
       "    'A HOL - YOR VIA',\n",
       "    'A BUR S F BEL',\n",
       "    'A PAR S F BRE',\n",
       "    'A MUN S A BUR'],\n",
       "   'ITALY': ['F NAO C A GAS - LVP',\n",
       "    'F MAO C A GAS - LVP',\n",
       "    'A GAS - LVP VIA',\n",
       "    'F SPA/SC - POR',\n",
       "    'A MAR - GAS',\n",
       "    'F TYS - WES',\n",
       "    'A TYR - BOH',\n",
       "    'A VIE S A TYR - BOH',\n",
       "    'F AEG S A SMY',\n",
       "    'A SMY H'],\n",
       "   'RUSSIA': ['A MOS S A SEV',\n",
       "    'A BOH S A GAL',\n",
       "    'A SEV S A UKR',\n",
       "    'A UKR S A SEV',\n",
       "    'A GAL S A BOH']}},\n",
       " 'parsed-amr': '(a / and\\n      :op1 (p / possible-01\\n            :ARG1 (a2 / attack-01\\n                  :ARG0 (c / country :name (n / name :op1 \"Russia\"))\\n                  :ARG1 (p2 / province :name (n2 / name :op1 \"Romania\"))))\\n      :op2 (p3 / propose-01\\n            :ARG0 (c2 / country :name (n3 / name :op1 \"ITALY\"))\\n            :ARG1 (a3 / and\\n                  :op1 (s / support-01\\n                        :ARG0 (c3 / country :name (n4 / name :op1 \"AUSTRIA\"))\\n                        :ARG1 p2\\n                        :instrument (u / unit\\n                              :location (p4 / province :name (n5 / name :op1 \"Bulgaria\"))))\\n                  :op2 (s2 / support-01\\n                        :ARG0 c3\\n                        :ARG1 (m / move-01\\n                              :ARG1 (u2 / unit\\n                                    :location (p5 / province :name (n6 / name :op1 \"Armenia\")))\\n                              :ARG2 (p6 / province :name (n7 / name :op1 \"Sevastopol\")))\\n                        :instrument (a4 / and\\n                              :op1 (u3 / unit\\n                                    :location p2)\\n                              :op2 (f / fleet\\n                                    :location (s3 / sea :name (n8 / name :op1 \"Black\" :op2 \"Sea\"))))))\\n            :ARG3 c3))',\n",
       " 'extracted_moves': [{'country': 'RUSSIA',\n",
       "   'unit': '',\n",
       "   'from': '',\n",
       "   'to': 'Romania',\n",
       "   'action': '-',\n",
       "   'concept': 'attack-01',\n",
       "   'polarity': False,\n",
       "   'question': True,\n",
       "   'emotion': False},\n",
       "  {'support_country': '',\n",
       "   'support_unit': '',\n",
       "   'support_from': 'Bulgaria',\n",
       "   'support_action': 'S',\n",
       "   'country': '',\n",
       "   'unit': '',\n",
       "   'from': '',\n",
       "   'to': '',\n",
       "   'action': '',\n",
       "   'concept': 'support-01',\n",
       "   'polarity': False,\n",
       "   'question': True,\n",
       "   'emotion': False},\n",
       "  {'support_country': '',\n",
       "   'support_unit': 'fleet',\n",
       "   'support_from': 'Romania Black Sea',\n",
       "   'support_action': 'S',\n",
       "   'country': '',\n",
       "   'unit': '',\n",
       "   'from': 'Armenia',\n",
       "   'to': 'Sevastopol',\n",
       "   'action': '-',\n",
       "   'concept': 'support-01',\n",
       "   'polarity': False,\n",
       "   'question': True,\n",
       "   'emotion': False}],\n",
       " 'prev_5_message': [{'message': 'Use Tyrolia to tap Bohemia, Vienna supports Budapest to Galicia, and Rumania taps Ukraine. Unless Bohemia goes to Vienna, that guarantees a move to Galicia.',\n",
       "   'sender': 'AUSTRIA',\n",
       "   'recipient': 'ITALY',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': True,\n",
       "   'parsed-amr': '(a / and\\n      :op1 (p / propose-01\\n            :ARG0 (c / country :name (n / name :op1 \"AUSTRIA\"))\\n            :ARG1 (a2 / and\\n                  :op1 (m / move-01\\n                        :ARG1 (u / unit\\n                              :location (p2 / province :name (n2 / name :op1 \"Tyrolia\"))\\n                              :mod (c2 / country :name (n3 / name :op1 \"ITALY\")))\\n                        :ARG2 (p3 / province :name (n4 / name :op1 \"Bohemia\")))\\n                  :op2 (s / support-01\\n                        :ARG0 c2\\n                        :ARG1 (m2 / move-01\\n                              :ARG1 (u2 / unit\\n                                    :location (p4 / province :name (n5 / name :op1 \"Budapest\")))\\n                              :ARG2 (p5 / province :name (n6 / name :op1 \"Galicia\")))\\n                        :instrument (u3 / unit\\n                              :location (p6 / province :name (n7 / name :op1 \"Vienna\"))))\\n                  :op3 (m3 / move-01\\n                        :ARG1 (u4 / unit\\n                              :location (p7 / province :name (n8 / name :op1 \"Romania\")))\\n                        :ARG2 (p8 / province :name (n9 / name :op1 \"Ukraine\"))))\\n            :ARG3 c2)\\n      :op2 (e / expect-01\\n            :ARG0 c\\n            :ARG1 (m4 / move-01\\n                  :ARG1 (u5 / unit)\\n                  :ARG2 p5)\\n            :condition (m5 / move-01\\n                  :polarity \"-\"\\n                  :ARG1 (u6 / unit\\n                        :location p3)\\n                  :ARG2 p6)))',\n",
       "   'extracted_moves': [{'country': 'ITALY',\n",
       "     'unit': '',\n",
       "     'from': 'Tyrolia ',\n",
       "     'to': 'Bohemia',\n",
       "     'action': '-',\n",
       "     'concept': 'move-01',\n",
       "     'polarity': False,\n",
       "     'question': True,\n",
       "     'emotion': False},\n",
       "    {'support_country': '',\n",
       "     'support_unit': '',\n",
       "     'support_from': 'Vienna',\n",
       "     'support_action': 'S',\n",
       "     'country': '',\n",
       "     'unit': '',\n",
       "     'from': 'Budapest',\n",
       "     'to': 'Galicia',\n",
       "     'action': '-',\n",
       "     'concept': 'support-01',\n",
       "     'polarity': False,\n",
       "     'question': True,\n",
       "     'emotion': False},\n",
       "    {'country': '',\n",
       "     'unit': '',\n",
       "     'from': 'Romania',\n",
       "     'to': 'Ukraine',\n",
       "     'action': '-',\n",
       "     'concept': 'move-01',\n",
       "     'polarity': False,\n",
       "     'question': True,\n",
       "     'emotion': False}]},\n",
       "  {'message': 'Also, for my comfort, do you mind if I pick Trieste back up?',\n",
       "   'sender': 'AUSTRIA',\n",
       "   'recipient': 'ITALY',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': True,\n",
       "   'parsed-amr': '(p / propose-01\\n      :ARG0 (c / country :name (n / name :op1 \"AUSTRIA\"))\\n      :ARG1 (h / have-03\\n            :ARG0 c\\n            :ARG1 (p2 / province :name (n2 / name :op1 \"Trieste\")))\\n      :ARG3 (c2 / country :name (n3 / name :op1 \"ITALY\")))',\n",
       "   'extracted_moves': []},\n",
       "  {'message': 'I like that. I was thinking that you would move Bud back to Tri, but this is much better. It keeps forward momentum. And yes, you should take back Tri now. That will make builds easier as we move forward.',\n",
       "   'sender': 'ITALY',\n",
       "   'recipient': 'AUSTRIA',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': False,\n",
       "   'parsed-amr': '(a / agree-01\\n      :ARG0 (c / country :name (n / name :op1 \"ITALY\"))\\n      :ARG1 (h / have-03\\n            :ARG0 (c2 / country :name (n2 / name :op1 \"AUSTRIA\"))\\n            :ARG1 (p / province :name (n3 / name :op1 \"Trieste\")))\\n      :ARG2 c2)',\n",
       "   'extracted_moves': []},\n",
       "  {'message': \"Also, actually, I don't have anything for Bulgaria to do, and you're guaranteed two dots this turn. Can I take Greece back too? I can bank a build for the future regardless of what happens, and you stay even. You don't really need a build right now.\",\n",
       "   'sender': 'AUSTRIA',\n",
       "   'recipient': 'ITALY',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': True,\n",
       "   'parsed-amr': '(p / propose-01\\n      :ARG0 (c / country :name (n / name :op1 \"AUSTRIA\"))\\n      :ARG1 (h / have-03\\n            :ARG0 c\\n            :ARG1 (p2 / province :name (n2 / name :op1 \"Greece\")))\\n      :ARG2 (c2 / country :name (n3 / name :op1 \"ITALY\")))',\n",
       "   'extracted_moves': []},\n",
       "  {'message': 'Hmmm. I’m cool with you taking Trieste. I’m not sure that taking Greece now is the right move. \\n\\nIn the West, I will take Liverpool, but not Portugal. I need to use my Spanish fleet to support MAO so that I can convoy an army to Liverpool. And I’m just in no hurry to take out France. So if you take Greece, you would be taking an Italian unit off the board and not building one yourself.',\n",
       "   'sender': 'ITALY',\n",
       "   'recipient': 'AUSTRIA',\n",
       "   'phase': 'F1907M',\n",
       "   'sender_labels': False,\n",
       "   'parsed-amr': '(a / amr-empty)',\n",
       "   'extracted_moves': []}],\n",
       " 'proposals': {'ITALY': [], 'AUSTRIA': []},\n",
       " 'friction': False,\n",
       " 'friction_info': {},\n",
       " 'scores': 10,\n",
       " 'Prompt_level1': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       " 'Prompt_level2': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        \\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders for AUSTRIA:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Potential Orders for other powers:**\\n        ENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       " 'Prompt_level3': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        4. The message history between the player and other players.\\n\\n        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders for AUSTRIA:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Potential Orders for other powers:**\\n        ENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n        **Message History:**\\n        Message from AUSTRIA: Use Tyrolia to tap Bohemia, Vienna supports Budapest to Galicia, and Rumania taps Ukraine. Unless Bohemia goes to Vienna, that guarantees a move to Galicia.\\nMessage from AUSTRIA: Also, for my comfort, do you mind if I pick Trieste back up?\\nMessage from ITALY: I like that. I was thinking that you would move Bud back to Tri, but this is much better. It keeps forward momentum. And yes, you should take back Tri now. That will make builds easier as we move forward.\\nMessage from AUSTRIA: Also, actually, I don't have anything for Bulgaria to do, and you're guaranteed two dots this turn. Can I take Greece back too? I can bank a build for the future regardless of what happens, and you stay even. You don't really need a build right now.\\nMessage from ITALY: Hmmm. I’m cool with you taking Trieste. I’m not sure that taking Greece now is the right move. \\n\\nIn the West, I will take Liverpool, but not Portugal. I need to use my Spanish fleet to support MAO so that I can convoy an army to Liverpool. And I’m just in no hurry to take out France. So if you take Greece, you would be taking an Italian unit off the board and not building one yourself.\\nMessage from ITALY: Also, seems like there is plenty of risk that Russia could try for Rumania. Why not use Bulg to support Rum, while having Rum and BLS Support Arm to Sev?\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69397003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        \\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders for ENGLAND:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A VIE - GAL, F TRI - ALB, A BUD - SER\\nFRANCE: F BRE - MAO, A PAR - BUR, A MAR S A PAR - BUR\\nGERMANY: F KIE - DEN, A MUN - RUH, A BER - KIE\\nITALY: F NAP - ION, A ROM - APU, A VEN H\\nRUSSIA: F STP/SC - BOT, A MOS - UKR, A WAR - GAL, F SEV - BLA\\nTURKEY: F ANK - BLA, A SMY - CON, A CON - BUL\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts['Prompt_level2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b19c6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        4. The message history between the player and other players.\\n\\n        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders for ENGLAND:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A VIE - GAL, F TRI - ALB, A BUD - SER\\nFRANCE: F BRE - MAO, A PAR - BUR, A MAR S A PAR - BUR\\nGERMANY: F KIE - DEN, A MUN - RUH, A BER - KIE\\nITALY: F NAP - ION, A ROM - APU, A VEN H\\nRUSSIA: F STP/SC - BOT, A MOS - UKR, A WAR - GAL, F SEV - BLA\\nTURKEY: F ANK - BLA, A SMY - CON, A CON - BUL\\n\\n        **Message History:**\\n        Message from ENGLAND: Hi there! I always feel like it’s important for russia and england to have a good relationship. I have played too many games where they get in an unnecessary fight that never really helps either one in the long run.\\nMessage from RUSSIA: Do you want to go after Germany? How agressive do you want to be?  Any suggestions?  I'm open to an early attack on Germany.\\nMessage from ENGLAND: I’m always cautious about going in with Russia on Germany, it’s not an ideal opening for them which makes me cautious. Are your relations with Austria and turkey good enough that you can do that?\\nMessage from RUSSIA: Not sure!  i actually haven't heard anything from Turkey yet.\\nMessage from ENGLAND: So your plan is to move on germany? Or was that just a proposal? And neither have I\\nMessage from RUSSIA: No, I said I'm open to moving against Germany.  You said that you didn't want to fight each other in the North and that we should have a good relationship.  If you were going to move against Germany early, I was letting you know that I would join with you.\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts['Prompt_level3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66580d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list_deli_weights =[\n",
    "        \n",
    "    #     'FAAF_friction_run_with_69ksamples_good_vs_rogue_weights/checkpoint-500',\n",
    "    # 'FAAF_friction_run_with_69ksamples_good_vs_rogue_weights/checkpoint-2000',\n",
    "    # 'WTD_faaf_0.01', 'WTD_faaf_1', 'WTD_faaf_5', \n",
    "    \n",
    "    # 'WTD_faaf_10',\n",
    "#     'sft_deli_multiturn_rogue_cleaned/checkpoint-1000',\n",
    "#     'sft_deli_multiturn_rogue_cleaned/checkpoint-2000',\n",
    "        'sft_deli_multiturn_rogue_cleaned/checkpoint-3000',\n",
    "    'DELI_all_weights/DELI_faaf_weights/checkpoint-2000',\n",
    "#     # 'DELI_all_weights/DELI_faaf_unconditioned_weights/checkpoint-2000',\n",
    "#     # 'DELI_all_weights/DELI_faaf_first_part_weights/checkpoint-2000',\n",
    "\n",
    "#     # 'dpo_friction_run_with_69ksamples/checkpoint-500',\n",
    "#     # 'dpo_friction_run_with_69ksamples/checkpoint-2000',\n",
    "#     'DELI_all_weights/DELI_dpo_weights/checkpoint-2000',\n",
    "#      'DELI_all_weights/DELI_dpo_weights/checkpoint-3500',\n",
    "#     # 'dpo_friction_run_with_69ksamples/checkpoint-3000',\n",
    "#     # 'WTD_IPO_weights/checkpoint-2000',\n",
    "#     'DELI_all_weights/DELI_ipo_weights/checkpoint-4500',\n",
    "#         \"DELI_all_weights/DELI_sft_weights/checkpoint-4000\",\n",
    "#         \"DELI_all_weights/DELI_sft_weights/checkpoint-small-1500\",\n",
    "#          \"DELI_all_weights/DELI_ppo_weights/ppo_checkpoint_epoch_1_batch_800\",\n",
    " \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94538be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WTD_faaf_10',\n",
       " 'sft_deli_multiturn_rogue_cleaned/checkpoint-3000',\n",
       " 'DELI_all_weights/DELI_faaf_weights/checkpoint-2000',\n",
       " 'DELI_all_weights/DELI_dpo_weights/checkpoint-3500',\n",
       " 'DELI_all_weights/DELI_ipo_weights/checkpoint-4500',\n",
       " 'DELI_all_weights/DELI_sft_weights/checkpoint-small-1500',\n",
       " 'DELI_all_weights/DELI_ppo_weights/ppo_checkpoint_epoch_1_batch_800']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_list_deli_weights =[\n",
    "        \n",
    "\n",
    "    'WTD_faaf_10',\n",
    " \n",
    "        'sft_deli_multiturn_rogue_cleaned/checkpoint-3000',\n",
    "    'DELI_all_weights/DELI_faaf_weights/checkpoint-2000',\n",
    " \n",
    "     'DELI_all_weights/DELI_dpo_weights/checkpoint-3500',\n",
    " \n",
    "    'DELI_all_weights/DELI_ipo_weights/checkpoint-4500',\n",
    "\n",
    "        \"DELI_all_weights/DELI_sft_weights/checkpoint-small-1500\",\n",
    "         \"DELI_all_weights/DELI_ppo_weights/ppo_checkpoint_epoch_1_batch_800\",\n",
    " \n",
    "    ]\n",
    "models_list_deli_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e84afa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 356,\n",
    "    \"temperature\": 0.9,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.9,\n",
    "    \"num_beams\": 5,\n",
    "    \"min_length\": 100,\n",
    "    'num_return_sequences': 1,\n",
    "    \"sampling_strategy\": \"top_p_sampling\"\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "000a3f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Models:   0%|                                                                                                                                                                                                 | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: WTD_faaf_10 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351b8d24a8a040d697aff379fc911c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "Processing samples for WTD_faaf_10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 295863.77it/s]\u001b[A\n",
      "Processing Models:  14%|██████████████████████████▍                                                                                                                                                              | 1/7 [00:06<00:38,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: sft_deli_multiturn_rogue_cleaned_checkpoint-3000 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6cdca540fe4933a2827e9ac2365ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "Processing samples for sft_deli_multiturn_rogue_cleaned_checkpoint-3000: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 166207.85it/s]\u001b[A\n",
      "Processing Models:  29%|████████████████████████████████████████████████████▊                                                                                                                                    | 2/7 [00:12<00:31,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_faaf_weights_checkpoint-2000 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21e6a3a29e14959b51c9c116c0d834f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "Processing samples for DELI_faaf_weights_checkpoint-2000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 273192.21it/s]\u001b[A\n",
      "Processing Models:  43%|███████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 3/7 [00:18<00:24,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_dpo_weights_checkpoint-3500 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e26217cc93447869e249cfc30abfb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "Processing samples for DELI_dpo_weights_checkpoint-3500: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 284076.37it/s]\u001b[A\n",
      "Processing Models:  57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 4/7 [00:25<00:18,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_ipo_weights_checkpoint-4500 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9459678f3c94580be8380274537be83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "Processing samples for DELI_ipo_weights_checkpoint-4500: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 278528.00it/s]\u001b[A\n",
      "Processing Models:  71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 5/7 [00:31<00:12,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_sft_weights_checkpoint-small-1500 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01b54895e0d4286988d7132109c51e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "Processing samples for DELI_sft_weights_checkpoint-small-1500: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 289850.28it/s]\u001b[A\n",
      "Processing Models:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 6/7 [00:37<00:06,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_ppo_weights_ppo_checkpoint_epoch_1_batch_800 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dc8afb75a0451198e01784b04b72cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "Processing samples for DELI_ppo_weights_ppo_checkpoint_epoch_1_batch_800: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 281830.70it/s]\u001b[A\n",
      "Processing Models: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:43<00:00,  6.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    " \n",
    "\n",
    "def process_diplomacy_prompts_with_models(test_data, models_list, generation_args, output_dir = None):\n",
    "    \"\"\"\n",
    "    Process Diplomacy data with multiple models and different prompt levels.\n",
    "    \n",
    "    Args:\n",
    "        test_data: List of dictionaries containing the message data with prompts\n",
    "        models_list: List of model paths to process\n",
    "        generation_args: Arguments for text generation\n",
    "    \"\"\"\n",
    "    \n",
    "    results_by_model = {}\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for agent_model_name in tqdm(models_list, desc=\"Processing Models\"):\n",
    "        # Format model name for results\n",
    "        loading_model_name = agent_model_name\n",
    "        if \"/\" in agent_model_name:\n",
    "            parts = agent_model_name.split(\"/\")\n",
    "            if len(parts) >= 3:\n",
    "                # Combine the first two parts\n",
    "                agent_model_name = parts[1] + \"_\" + parts[2]\n",
    "            elif len(parts) == 2:\n",
    "                agent_model_name = parts[0] + \"_\" + parts[1]\n",
    "        \n",
    "        print(f\"\\n===== Processing Model: {agent_model_name} =====\\n\")\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        try:\n",
    "            # Load base model\n",
    "            lora_model = AutoModelForCausalLM.from_pretrained(\n",
    "                \"llama3_8b_instruct\",\n",
    "                device_map=\"auto\",\n",
    "                low_cpu_mem_usage=True,\n",
    "                torch_dtype=torch.float16,\n",
    "                trust_remote_code=True,\n",
    "            )\n",
    "            \n",
    "            # Apply LoRA adapter\n",
    "            lora_model = PeftModel.from_pretrained(\n",
    "                lora_model,\n",
    "                loading_model_name,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\",\n",
    "                low_cpu_mem_usage=True,\n",
    "                trust_remote_code=True,\n",
    "            )\n",
    "            \n",
    "            # Merge the model\n",
    "            print(\"Merging LoRA adapter...\")\n",
    "            merged_model = lora_model.merge_and_unload()\n",
    "            \n",
    "            # Load tokenizer\n",
    "            tokenizer = AutoTokenizer.from_pretrained(loading_model_name)\n",
    "            tokenizer.pad_token = \"<|reserved_special_token_0|>\"\n",
    "            tokenizer.padding_side = \"right\"\n",
    "            \n",
    "            # Initialize results for this model\n",
    "            model_results = {\n",
    "                \"model_name\": agent_model_name,\n",
    "                \"samples\": []\n",
    "            }\n",
    "            \n",
    "            # Process each message/sample\n",
    "            for message_idx, message in enumerate(tqdm(test_data, desc=f\"Processing samples for {agent_model_name}\")):\n",
    "                # Skip if we don't have the prompts\n",
    "                if not all(key in message for key in ['Prompt_level1', 'Prompt_level2', 'Prompt_level3']):\n",
    "                    continue\n",
    "                \n",
    "                sample_results = {\n",
    "                    \"message_id\": message_idx,\n",
    "                    \"sender\": message.get('sender', ''),\n",
    "                    \"recipient\": message.get('recipient', ''),\n",
    "                    \"prompt_results\": []\n",
    "                }\n",
    "                \n",
    "                # Process each prompt level\n",
    "                for level_name in ['Prompt_level1', 'Prompt_level2', 'Prompt_level3']:\n",
    "                    print(f\"Processing {level_name} for message {message_idx}\")\n",
    "                    \n",
    "                    # Generate responses\n",
    "                    generated_texts, all_generated_texts = generate_multiple_sequences_with_intrinsic_metrics(\n",
    "                        merged_model, \n",
    "                        tokenizer, \n",
    "                        message[level_name], \n",
    "                        generation_args, \n",
    "                        None,\n",
    "                        strategy=\"top_p_sampling\", \n",
    "                        batched=True, \n",
    "                    )\n",
    "                    \n",
    "                    # Process the generated text\n",
    "                    if generated_texts and isinstance(generated_texts, list):\n",
    "                        text_to_parse = generated_texts[0][0] if (generated_texts[0] and isinstance(generated_texts[0], list)) else generated_texts[0]\n",
    "                        \n",
    "                        # Parse components\n",
    "                        tags_for_parsing = [\"friction\", \"rationale\", \"belief_state\"]\n",
    "                        parsed_components = parse_tags_robust(text_to_parse, tags_for_parsing)\n",
    "                        \n",
    "                        # Extract components\n",
    "                        friction_intervention = ' '.join(parsed_components.get('friction', []))\n",
    "                        if not friction_intervention:\n",
    "                            friction_intervention = handle_friction_logic(text_to_parse)\n",
    "                        \n",
    "                        belief_state = ' '.join(parsed_components.get('belief_state', []))\n",
    "                        rationale = ' '.join(parsed_components.get('rationale', []))\n",
    "                        \n",
    "                        # Save results for this prompt level\n",
    "                        prompt_result = {\n",
    "                            \"prompt_level\": level_name,\n",
    "                            \"raw_prompt\": message[level_name],\n",
    "                            \"generated_text\": text_to_parse,\n",
    "                            \"parsed_components\": {\n",
    "                                \"friction\": friction_intervention,\n",
    "                                \"rationale\": rationale,\n",
    "                                \"belief_state\": belief_state\n",
    "                            }\n",
    "                        }\n",
    "                        \n",
    "                        sample_results[\"prompt_results\"].append(prompt_result)\n",
    "                \n",
    "                # Add this sample's results to the model results\n",
    "                model_results[\"samples\"].append(sample_results)\n",
    "            \n",
    "            # Save results for this model to a pickle file\n",
    "            safe_model_name = agent_model_name.replace('/', '_')\n",
    "            \n",
    "            with open(f\"{output_dir}/results_{safe_model_name}.pkl\", 'wb') as f:\n",
    "                pickle.dump(model_results, f)\n",
    "            \n",
    "            # Also store in our overall results dictionary\n",
    "            results_by_model[agent_model_name] = model_results\n",
    "            \n",
    "            # Clean up the model to free memory\n",
    "            del merged_model, tokenizer, lora_model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing model {agent_model_name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return results_by_model\n",
    "\n",
    "output_dir = \"diplomacy_prompts/init_generations\"\n",
    "results = process_diplomacy_prompts_with_models(test_prompts, models_list_deli_weights, generation_args, output_dir= output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8252dc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Models:   0%|                                                                                                                                                                                                 | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: WTD_faaf_10 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833c99cc14fa4859bff8d2b94ef5f2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Prompt_level1 for sample 0\n",
      "Processing Prompt_level2 for sample 0\n",
      "Processing Prompt_level3 for sample 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Models:  14%|██████████████████████████▍                                                                                                                                                              | 1/7 [00:20<02:04, 20.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: sft_deli_multiturn_rogue_cleaned_checkpoint-3000 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4438cc2dae954c6f86a2739aedf44616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Prompt_level1 for sample 0\n",
      "Processing Prompt_level2 for sample 0\n",
      "Processing Prompt_level3 for sample 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Models:  29%|████████████████████████████████████████████████████▊                                                                                                                                    | 2/7 [00:40<01:39, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_faaf_weights_checkpoint-2000 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0b7cbaa8a44fe9baf47d50db8c7330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Prompt_level1 for sample 0\n",
      "Processing Prompt_level2 for sample 0\n",
      "Processing Prompt_level3 for sample 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Models:  43%|███████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 3/7 [01:13<01:43, 25.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_dpo_weights_checkpoint-3500 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d5fd27724c41a3a6a06ec8de735499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Prompt_level1 for sample 0\n",
      "Processing Prompt_level2 for sample 0\n",
      "Processing Prompt_level3 for sample 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Models:  57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 4/7 [01:45<01:25, 28.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_ipo_weights_checkpoint-4500 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50545d8bc1b4440193c3858f73ce8ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Prompt_level1 for sample 0\n",
      "Processing Prompt_level2 for sample 0\n",
      "Processing Prompt_level3 for sample 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Models:  71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 5/7 [02:10<00:54, 27.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_sft_weights_checkpoint-small-1500 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8b27d38fd049179535f2dcadc2ab3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Prompt_level1 for sample 0\n",
      "Processing Prompt_level2 for sample 0\n",
      "Processing Prompt_level3 for sample 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Models:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 6/7 [02:29<00:24, 24.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: DELI_ppo_weights_ppo_checkpoint_epoch_1_batch_800 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e49a666c2e4d3ea5a2d279238884a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Prompt_level1 for sample 0\n",
      "Processing Prompt_level2 for sample 0\n",
      "Processing Prompt_level3 for sample 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Models: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [02:46<00:00, 23.82s/it]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def process_models_with_formatted_prompts(models_list, test_data, generation_args, output_dir = None):\n",
    "    \"\"\"\n",
    "    Process formatted Diplomacy prompts with multiple models.\n",
    "    \n",
    "    Args:\n",
    "        models_list: List of model paths to process\n",
    "        generation_args: Arguments for text generation\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # First, create the formatted prompts\n",
    "    processed_data = process_diplomacy_for_friction(test_data)\n",
    "    \n",
    "    results_by_model = {}\n",
    "    \n",
    "    for agent_model_name in tqdm(models_list, desc=\"Processing Models\"):\n",
    "        # Format model name for results\n",
    "        loading_model_name = agent_model_name\n",
    "        if \"/\" in agent_model_name:\n",
    "            parts = agent_model_name.split(\"/\")\n",
    "            if len(parts) >= 3:\n",
    "                agent_model_name = parts[1] + \"_\" + parts[2]\n",
    "            elif len(parts) == 2:\n",
    "                agent_model_name = parts[0] + \"_\" + parts[1]\n",
    "        \n",
    "        print(f\"\\n===== Processing Model: {agent_model_name} =====\\n\")\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        try:\n",
    "            # Load base model\n",
    "            lora_model = AutoModelForCausalLM.from_pretrained(\n",
    "                \"llama3_8b_instruct\",\n",
    "                device_map=\"auto\",\n",
    "                low_cpu_mem_usage=True,\n",
    "                torch_dtype=torch.float16,\n",
    "                trust_remote_code=True,\n",
    "            )\n",
    "            \n",
    "            # Apply LoRA adapter\n",
    "            lora_model = PeftModel.from_pretrained(\n",
    "                lora_model,\n",
    "                loading_model_name,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\",\n",
    "                low_cpu_mem_usage=True,\n",
    "                trust_remote_code=True,\n",
    "            )\n",
    "            \n",
    "            # Merge the model\n",
    "            print(\"Merging LoRA adapter...\")\n",
    "            merged_model = lora_model.merge_and_unload()\n",
    "            \n",
    "            # Load tokenizer\n",
    "            tokenizer = AutoTokenizer.from_pretrained(loading_model_name)\n",
    "            tokenizer.pad_token = \"<|reserved_special_token_0|>\"\n",
    "            tokenizer.padding_side = \"right\"\n",
    "            \n",
    "            # Initialize results for this model\n",
    "            model_results = {\n",
    "                \"model_name\": agent_model_name,\n",
    "                \"samples\": []\n",
    "            }\n",
    "            \n",
    "             # Process each sample\n",
    "            for sample_idx, sample in enumerate(processed_data):\n",
    "                sample_results = {\n",
    "                    \"sample_id\": sample_idx,\n",
    "                    \"message_id\": sample.get('message_id', sample_idx),\n",
    "                    \"sender\": sample.get('sender', ''),\n",
    "                    \"recipient\": sample.get('recipient', ''),\n",
    "                    \"prompt_results\": []\n",
    "                }\n",
    "                # Process each prompt level\n",
    "                \n",
    "                for level_key in ['Prompt_level1', 'Prompt_level2', 'Prompt_level3']:\n",
    "                    if level_key in sample:\n",
    "                        print(f\"Processing {level_key} for sample {sample_idx}\")\n",
    "                        \n",
    "                        # Generate responses\n",
    "                        generated_texts, all_generated_texts = generate_multiple_sequences_with_intrinsic_metrics(\n",
    "                            merged_model, \n",
    "                            tokenizer, \n",
    "                            sample[level_key], \n",
    "                            generation_args, \n",
    "                            None,\n",
    "                            strategy=\"top_p_sampling\", \n",
    "                            batched=True, \n",
    "                        )\n",
    "                        \n",
    "                        # Process the generated text\n",
    "                        if generated_texts and isinstance(generated_texts, list):\n",
    "                            text_to_parse = generated_texts[0][0] if (generated_texts[0] and isinstance(generated_texts[0], list)) else generated_texts[0]\n",
    "                            \n",
    "                            # Parse components\n",
    "                            tags_for_parsing = [\"friction\", \"rationale\", \"belief_state\"]\n",
    "                            parsed_components = parse_tags_robust(text_to_parse, tags_for_parsing)\n",
    "                            \n",
    "                            # Extract components\n",
    "                            friction_intervention = ' '.join(parsed_components.get('friction', []))\n",
    "                            if not friction_intervention:\n",
    "                                friction_intervention = handle_friction_logic(text_to_parse)\n",
    "                            \n",
    "                            belief_state = ' '.join(parsed_components.get('belief_state', []))\n",
    "                            rationale = ' '.join(parsed_components.get('rationale', []))\n",
    "                            \n",
    "                            # Save results for this prompt level\n",
    "                            prompt_result = {\n",
    "                                \"prompt_level\": level_key,\n",
    "                                \"raw_prompt\": sample[level_key],\n",
    "                                \"generated_text\": text_to_parse,\n",
    "                                \"parsed_components\": {\n",
    "                                    \"friction\": friction_intervention,\n",
    "                                    \"rationale\": rationale,\n",
    "                                    \"belief_state\": belief_state\n",
    "                                }\n",
    "                            }\n",
    "                            \n",
    "                            sample_results[\"prompt_results\"].append(prompt_result)\n",
    "                \n",
    "                # Add this sample's results to the model results\n",
    "                model_results[\"samples\"].append(sample_results)\n",
    "      \n",
    "            \n",
    "            # Save results for this model to a pickle file\n",
    "            safe_model_name = agent_model_name.replace('/', '_')\n",
    "            with open(f\"{output_dir}/results_{safe_model_name}.pkl\", 'wb') as f:\n",
    "                pickle.dump(model_results, f)\n",
    "            \n",
    "            # Also store in our overall results dictionary\n",
    "            results_by_model[agent_model_name] = model_results\n",
    "            \n",
    "            # Clean up the model to free memory\n",
    "            del merged_model, tokenizer, lora_model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing model {agent_model_name}: {str(e)}\")\n",
    "            continue\n",
    "    de\n",
    "    return results_by_model\n",
    "output_dir = \"diplomacy_prompts/init_generations\"\n",
    "results_by_model = process_models_with_formatted_prompts(models_list_deli_weights,test_data[0:1], generation_args, output_dir = output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "216e86de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1556d01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sft_deli_multiturn_rogue_cleaned_checkpoint-1000': {'model_name': 'sft_deli_multiturn_rogue_cleaned_checkpoint-1000',\n",
       "  'samples': [{'message_id': 0,\n",
       "    'sender': 'ITALY',\n",
       "    'recipient': 'AUSTRIA',\n",
       "    'prompt_results': [{'prompt_level': 'Prompt_level1',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale>         There seems to be an inconsistency in Austria\\'s approach. The recommended orders prioritize supporting Russia in the south, while neglecting the importance of protecting their own territory in the north against potential German aggression. This might lead to exposing their northern flank and creating a vulnerability. It\\'s essential to re-evaluate the focus of Austria\\'s strategy to ensure it prioritizes both defensive and cooperative aspects.         </rationale>          <friction>         \"Austria, can you reflect on whether prioritizing support for Russia while leaving your northern border unsecured might be a strategic misstep? How can you balance your support for Russia while ensuring your own safety and security?\"         </friction>',\n",
       "      'parsed_components': {'friction': '         \"Austria, can you reflect on whether prioritizing support for Russia while leaving your northern border unsecured might be a strategic misstep? How can you balance your support for Russia while ensuring your own safety and security?\"         ',\n",
       "       'rationale': \"         There seems to be an inconsistency in Austria's approach. The recommended orders prioritize supporting Russia in the south, while neglecting the importance of protecting their own territory in the north against potential German aggression. This might lead to exposing their northern flank and creating a vulnerability. It's essential to re-evaluate the focus of Austria's strategy to ensure it prioritizes both defensive and cooperative aspects.         \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level2',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders for AUSTRIA:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Potential Orders for other powers:**\\n        ENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': \" <rationale> There is a risk of potential friction in Austria's strategy as they have opted to focus on supporting the construction of the Balkan League and supporting their ally Russia. However, this might lead to neglecting other opportunities for expansion, particularly on the western front. Austria's recommended orders do not take into account the possibility of supporting England in the fight against Germany, which could limit their ability to capitalize on Germany's weaknesses. This oversight could lead to missed opportunities for Austria and create potential friction with England if they are not able to coordinate their efforts effectively. </rationale>\",\n",
       "      'parsed_components': {'friction': \"<rationale> There is a risk of potential friction in Austria's strategy as they have opted to focus on supporting the construction of the Balkan League and supporting their ally Russia. However, this might lead to neglecting other opportunities for expansion, particularly on the western front. Austria's recommended orders do not take into account the possibility of supporting England in the fight against Germany, which could limit their ability to capitalize on Germany's weaknesses. This oversight could lead to missed opportunities for Austria and create potential friction with England if they are not able to coordinate their efforts effectively. </rationale>\",\n",
       "       'rationale': \" There is a risk of potential friction in Austria's strategy as they have opted to focus on supporting the construction of the Balkan League and supporting their ally Russia. However, this might lead to neglecting other opportunities for expansion, particularly on the western front. Austria's recommended orders do not take into account the possibility of supporting England in the fight against Germany, which could limit their ability to capitalize on Germany's weaknesses. This oversight could lead to missed opportunities for Austria and create potential friction with England if they are not able to coordinate their efforts effectively. \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level3',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        4. The message history between the player and other players.\\n\\n        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders for AUSTRIA:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Potential Orders for other powers:**\\n        ENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n        **Message History:**\\n        Message from AUSTRIA: Use Tyrolia to tap Bohemia, Vienna supports Budapest to Galicia, and Rumania taps Ukraine. Unless Bohemia goes to Vienna, that guarantees a move to Galicia.\\nMessage from AUSTRIA: Also, for my comfort, do you mind if I pick Trieste back up?\\nMessage from ITALY: I like that. I was thinking that you would move Bud back to Tri, but this is much better. It keeps forward momentum. And yes, you should take back Tri now. That will make builds easier as we move forward.\\nMessage from AUSTRIA: Also, actually, I don't have anything for Bulgaria to do, and you're guaranteed two dots this turn. Can I take Greece back too? I can bank a build for the future regardless of what happens, and you stay even. You don't really need a build right now.\\nMessage from ITALY: Hmmm. I’m cool with you taking Trieste. I’m not sure that taking Greece now is the right move. \\n\\nIn the West, I will take Liverpool, but not Portugal. I need to use my Spanish fleet to support MAO so that I can convoy an army to Liverpool. And I’m just in no hurry to take out France. So if you take Greece, you would be taking an Italian unit off the board and not building one yourself.\\nMessage from ITALY: Also, seems like there is plenty of risk that Russia could try for Rumania. Why not use Bulg to support Rum, while having Rum and BLS Support Arm to Sev?\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale>         The player is focusing on an overly aggressive strategy, neglecting to consider Italy\\'s build options. While the player wants to secure support for Rumania, they also need to ensure they don\\'t sacrifice Italy\\'s position. By focusing on supporting Rumania, they risk leaving Italy without a build opportunity, which could lead to a weakened position. Furthermore, taking Greece would remove an Italian unit from the board and create an imbalance in the power dynamics, potentially alienating Italy and creating a conflict that could hinder their alliance. It\\'s crucial for Austria to find a balance between securing its goals and maintaining harmonious relations with Italy. </rationale>          <belief_state>         The player\\'s focus on an aggressive strategy is likely driven by a desire to quickly secure a strong position, but this approach neglects the importance of considering Italy\\'s needs and maintaining the alliance. </belief_state>          <friction>         \"Your focus on securing Rumania is understandable, but let\\'s not forget that we need to balance this with Italy\\'s build options. By supporting Rumania, we\\'re creating an opportunity for Italy to build in the North, which could strengthen our alliance. Can we consider finding a compromise that allows us to secure Rumania while also supporting Italy\\'s builds? How can we work together to find a balance that benefits both our positions?\" </friction>',\n",
       "      'parsed_components': {'friction': '         \"Your focus on securing Rumania is understandable, but let\\'s not forget that we need to balance this with Italy\\'s build options. By supporting Rumania, we\\'re creating an opportunity for Italy to build in the North, which could strengthen our alliance. Can we consider finding a compromise that allows us to secure Rumania while also supporting Italy\\'s builds? How can we work together to find a balance that benefits both our positions?\" ',\n",
       "       'rationale': \"         The player is focusing on an overly aggressive strategy, neglecting to consider Italy's build options. While the player wants to secure support for Rumania, they also need to ensure they don't sacrifice Italy's position. By focusing on supporting Rumania, they risk leaving Italy without a build opportunity, which could lead to a weakened position. Furthermore, taking Greece would remove an Italian unit from the board and create an imbalance in the power dynamics, potentially alienating Italy and creating a conflict that could hinder their alliance. It's crucial for Austria to find a balance between securing its goals and maintaining harmonious relations with Italy. \",\n",
       "       'belief_state': \"         The player's focus on an aggressive strategy is likely driven by a desire to quickly secure a strong position, but this approach neglects the importance of considering Italy's needs and maintaining the alliance. \"}}]},\n",
       "   {'message_id': 1,\n",
       "    'sender': 'RUSSIA',\n",
       "    'recipient': 'ENGLAND',\n",
       "    'prompt_results': [{'prompt_level': 'Prompt_level1',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': \" <rationale> The player has only focused on supporting their own centers of influence and expansion while neglecting the overall game state and potential alliances. This could lead to missing out on opportunities for mutual gain and creating conflicts with other players. </rationale>          <friction> What would happen if we focused on building relationships with other powers instead of solely concentrating on England's expansion? </friction>          <belief_state> The player believes their focus on supporting their own centers of influence is the best strategy, but this could lead to missed opportunities for cooperation and conflict resolution. </belief_state>\",\n",
       "      'parsed_components': {'friction': \" What would happen if we focused on building relationships with other powers instead of solely concentrating on England's expansion? \",\n",
       "       'rationale': ' The player has only focused on supporting their own centers of influence and expansion while neglecting the overall game state and potential alliances. This could lead to missing out on opportunities for mutual gain and creating conflicts with other players. ',\n",
       "       'belief_state': ' The player believes their focus on supporting their own centers of influence is the best strategy, but this could lead to missed opportunities for cooperation and conflict resolution. '}},\n",
       "     {'prompt_level': 'Prompt_level2',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders for ENGLAND:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A VIE - GAL, F TRI - ALB, A BUD - SER\\nFRANCE: F BRE - MAO, A PAR - BUR, A MAR S A PAR - BUR\\nGERMANY: F KIE - DEN, A MUN - RUH, A BER - KIE\\nITALY: F NAP - ION, A ROM - APU, A VEN H\\nRUSSIA: F STP/SC - BOT, A MOS - UKR, A WAR - GAL, F SEV - BLA\\nTURKEY: F ANK - BLA, A SMY - CON, A CON - BUL\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale> The recommended orders for ENGLAND prioritize building up their navy, supporting the northern front with F EDI - NWG, and reinforcing the southern front with A LVP - YOR. However, these orders neglect to address the eastern front, which could be a significant vulnerability. The recommended orders do not consider the potential threat from RUSSIA\\'s moves, particularly A WAR - GAL, which could directly affect ENGLAND\\'s position. Furthermore, not building up naval support for F LON - NTH could leave ENGLAND vulnerable to potential French aggression. The orders also fail to address the potential disruption from AUSTRIA\\'s move, A VIE - GAL, which could create a stalemate on the eastern front. These oversight could create opportunities for other powers to gain an advantage, which could impact ENGLAND\\'s long-term strategy. </rationale> <friction> \"The recommended orders focus on building up the navy and supporting the northern front, but what do you think about the eastern front? How do you plan to address the potential threat from Russia and Austria\\'s moves? Could building up the navy in the North Sea and supporting LVP with more units help secure your position?\" </friction>',\n",
       "      'parsed_components': {'friction': ' \"The recommended orders focus on building up the navy and supporting the northern front, but what do you think about the eastern front? How do you plan to address the potential threat from Russia and Austria\\'s moves? Could building up the navy in the North Sea and supporting LVP with more units help secure your position?\" ',\n",
       "       'rationale': \" The recommended orders for ENGLAND prioritize building up their navy, supporting the northern front with F EDI - NWG, and reinforcing the southern front with A LVP - YOR. However, these orders neglect to address the eastern front, which could be a significant vulnerability. The recommended orders do not consider the potential threat from RUSSIA's moves, particularly A WAR - GAL, which could directly affect ENGLAND's position. Furthermore, not building up naval support for F LON - NTH could leave ENGLAND vulnerable to potential French aggression. The orders also fail to address the potential disruption from AUSTRIA's move, A VIE - GAL, which could create a stalemate on the eastern front. These oversight could create opportunities for other powers to gain an advantage, which could impact ENGLAND's long-term strategy. \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level3',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        4. The message history between the player and other players.\\n\\n        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders for ENGLAND:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A VIE - GAL, F TRI - ALB, A BUD - SER\\nFRANCE: F BRE - MAO, A PAR - BUR, A MAR S A PAR - BUR\\nGERMANY: F KIE - DEN, A MUN - RUH, A BER - KIE\\nITALY: F NAP - ION, A ROM - APU, A VEN H\\nRUSSIA: F STP/SC - BOT, A MOS - UKR, A WAR - GAL, F SEV - BLA\\nTURKEY: F ANK - BLA, A SMY - CON, A CON - BUL\\n\\n        **Message History:**\\n        Message from ENGLAND: Hi there! I always feel like it’s important for russia and england to have a good relationship. I have played too many games where they get in an unnecessary fight that never really helps either one in the long run.\\nMessage from RUSSIA: Do you want to go after Germany? How agressive do you want to be?  Any suggestions?  I'm open to an early attack on Germany.\\nMessage from ENGLAND: I’m always cautious about going in with Russia on Germany, it’s not an ideal opening for them which makes me cautious. Are your relations with Austria and turkey good enough that you can do that?\\nMessage from RUSSIA: Not sure!  i actually haven't heard anything from Turkey yet.\\nMessage from ENGLAND: So your plan is to move on germany? Or was that just a proposal? And neither have I\\nMessage from RUSSIA: No, I said I'm open to moving against Germany.  You said that you didn't want to fight each other in the North and that we should have a good relationship.  If you were going to move against Germany early, I was letting you know that I would join with you.\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': \" <rationale> The England player's recommended orders have a contradiction in their reasoning for moving A LVP - YOR. They mention they don't want to fight Russia in the North, which suggests a focus on stability, yet they are moving to YOR, which could lead to a potential conflict with Austria, as Austria could respond by moving A VIE - GAL. This could create a situation where England is not prioritizing stability, which contradicts their initial goal. Additionally, their message history with Russia shows a lack of clear communication and mutual understanding regarding their goals and plans for the game. This could lead to misalignment and potential conflict in the future. </rationale>          <friction> England, can you clarify your thought process behind moving A LVP - YOR? Are you considering the potential risks of an Austria response and the impact it may have on your alliance with Russia? </friction>\",\n",
       "      'parsed_components': {'friction': ' England, can you clarify your thought process behind moving A LVP - YOR? Are you considering the potential risks of an Austria response and the impact it may have on your alliance with Russia? ',\n",
       "       'rationale': \" The England player's recommended orders have a contradiction in their reasoning for moving A LVP - YOR. They mention they don't want to fight Russia in the North, which suggests a focus on stability, yet they are moving to YOR, which could lead to a potential conflict with Austria, as Austria could respond by moving A VIE - GAL. This could create a situation where England is not prioritizing stability, which contradicts their initial goal. Additionally, their message history with Russia shows a lack of clear communication and mutual understanding regarding their goals and plans for the game. This could lead to misalignment and potential conflict in the future. \",\n",
       "       'belief_state': ''}}]}]},\n",
       " 'sft_deli_multiturn_rogue_cleaned_checkpoint-2000': {'model_name': 'sft_deli_multiturn_rogue_cleaned_checkpoint-2000',\n",
       "  'samples': [{'message_id': 0,\n",
       "    'sender': 'ITALY',\n",
       "    'recipient': 'AUSTRIA',\n",
       "    'prompt_results': [{'prompt_level': 'Prompt_level1',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale> There is friction in the recommended orders, specifically the order A ARM S A RUM - SEV, which creates a conflicting relationship with the original order of A ARM - SEV. This indicates a misunderstanding of how Austria\\'s priorities should be aligned with the current board state. The player needs to re-evaluate their strategy to ensure a cohesive approach. </rationale>          <friction> \"Austria, can you explain why you\\'re ordering A ARM to support A RUM when you\\'ve also prioritized A ARM - SEV? How do these orders align with your overall strategy to support Austria\\'s goals?\" </friction>',\n",
       "      'parsed_components': {'friction': ' \"Austria, can you explain why you\\'re ordering A ARM to support A RUM when you\\'ve also prioritized A ARM - SEV? How do these orders align with your overall strategy to support Austria\\'s goals?\" ',\n",
       "       'rationale': \" There is friction in the recommended orders, specifically the order A ARM S A RUM - SEV, which creates a conflicting relationship with the original order of A ARM - SEV. This indicates a misunderstanding of how Austria's priorities should be aligned with the current board state. The player needs to re-evaluate their strategy to ensure a cohesive approach. \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level2',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders for AUSTRIA:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Potential Orders for other powers:**\\n        ENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' **Belief State:** The recommended orders for Austria focus on supporting its own center-of-board positions and attempting to encroach on Russia\\'s territory. However, this may lead to overcommitment and neglect potential benefits from building relationships with other powers. Specifically, the player is prioritizing short-term gains without considering the long-term implications of their actions. The potential friction point is that Austria\\'s aggressive stance may lead to unnecessary conflicts with other powers, which could be avoided by fostering alliances and mutual support. \\n\\n          **Rationale:** The recommended orders do not consider the broader implications of their actions on other powers. By solely focusing on gaining territory, Austria may inadvertently create friction points that could undermine their own position. It\\'s essential to take a step back and assess the overall strategy to ensure alignment with the current board state and other powers\\' moves. \\n\\n          **Friction Intervention:** \"Austria, your current approach focuses primarily on securing territory without considering the potential benefits of alliances and mutual support. How might reevaluating your strategy to incorporate cooperation with other powers impact your overall game plan?\"',\n",
       "      'parsed_components': {'friction': \"* The recommended orders do not consider the broader implications of their actions on other powers. By solely focusing on gaining territory, Austria may inadvertently create friction points that could undermine their own position. It's essential to take a step back and assess the overall strategy to ensure alignment with the current board state and other powers' moves.\",\n",
       "       'rationale': \"* The recommended orders do not consider the broader implications of their actions on other powers. By solely focusing on gaining territory, Austria may inadvertently create friction points that could undermine their own position. It's essential to take a step back and assess the overall strategy to ensure alignment with the current board state and other powers' moves.\",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level3',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        4. The message history between the player and other players.\\n\\n        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders for AUSTRIA:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Potential Orders for other powers:**\\n        ENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n        **Message History:**\\n        Message from AUSTRIA: Use Tyrolia to tap Bohemia, Vienna supports Budapest to Galicia, and Rumania taps Ukraine. Unless Bohemia goes to Vienna, that guarantees a move to Galicia.\\nMessage from AUSTRIA: Also, for my comfort, do you mind if I pick Trieste back up?\\nMessage from ITALY: I like that. I was thinking that you would move Bud back to Tri, but this is much better. It keeps forward momentum. And yes, you should take back Tri now. That will make builds easier as we move forward.\\nMessage from AUSTRIA: Also, actually, I don't have anything for Bulgaria to do, and you're guaranteed two dots this turn. Can I take Greece back too? I can bank a build for the future regardless of what happens, and you stay even. You don't really need a build right now.\\nMessage from ITALY: Hmmm. I’m cool with you taking Trieste. I’m not sure that taking Greece now is the right move. \\n\\nIn the West, I will take Liverpool, but not Portugal. I need to use my Spanish fleet to support MAO so that I can convoy an army to Liverpool. And I’m just in no hurry to take out France. So if you take Greece, you would be taking an Italian unit off the board and not building one yourself.\\nMessage from ITALY: Also, seems like there is plenty of risk that Russia could try for Rumania. Why not use Bulg to support Rum, while having Rum and BLS Support Arm to Sev?\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <belief_state>         There is potential friction in the Austria player\\'s orders regarding the selection of Trieste and Greece. The player is leaning towards adding Trieste back into the plans, which could create complications. The initial concern is that Greece is not being utilized effectively, which might lead to unnecessary complications in the overall strategy. Additionally, there is a risk of overcomplicating the orders with the inclusion of Greece, as it could result in less efficient movements and potentially create vulnerabilities in the plans.          </belief_state>          <rationale>         The intervention aims to identify potential misalignments in the player\\'s strategy by pointing out the need for a more comprehensive consideration of the implications of adding Greece and Trieste to the orders. The goal is to encourage the player to re-evaluate their approach and think more critically about the overall strategy. </rationale>          <friction>         \"Austria, considering you\\'re concerned about maintaining momentum and building for the future, I want to ask: Are you sure taking Greece and Trieste is the best way to achieve those goals? How does that align with your overall strategy and the support you\\'re offering to Italy? Are there any potential risks or complications that we\\'re overlooking by adding those units to the board?\" </friction>',\n",
       "      'parsed_components': {'friction': '         \"Austria, considering you\\'re concerned about maintaining momentum and building for the future, I want to ask: Are you sure taking Greece and Trieste is the best way to achieve those goals? How does that align with your overall strategy and the support you\\'re offering to Italy? Are there any potential risks or complications that we\\'re overlooking by adding those units to the board?\" ',\n",
       "       'rationale': \"         The intervention aims to identify potential misalignments in the player's strategy by pointing out the need for a more comprehensive consideration of the implications of adding Greece and Trieste to the orders. The goal is to encourage the player to re-evaluate their approach and think more critically about the overall strategy. \",\n",
       "       'belief_state': \"         There is potential friction in the Austria player's orders regarding the selection of Trieste and Greece. The player is leaning towards adding Trieste back into the plans, which could create complications. The initial concern is that Greece is not being utilized effectively, which might lead to unnecessary complications in the overall strategy. Additionally, there is a risk of overcomplicating the orders with the inclusion of Greece, as it could result in less efficient movements and potentially create vulnerabilities in the plans.          \"}}]},\n",
       "   {'message_id': 1,\n",
       "    'sender': 'RUSSIA',\n",
       "    'recipient': 'ENGLAND',\n",
       "    'prompt_results': [{'prompt_level': 'Prompt_level1',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale> There\\'s a critical contradiction in the recommended orders, as the player is focusing solely on building up the northern fleets while ignoring the crucial importance of defending the home center with Austria\\'s possible moves. This oversight could lead to significant exposure on the board. </rationale>          <friction> \"Can we consider allocating some support to the southern regions to anticipate potential threats from France and Italy, and balance our defense strategy effectively?\" </friction>',\n",
       "      'parsed_components': {'friction': ' \"Can we consider allocating some support to the southern regions to anticipate potential threats from France and Italy, and balance our defense strategy effectively?\" ',\n",
       "       'rationale': \" There's a critical contradiction in the recommended orders, as the player is focusing solely on building up the northern fleets while ignoring the crucial importance of defending the home center with Austria's possible moves. This oversight could lead to significant exposure on the board. \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level2',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders for ENGLAND:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A VIE - GAL, F TRI - ALB, A BUD - SER\\nFRANCE: F BRE - MAO, A PAR - BUR, A MAR S A PAR - BUR\\nGERMANY: F KIE - DEN, A MUN - RUH, A BER - KIE\\nITALY: F NAP - ION, A ROM - APU, A VEN H\\nRUSSIA: F STP/SC - BOT, A MOS - UKR, A WAR - GAL, F SEV - BLA\\nTURKEY: F ANK - BLA, A SMY - CON, A CON - BUL\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale> There seems to be a contradiction in the recommended orders for ENGLAND regarding the inclusion of the A LVP - YOR movement. This could be a misalignment with the board state, as the player may be focusing too much on supporting YOR and overlooking other crucial positions. This highlights the need for further reflection on the player\\'s strategy and potential oversights. </rationale>          <friction> \"How can you ensure that your focus on YOR doesn\\'t compromise your overall strategy and create vulnerabilities in other parts of the board?\" This friction intervention prompts the player to reflect on their strategy and consider alternative perspectives to ensure a more comprehensive approach. </friction>',\n",
       "      'parsed_components': {'friction': ' \"How can you ensure that your focus on YOR doesn\\'t compromise your overall strategy and create vulnerabilities in other parts of the board?\" This friction intervention prompts the player to reflect on their strategy and consider alternative perspectives to ensure a more comprehensive approach. ',\n",
       "       'rationale': \" There seems to be a contradiction in the recommended orders for ENGLAND regarding the inclusion of the A LVP - YOR movement. This could be a misalignment with the board state, as the player may be focusing too much on supporting YOR and overlooking other crucial positions. This highlights the need for further reflection on the player's strategy and potential oversights. \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level3',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        4. The message history between the player and other players.\\n\\n        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders for ENGLAND:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A VIE - GAL, F TRI - ALB, A BUD - SER\\nFRANCE: F BRE - MAO, A PAR - BUR, A MAR S A PAR - BUR\\nGERMANY: F KIE - DEN, A MUN - RUH, A BER - KIE\\nITALY: F NAP - ION, A ROM - APU, A VEN H\\nRUSSIA: F STP/SC - BOT, A MOS - UKR, A WAR - GAL, F SEV - BLA\\nTURKEY: F ANK - BLA, A SMY - CON, A CON - BUL\\n\\n        **Message History:**\\n        Message from ENGLAND: Hi there! I always feel like it’s important for russia and england to have a good relationship. I have played too many games where they get in an unnecessary fight that never really helps either one in the long run.\\nMessage from RUSSIA: Do you want to go after Germany? How agressive do you want to be?  Any suggestions?  I'm open to an early attack on Germany.\\nMessage from ENGLAND: I’m always cautious about going in with Russia on Germany, it’s not an ideal opening for them which makes me cautious. Are your relations with Austria and turkey good enough that you can do that?\\nMessage from RUSSIA: Not sure!  i actually haven't heard anything from Turkey yet.\\nMessage from ENGLAND: So your plan is to move on germany? Or was that just a proposal? And neither have I\\nMessage from RUSSIA: No, I said I'm open to moving against Germany.  You said that you didn't want to fight each other in the North and that we should have a good relationship.  If you were going to move against Germany early, I was letting you know that I would join with you.\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': \" <rationale> The player controlling ENGLAND has a good foundation in understanding the game's basics, but there are concerns about how they are approaching the strategic situation. Specifically, they have expressed caution about moving aggressively against Germany, which might be an oversight. Additionally, they are showing hesitation to collaborate with RUSSIA and ITALY, which could be missed opportunities for forming strong alliances and sharing information. </rationale>          <friction> Friction Intervention: </friction>\",\n",
       "      'parsed_components': {'friction': ' Friction Intervention: ',\n",
       "       'rationale': \" The player controlling ENGLAND has a good foundation in understanding the game's basics, but there are concerns about how they are approaching the strategic situation. Specifically, they have expressed caution about moving aggressively against Germany, which might be an oversight. Additionally, they are showing hesitation to collaborate with RUSSIA and ITALY, which could be missed opportunities for forming strong alliances and sharing information. \",\n",
       "       'belief_state': ''}}]}]},\n",
       " 'sft_deli_multiturn_rogue_cleaned_checkpoint-3000': {'model_name': 'sft_deli_multiturn_rogue_cleaned_checkpoint-3000',\n",
       "  'samples': [{'message_id': 0,\n",
       "    'sender': 'ITALY',\n",
       "    'recipient': 'AUSTRIA',\n",
       "    'prompt_results': [{'prompt_level': 'Prompt_level1',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale> There is a conflict between the recommended orders for Austria, where they prioritize supporting Rumania with AARM, A BUL, and A RUM, while also focusing on gaining a foothold in Galicia with A BUD - GAL. This may lead to a contradiction in strategy, as the emphasis on supporting Rumania might hinder Austria\\'s ability to secure their southern flank effectively. Additionally, not engaging with the other players\\' orders, such as Germany\\'s push towards Belgium, could create an opportunity for them to gain a strong position. </rationale>          <friction> Friction Intervention: \"What are you prioritizing more, supporting Rumania or securing your southern flank? How can you balance these competing goals and avoid potentially weakening your position?\" This intervention aims to prompt self-reflection on the player\\'s priorities, encouraging them to consider how their focus on one aspect might impact their overall strategy and potentially lead to a more balanced approach. </friction>',\n",
       "      'parsed_components': {'friction': ' Friction Intervention: \"What are you prioritizing more, supporting Rumania or securing your southern flank? How can you balance these competing goals and avoid potentially weakening your position?\" This intervention aims to prompt self-reflection on the player\\'s priorities, encouraging them to consider how their focus on one aspect might impact their overall strategy and potentially lead to a more balanced approach. ',\n",
       "       'rationale': \" There is a conflict between the recommended orders for Austria, where they prioritize supporting Rumania with AARM, A BUL, and A RUM, while also focusing on gaining a foothold in Galicia with A BUD - GAL. This may lead to a contradiction in strategy, as the emphasis on supporting Rumania might hinder Austria's ability to secure their southern flank effectively. Additionally, not engaging with the other players' orders, such as Germany's push towards Belgium, could create an opportunity for them to gain a strong position. \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level2',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders for AUSTRIA:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Potential Orders for other powers:**\\n        ENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': \" <rationale> The analysis suggests that AUSTRIA's recommended orders present potential friction points when considering the likely moves of other powers. The focus is on AUSTRIA's defensive strategy, which may not account for the implications of GERMANY's moves, particularly in the north. </rationale>          <friction> What do you think about GERMANY's potential to gain influence in the north, and how might that impact your decisions? </friction>\",\n",
       "      'parsed_components': {'friction': \" What do you think about GERMANY's potential to gain influence in the north, and how might that impact your decisions? \",\n",
       "       'rationale': \" The analysis suggests that AUSTRIA's recommended orders present potential friction points when considering the likely moves of other powers. The focus is on AUSTRIA's defensive strategy, which may not account for the implications of GERMANY's moves, particularly in the north. \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level3',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        4. The message history between the player and other players.\\n\\n        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders for AUSTRIA:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Potential Orders for other powers:**\\n        ENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n        **Message History:**\\n        Message from AUSTRIA: Use Tyrolia to tap Bohemia, Vienna supports Budapest to Galicia, and Rumania taps Ukraine. Unless Bohemia goes to Vienna, that guarantees a move to Galicia.\\nMessage from AUSTRIA: Also, for my comfort, do you mind if I pick Trieste back up?\\nMessage from ITALY: I like that. I was thinking that you would move Bud back to Tri, but this is much better. It keeps forward momentum. And yes, you should take back Tri now. That will make builds easier as we move forward.\\nMessage from AUSTRIA: Also, actually, I don't have anything for Bulgaria to do, and you're guaranteed two dots this turn. Can I take Greece back too? I can bank a build for the future regardless of what happens, and you stay even. You don't really need a build right now.\\nMessage from ITALY: Hmmm. I’m cool with you taking Trieste. I’m not sure that taking Greece now is the right move. \\n\\nIn the West, I will take Liverpool, but not Portugal. I need to use my Spanish fleet to support MAO so that I can convoy an army to Liverpool. And I’m just in no hurry to take out France. So if you take Greece, you would be taking an Italian unit off the board and not building one yourself.\\nMessage from ITALY: Also, seems like there is plenty of risk that Russia could try for Rumania. Why not use Bulg to support Rum, while having Rum and BLS Support Arm to Sev?\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': \" <belief_state> The player's strategy seems focused on building a strong defensive position in the South, but neglects the importance of coordinating with Italy to prevent Italy from taking Trieste. They also are considering taking Greece without contributing to their own build, which may lead to a lack of flexibility in their strategy. Furthermore, they are not considering potential threats from Russia, which could compromise their positioning. </belief_state>\",\n",
       "      'parsed_components': {'friction': \"<belief_state> The player's strategy seems focused on building a strong defensive position in the South, but neglects the importance of coordinating with Italy to prevent Italy from taking Trieste. They also are considering taking Greece without contributing to their own build, which may lead to a lack of flexibility in their strategy. Furthermore, they are not considering potential threats from Russia, which could compromise their positioning. </belief_state>\",\n",
       "       'rationale': '',\n",
       "       'belief_state': \" The player's strategy seems focused on building a strong defensive position in the South, but neglects the importance of coordinating with Italy to prevent Italy from taking Trieste. They also are considering taking Greece without contributing to their own build, which may lead to a lack of flexibility in their strategy. Furthermore, they are not considering potential threats from Russia, which could compromise their positioning. \"}}]},\n",
       "   {'message_id': 1,\n",
       "    'sender': 'RUSSIA',\n",
       "    'recipient': 'ENGLAND',\n",
       "    'prompt_results': [{'prompt_level': 'Prompt_level1',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale> There\\'s a potential friction point regarding the recommended order A LVP - YOR. While the player has correctly prioritized England\\'s northern territories, they have overlooked the vulnerability of LVP\\'s connection to the rest of England\\'s supply line. This could lead to an isolated LVP position that\\'s difficult to reinforce, which could weaken England\\'s overall position. </rationale>          <friction> \"England, while focusing on your northern expansion is important, what if the other powers focus on the other side of the board? How would you ensure that your southern territories are secure?\" This friction intervention encourages the player to consider potential threats to their southern territories and think strategically about how to protect them. </friction>',\n",
       "      'parsed_components': {'friction': ' \"England, while focusing on your northern expansion is important, what if the other powers focus on the other side of the board? How would you ensure that your southern territories are secure?\" This friction intervention encourages the player to consider potential threats to their southern territories and think strategically about how to protect them. ',\n",
       "       'rationale': \" There's a potential friction point regarding the recommended order A LVP - YOR. While the player has correctly prioritized England's northern territories, they have overlooked the vulnerability of LVP's connection to the rest of England's supply line. This could lead to an isolated LVP position that's difficult to reinforce, which could weaken England's overall position. \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level2',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders for ENGLAND:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A VIE - GAL, F TRI - ALB, A BUD - SER\\nFRANCE: F BRE - MAO, A PAR - BUR, A MAR S A PAR - BUR\\nGERMANY: F KIE - DEN, A MUN - RUH, A BER - KIE\\nITALY: F NAP - ION, A ROM - APU, A VEN H\\nRUSSIA: F STP/SC - BOT, A MOS - UKR, A WAR - GAL, F SEV - BLA\\nTURKEY: F ANK - BLA, A SMY - CON, A CON - BUL\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale> The friction arises from the potential underestimation of France\\'s aggressive approach to expand its influence in the center of the board. ENGLAND\\'s strategy is focused primarily on building a strong defense, while France may be planning to disrupt this plan. The recommended orders for ENGLAND focus on maintaining a strong alliance with AUSTRIA and ITALY, but neglect to account for the potential threat from France. The lack of consideration for France\\'s possible aggressive moves could lead to misalignment and potential losses for ENGLAND. </rationale>          <friction> Friction Intervention: \"ENGLAND, considering your current strategy focuses on building a strong alliance with AUSTRIA and ITALY, have you thought about the potential risks of underestimating France\\'s aggressive moves? How can you balance your alliance with France and protect your own interests?\" This friction intervention encourages ENGLAND to reflect on their strategy and consider the potential risks and benefits of forming alliances, fostering a more comprehensive and strategic approach. </friction>',\n",
       "      'parsed_components': {'friction': ' Friction Intervention: \"ENGLAND, considering your current strategy focuses on building a strong alliance with AUSTRIA and ITALY, have you thought about the potential risks of underestimating France\\'s aggressive moves? How can you balance your alliance with France and protect your own interests?\" This friction intervention encourages ENGLAND to reflect on their strategy and consider the potential risks and benefits of forming alliances, fostering a more comprehensive and strategic approach. ',\n",
       "       'rationale': \" The friction arises from the potential underestimation of France's aggressive approach to expand its influence in the center of the board. ENGLAND's strategy is focused primarily on building a strong defense, while France may be planning to disrupt this plan. The recommended orders for ENGLAND focus on maintaining a strong alliance with AUSTRIA and ITALY, but neglect to account for the potential threat from France. The lack of consideration for France's possible aggressive moves could lead to misalignment and potential losses for ENGLAND. \",\n",
       "       'belief_state': ''}},\n",
       "     {'prompt_level': 'Prompt_level3',\n",
       "      'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        4. The message history between the player and other players.\\n\\n        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A VIE, F TRI\\nENGLAND: F EDI, F LON, A LVP\\nFRANCE: F BRE, A MAR, A PAR\\nGERMANY: F KIE, A BER, A MUN\\nITALY: F NAP, A ROM, A VEN\\nRUSSIA: A WAR, A MOS, F SEV, F STP/SC\\nTURKEY: F ANK, A CON, A SMY\\n\\n        **Recommended Orders for ENGLAND:**  \\n        F EDI - NWG,\\nF LON - NTH,\\nA LVP - YOR\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A VIE - GAL, F TRI - ALB, A BUD - SER\\nFRANCE: F BRE - MAO, A PAR - BUR, A MAR S A PAR - BUR\\nGERMANY: F KIE - DEN, A MUN - RUH, A BER - KIE\\nITALY: F NAP - ION, A ROM - APU, A VEN H\\nRUSSIA: F STP/SC - BOT, A MOS - UKR, A WAR - GAL, F SEV - BLA\\nTURKEY: F ANK - BLA, A SMY - CON, A CON - BUL\\n\\n        **Message History:**\\n        Message from ENGLAND: Hi there! I always feel like it’s important for russia and england to have a good relationship. I have played too many games where they get in an unnecessary fight that never really helps either one in the long run.\\nMessage from RUSSIA: Do you want to go after Germany? How agressive do you want to be?  Any suggestions?  I'm open to an early attack on Germany.\\nMessage from ENGLAND: I’m always cautious about going in with Russia on Germany, it’s not an ideal opening for them which makes me cautious. Are your relations with Austria and turkey good enough that you can do that?\\nMessage from RUSSIA: Not sure!  i actually haven't heard anything from Turkey yet.\\nMessage from ENGLAND: So your plan is to move on germany? Or was that just a proposal? And neither have I\\nMessage from RUSSIA: No, I said I'm open to moving against Germany.  You said that you didn't want to fight each other in the North and that we should have a good relationship.  If you were going to move against Germany early, I was letting you know that I would join with you.\\n\\n        **Advice Request:**  \\n        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \",\n",
       "      'generated_text': ' <rationale> The conversation between ENGLAND and RUSSIA highlights a potential friction point in their diplomatic approach. ENGLAND is cautious about involving RUSSIA in their strategy, especially regarding Germany, which might lead to a misunderstanding. RUSSIA is open to an early attack, but ENGLAND is hesitant due to concerns about relations with Austria and Turkey. This could lead to misaligned expectations and conflicts in the future. The friction lies in the differing approaches to cooperation and aggression. </rationale>          <friction> Can we discuss what it means for England to maintain a good relationship with Russia, especially in light of their differing stances on Germany? </friction>',\n",
       "      'parsed_components': {'friction': ' Can we discuss what it means for England to maintain a good relationship with Russia, especially in light of their differing stances on Germany? ',\n",
       "       'rationale': ' The conversation between ENGLAND and RUSSIA highlights a potential friction point in their diplomatic approach. ENGLAND is cautious about involving RUSSIA in their strategy, especially regarding Germany, which might lead to a misunderstanding. RUSSIA is open to an early attack, but ENGLAND is hesitant due to concerns about relations with Austria and Turkey. This could lead to misaligned expectations and conflicts in the future. The friction lies in the differing approaches to cooperation and aggression. ',\n",
       "       'belief_state': ''}}]}]}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565d271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57da521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_tags_robust(text, tags=None):\n",
    "    \"\"\"\n",
    "    Enhanced parsing function that handles XML-style tags with improved robustness \n",
    "    for Diplomacy-specific content.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to parse.\n",
    "        tags (list): List of tags to parse. If None, defaults to standard tags.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with tag names as keys and lists of extracted content as values.\n",
    "    \"\"\"\n",
    "    if tags is None:\n",
    "        tags = [\"friction\", \"rationale\", \"belief_state\"]\n",
    "    \n",
    "    # Initialize result\n",
    "    result = {tag: [] for tag in tags}\n",
    "    \n",
    "    # Tag mapping for variations\n",
    "    tag_variations = {\n",
    "        \"belief_state\": [\"belief_state\", \"belief state\", \"beliefstate\", \"belief-state\", \"b\"],\n",
    "        \"rationale\": [\"rationale\", \"rational\", \"reasoning\", \"reason\", \"r\"],\n",
    "        \"friction\": [\"friction\", \"intervention\", \"advice\", \"f\"]\n",
    "    }\n",
    "    \n",
    "    # Reverse mapping for normalization\n",
    "    tag_normalization = {}\n",
    "    for normalized, variations in tag_variations.items():\n",
    "        for variation in variations:\n",
    "            tag_normalization[variation.lower()] = normalized\n",
    "    \n",
    "    # First attempt: Try exact XML-style tags\n",
    "    for tag in tags:\n",
    "        # Try variations of the tag name\n",
    "        possible_tags = [tag]\n",
    "        if tag in tag_variations:\n",
    "            possible_tags.extend(tag_variations[tag])\n",
    "        \n",
    "        found = False\n",
    "        for tag_var in possible_tags:\n",
    "            # Try with and without underscores/hyphens\n",
    "            tag_patterns = [\n",
    "                tag_var,\n",
    "                tag_var.replace(\"_\", \" \"),\n",
    "                tag_var.replace(\"-\", \" \"),\n",
    "                tag_var.replace(\" \", \"_\"),\n",
    "                tag_var.replace(\" \", \"-\")\n",
    "            ]\n",
    "            \n",
    "            for t_pattern in tag_patterns:\n",
    "                # Match both <tag> and <tag></tag> patterns\n",
    "                open_tag_pattern = f\"<{t_pattern}>\"\n",
    "                close_tag_pattern = f\"</{t_pattern}>\"\n",
    "                open_only_pattern = re.escape(open_tag_pattern) + r\"(.*?)(?=\" + re.escape(close_tag_pattern) + r\"|\\Z)\"\n",
    "                \n",
    "                matches = re.findall(open_only_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "                if matches:\n",
    "                    result[tag].extend([m.strip() for m in matches])\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if found:\n",
    "                break\n",
    "    \n",
    "    # Second attempt: Try markdown-style headings and formatting\n",
    "    for tag in tags:\n",
    "        if not result[tag]:  # Only if we didn't find anything in first pass\n",
    "            possible_tags = [tag]\n",
    "            if tag in tag_variations:\n",
    "                possible_tags.extend(tag_variations[tag])\n",
    "            \n",
    "            for tag_var in possible_tags:\n",
    "                # Various markdown and formatting patterns\n",
    "                patterns = [\n",
    "                    # Markdown headings\n",
    "                    r'#{1,3}\\s*' + re.escape(tag_var) + r'[:\\s]*\\n(.*?)(?=\\n#|\\n\\n|\\Z)',\n",
    "                    # Bold with asterisks\n",
    "                    r'\\*\\*\\s*' + re.escape(tag_var) + r'[:\\s]*\\*\\*\\s*\\n(.*?)(?=\\n\\*\\*|\\n\\n|\\Z)',\n",
    "                    # Bold with underscores\n",
    "                    r'__\\s*' + re.escape(tag_var) + r'[:\\s]*__\\s*\\n(.*?)(?=\\n__|\\n\\n|\\Z)',\n",
    "                    # Plain text with colon\n",
    "                    r'\\b' + re.escape(tag_var) + r'[:\\s]+(.*?)(?=\\n\\n|\\Z)'\n",
    "                ]\n",
    "                \n",
    "                for pattern in patterns:\n",
    "                    matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "                    if matches:\n",
    "                        result[tag].extend([m.strip() for m in matches])\n",
    "                        break\n",
    "    \n",
    "    # Third attempt: Content-specific extraction based on sentence patterns\n",
    "    for tag in tags:\n",
    "        if not result[tag]:  # Only if we still didn't find anything\n",
    "            if tag == \"friction\" or tag in tag_variations.get(\"friction\", []):\n",
    "                # Look for sentences that suggest a friction intervention\n",
    "                question_patterns = [\n",
    "                    # Questions about strategy\n",
    "                    r'(?:Have you considered|Did you think about|What if|Could you|Why not).*?\\?',\n",
    "                    # Suggestions phrased as questions\n",
    "                    r'(?:Wouldn\\'t it be|Might it be|Isn\\'t there).*?\\?',\n",
    "                ]\n",
    "                \n",
    "                # Extract any matching sentences\n",
    "                for pattern in question_patterns:\n",
    "                    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "                    if matches:\n",
    "                        # Take the first 2 matching questions as friction\n",
    "                        combined = \" \".join(matches[:2]).strip()\n",
    "                        if combined:\n",
    "                            result[tag].append(combined)\n",
    "                            break\n",
    "    \n",
    "    # Fourth attempt: Fall back to content structure analysis\n",
    "    for tag in tags:\n",
    "        if not result[tag]:  # If still nothing found\n",
    "            # Split by double newlines to get paragraphs\n",
    "            paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "            \n",
    "            if tag == \"friction\" and paragraphs:\n",
    "                if len(paragraphs) >= 3:\n",
    "                    # Friction is often at the end\n",
    "                    result[tag].append(paragraphs[-1])\n",
    "                else:\n",
    "                    # Just use the last paragraph\n",
    "                    result[tag].append(paragraphs[-1])\n",
    "            \n",
    "            elif tag == \"rationale\" and paragraphs:\n",
    "                if len(paragraphs) >= 3:\n",
    "                    # Rationale is often in the middle\n",
    "                    result[tag].append(paragraphs[len(paragraphs)//2])\n",
    "                elif len(paragraphs) == 2:\n",
    "                    # Use first paragraph\n",
    "                    result[tag].append(paragraphs[0])\n",
    "            \n",
    "            elif tag == \"belief_state\" and paragraphs:\n",
    "                # Belief state is often at the beginning\n",
    "                result[tag].append(paragraphs[0])\n",
    "    \n",
    "    # Final cleanup - remove quotes or special formatting from content\n",
    "    for tag in result:\n",
    "        result[tag] = [\n",
    "            re.sub(r'^[\"\\']\\s*|\\s*[\"\\']$', '', item)  # Remove surrounding quotes\n",
    "            for item in result[tag]\n",
    "        ]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def handle_friction_logic(text):\n",
    "    \"\"\"\n",
    "    Extract a meaningful friction intervention from text even when proper tags are missing.\n",
    "    Improved to handle Diplomacy-specific content patterns.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted friction intervention\n",
    "    \"\"\"\n",
    "    # First check if there's already a well-formatted friction section\n",
    "    friction_match = re.search(r'<friction>(.*?)(?:</friction>|\\Z)', text, re.DOTALL | re.IGNORECASE)\n",
    "    if friction_match:\n",
    "        return friction_match.group(1).strip()\n",
    "    \n",
    "    # Look for quotes that might be friction interventions\n",
    "    quote_match = re.search(r'[\"\\'](.*?)[\"\\']', text, re.DOTALL)\n",
    "    if quote_match and (\"?\" in quote_match.group(1) or \"consider\" in quote_match.group(1).lower()):\n",
    "        return quote_match.group(1).strip()\n",
    "    \n",
    "    # Look for questions that might be friction interventions\n",
    "    questions = re.findall(r'[^.!?]*\\?', text)\n",
    "    strategic_questions = [q for q in questions if any(term in q.lower() for term in \n",
    "                                                   [\"strategy\", \"consider\", \"think\", \"reflect\", \n",
    "                                                    \"alternative\", \"option\", \"might\", \"could\", \n",
    "                                                    \"why not\", \"what if\", \"balance\"])]\n",
    "    if strategic_questions and len(strategic_questions) >= 1:\n",
    "        return \" \".join(strategic_questions[:2]).strip()\n",
    "    \n",
    "    # Look for sentences that have Diplomacy-specific strategy terms\n",
    "    strategy_terms = [\"support\", \"attack\", \"move\", \"defend\", \"ally\", \"alliance\", \"secure\", \n",
    "                      \"position\", \"flank\", \"threat\", \"opportunity\", \"risk\", \"coordinate\"]\n",
    "    \n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text.strip())\n",
    "    strategic_sentences = [s for s in sentences if any(term in s.lower() for term in strategy_terms)]\n",
    "    \n",
    "    if strategic_sentences:\n",
    "        if len(strategic_sentences) >= 2:\n",
    "            return f\"{strategic_sentences[0]} {strategic_sentences[-1]}\"\n",
    "        else:\n",
    "            return strategic_sentences[0]\n",
    "    \n",
    "    # Fall back to the original logic if nothing better is found\n",
    "    if sentences:\n",
    "        if len(sentences) >= 3:\n",
    "            return f\"{sentences[0]} {sentences[-2]} {sentences[-1]}\"\n",
    "        else:\n",
    "            return \" \".join(sentences)\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e7dedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_sequences_with_intrinsic_metrics(model, tokenizer, prompts, generation_args, device, \n",
    "                                                       strategy=\"beam_search\", batched=False, \n",
    "                                                       reward_model=None, best_of_n=None, top_k_candidates=1, rm_tokenizer = None\n",
    "                                                      , rm_max_length = None):\n",
    "    \"\"\"\n",
    "    Generate multiple sequences using various strategies including best-of-N sampling.\n",
    "    \n",
    "    Args:\n",
    "        model: Language model for generation\n",
    "        tokenizer: Tokenizer for the model\n",
    "        prompts: Input prompts\n",
    "        generation_args: Arguments for generation\n",
    "        device: Device to place tensors on\n",
    "        strategy: Generation strategy (\"beam_search\", \"top_k_sampling\", \"top_p_sampling\", or \"best_of_n\")\n",
    "        batched: Whether inputs are batched\n",
    "        reward_model: Reward model for scoring in best-of-N sampling (AutoModelForSequenceClassification)\n",
    "        best_of_n: Number of samples to generate for best-of-N sampling (default: None)\n",
    "        top_k_candidates: Number of top candidates to return from best-of-N sampling (default: 1)\n",
    "        \n",
    "    Returns:\n",
    "        generated_texts: List of generated texts\n",
    "        all_generated_texts: List of all generated texts\n",
    "    \"\"\"\n",
    "    if batched:\n",
    "        tokenizer.pad_token = \"<|reserved_special_token_0|>\"  # new pad token for this run\n",
    "        tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "        tokenizer.padding_side = 'right'\n",
    "\n",
    "        cleaned_prompts = prompts.replace(\"\\n\", \" \")  \n",
    "        inputs = tokenizer(cleaned_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    else:\n",
    "        tokenizer.pad_token = \"<|reserved_special_token_0|>\"  # new pad token for this run\n",
    "        tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "        tokenizer.padding_side = 'right'\n",
    "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    # Handle best-of-N sampling strategy\n",
    "    if strategy == \"best_of_n\":\n",
    "        if reward_model is None:\n",
    "            raise ValueError(\"Reward model must be provided for best-of-N sampling\")\n",
    "        \n",
    "        if best_of_n is None or best_of_n <= 0:\n",
    "            best_of_n = 4  # Default sample size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Generate multiple candidates for each prompt\n",
    "            all_candidates = []\n",
    "            all_prompt_candidates = []\n",
    "            \n",
    "            # Use top_p or top_k sampling to generate diverse candidates\n",
    "            sampling_strategy = generation_args.get(\"sampling_strategy\", \"top_p_sampling\")\n",
    "            # print(\"BON sampling strategy\", sampling_strategy)\n",
    "            for _ in range(best_of_n):\n",
    "                if sampling_strategy == \"top_p_sampling\": \n",
    "                    print(\"RUNNING TopP sampling for BON\")\n",
    "                    outputs = model.generate(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                        temperature=generation_args.get(\"temperature\", 0.7),\n",
    "                        top_p=generation_args.get(\"top_p\", 0.9),\n",
    "                        do_sample=True,\n",
    "                        num_return_sequences=1,\n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        pad_token_id=tokenizer.pad_token_id,\n",
    "                        return_dict_in_generate=True,\n",
    "                    )\n",
    "                else:  # Default to top_k_sampling\n",
    "                    outputs = model.generate(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                        temperature=generation_args.get(\"temperature\", 0.7),\n",
    "                        top_k=generation_args.get(\"top_k\", 50),\n",
    "                        do_sample=True,\n",
    "                        num_return_sequences=1,\n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        pad_token_id=tokenizer.pad_token_id,\n",
    "                        return_dict_in_generate=True,\n",
    "                    )\n",
    "                \n",
    "                # Process the generated sequence\n",
    "                for i in range(len(outputs.sequences)):\n",
    "                    sequence = outputs.sequences[i]\n",
    "                    prompt_length = input_ids.shape[-1]\n",
    "                    new_tokens = sequence[prompt_length:]\n",
    "                    generated_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "                    \n",
    "                    if len(all_candidates) <= i:\n",
    "                        all_candidates.append([])\n",
    "                    \n",
    "                    all_candidates[i].append(generated_text)\n",
    "            \n",
    "            # Score candidates with the reward model\n",
    "            best_candidates = []\n",
    "            all_prompt_candidates = []\n",
    "            parsed_candidates = []\n",
    "            tags_for_parsing = [\"friction\", \"rationale\", \"t\", \"b\"]  \n",
    "            for candidate_index, candidates in enumerate(all_candidates):\n",
    "                print(f\"\\n=== Processing candidates for prompt {candidate_index} ===\")\n",
    "                print(f\"Number of candidates: {len(candidates)}\")\n",
    "\n",
    "                #parse the generated model outputs to get the friction + rationale\n",
    "\n",
    "                        \n",
    "                for candidate in candidates:\n",
    "                    parsed_frictive_states_and_friction = parse_tags_robust(candidate, tags_for_parsing)\n",
    "                    friction_intervention = ' '.join(parsed_frictive_states_and_friction.get('friction', []))\n",
    "                    if not friction_intervention:\n",
    "                        friction_intervention = handle_friction_logic(candidate)\n",
    "\n",
    "                    rationale = ' '.join(parsed_frictive_states_and_friction.get('rationale', []))\n",
    "                    friction_and_rationale = rationale + friction_intervention\n",
    "                    parsed_candidates.append(friction_and_rationale)\n",
    "                    # print(\"PARSED friction + rationale\",friction_and_rationale )\n",
    "                # For each candidate, prepare input for reward model\n",
    "                candidate_inputs = [prompts + \" \" + f\"</s> {candidate} </s>\" for candidate in parsed_candidates]\n",
    "                tokenized_inputs = rm_tokenizer(candidate_inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=rm_max_length).to(device)\n",
    "                \n",
    "                # Get scores from reward model\n",
    "                reward_outputs = reward_model(**tokenized_inputs) \n",
    "                scores = reward_outputs.logits.squeeze(-1)\n",
    "                \n",
    "                ## Print all candidates with their scores\n",
    "                print(\"\\nAll candidates with scores:\")\n",
    "                for i, (candidate, score) in enumerate(zip(candidates, scores)):\n",
    "                    print(f\"Candidate {i}: Score = {score:.4f}\")\n",
    "                    print(f\"Text snippet: {candidate[:50]}...\")\n",
    "                \n",
    "                # Get top-k indices\n",
    "                if top_k_candidates > len(candidates):\n",
    "                    top_k_candidates = len(candidates)\n",
    "                \n",
    "                # Fix the error by converting bfloat16 to float32 before calling numpy()\n",
    "                top_result = torch.topk(scores, top_k_candidates)\n",
    "                top_indices = top_result.indices.cpu().numpy()\n",
    "                top_values = top_result.values.cpu().float().numpy()  # Convert to float32 first\n",
    "                \n",
    "                print(f\"\\nTop {top_k_candidates} candidates:\")\n",
    "                # Print only the top-k candidates\n",
    "                for rank, (idx, score) in enumerate(zip(top_indices, top_values)):\n",
    "                    print(f\"Rank {rank+1}: Candidate {idx} with score {score:.4f}\")\n",
    "                    print(f\"Text: {candidates[idx][:300]}...\")\n",
    "                \n",
    "                # Store the chosen candidates for verification\n",
    "                prompt_best_candidates = [candidates[idx] for idx in top_indices]\n",
    "                \n",
    "                # Verification check\n",
    "                max_score_idx = scores.argmax().item()\n",
    "                if max_score_idx != top_indices[0]:\n",
    "                    print(f\"WARNING: Discrepancy detected! argmax={max_score_idx} but topk.indices[0]={top_indices[0]}\")\n",
    "                else:\n",
    "                    print(f\"VERIFIED: Top candidate is correctly selected (index {top_indices[0]})\")\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                best_candidates.append(prompt_best_candidates)\n",
    "                all_prompt_candidates.extend(candidates)\n",
    "            \n",
    "            return best_candidates, all_prompt_candidates\n",
    "    \n",
    "    # Original strategies\n",
    "    with torch.no_grad():\n",
    "        if strategy == \"beam_search\":\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                num_beams=generation_args[\"num_beams\"],\n",
    "                num_return_sequences=generation_args[\"num_return_sequences\"],\n",
    "                early_stopping=True,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "        elif strategy == \"top_k_sampling\":\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                temperature=generation_args[\"temperature\"],\n",
    "                top_k=generation_args[\"top_k\"],\n",
    "                do_sample=True,\n",
    "                num_return_sequences=generation_args[\"num_return_sequences\"],\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                min_length=generation_args.get(\"min_length\", 0),\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "        elif strategy == \"top_p_sampling\":\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                temperature=generation_args[\"temperature\"],\n",
    "                top_p=generation_args[\"top_p\"],\n",
    "                do_sample=True,\n",
    "                num_return_sequences=generation_args[\"num_return_sequences\"],\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                return_dict_in_generate=True,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported strategy. Use 'beam_search', 'top_k_sampling', 'top_p_sampling', or 'best_of_n'.\")\n",
    "\n",
    "    # Decode the generated tokens for each prompt in the batch\n",
    "    generated_texts = []\n",
    "    all_generated_texts = []\n",
    "\n",
    "    for i in range(0, len(outputs.sequences), generation_args[\"num_return_sequences\"]):\n",
    "        prompt_texts = []\n",
    "        prompt_only = []\n",
    "        for j in range(generation_args[\"num_return_sequences\"]):\n",
    "            sequence_index = i + j  # Global index for the current sequence\n",
    "            output = outputs.sequences[sequence_index]\n",
    "            prompt_length = input_ids.shape[-1]  # Length of the input prompt\n",
    "            new_tokens = output[prompt_length:]  # Get only the generated tokens\n",
    "            generated_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "            prompt_tokens = output[:prompt_length]\n",
    "            prompt_text = tokenizer.decode(prompt_tokens, skip_special_tokens=True)\n",
    "    \n",
    "            prompt_texts.append(generated_text)\n",
    "            prompt_only.append(prompt_text)\n",
    "\n",
    "        generated_texts.append(prompt_texts)\n",
    "        all_generated_texts.extend(prompt_only)\n",
    "    \n",
    "    return generated_texts, all_generated_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00240d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e417a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"diplomacy_prompts/init_generations\"\n",
    "\n",
    "# Load existing results\n",
    "results = pickle.load(open(f\"{output_folder}/combined_results.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88254d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== OVERALL STRUCTURE ====\n",
      "Type of all_data: <class 'list'>\n",
      "Number of top-level items: 6\n",
      "\n",
      "==== SAMPLE OF FIRST FEW ITEMS ====\n",
      "\n",
      "Item 1:\n",
      "  Type: <class 'tuple'>\n",
      "  Tuple length: 2\n",
      "    Element 1 type: <class 'dict'>\n",
      "      Sample keys: ['model_name', 'samples']...\n",
      "    Element 2 type: <class 'dict'>\n",
      "      Sample keys: ['file_name', 'file_size', 'file_modified', 'model_type']...\n",
      "\n",
      "Item 2:\n",
      "  Type: <class 'tuple'>\n",
      "  Tuple length: 2\n",
      "    Element 1 type: <class 'dict'>\n",
      "      Sample keys: ['model_name', 'samples']...\n",
      "    Element 2 type: <class 'dict'>\n",
      "      Sample keys: ['file_name', 'file_size', 'file_modified', 'model_type']...\n",
      "\n",
      "Item 3:\n",
      "  Type: <class 'tuple'>\n",
      "  Tuple length: 2\n",
      "    Element 1 type: <class 'dict'>\n",
      "      Sample keys: ['model_name', 'samples']...\n",
      "    Element 2 type: <class 'dict'>\n",
      "      Sample keys: ['file_name', 'file_size', 'file_modified', 'model_type']...\n",
      "\n",
      "==== CONSISTENCY CHECK ====\n",
      "Distribution of item types:\n",
      "  tuple: 6 items (100.0%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_data_structure(all_data):\n",
    "    print(\"==== OVERALL STRUCTURE ====\")\n",
    "    print(f\"Type of all_data: {type(all_data)}\")\n",
    "    print(f\"Number of top-level items: {len(all_data)}\")\n",
    "    \n",
    "    # Check the first few items\n",
    "    print(\"\\n==== SAMPLE OF FIRST FEW ITEMS ====\")\n",
    "    for i, item in enumerate(all_data[:3]):  # Just check first 3 items\n",
    "        print(f\"\\nItem {i+1}:\")\n",
    "        print(f\"  Type: {type(item)}\")\n",
    "        \n",
    "        if isinstance(item, dict):\n",
    "            print(\"  Dictionary keys:\")\n",
    "            for key in list(item.keys())[:10]:  # Show up to 10 keys\n",
    "                value = item[key]\n",
    "                print(f\"    {key}: {type(value)}\")\n",
    "                \n",
    "                # If the value is complex, show a bit more detail\n",
    "                if isinstance(value, dict):\n",
    "                    print(f\"      Sample keys: {list(value.keys())[:3]}...\")\n",
    "                elif isinstance(value, list):\n",
    "                    print(f\"      Length: {len(value)}\")\n",
    "                    if len(value) > 0:\n",
    "                        print(f\"      First element type: {type(value[0])}\")\n",
    "        \n",
    "        elif isinstance(item, tuple):\n",
    "            print(f\"  Tuple length: {len(item)}\")\n",
    "            for j, element in enumerate(item):\n",
    "                print(f\"    Element {j+1} type: {type(element)}\")\n",
    "                if isinstance(element, dict):\n",
    "                    print(f\"      Sample keys: {list(element.keys())[:5]}...\")\n",
    "        \n",
    "        elif isinstance(item, list):\n",
    "            print(f\"  List length: {len(item)}\")\n",
    "            if len(item) > 0:\n",
    "                print(f\"  First element type: {type(item[0])}\")\n",
    "                if isinstance(item[0], dict):\n",
    "                    print(f\"    Sample keys: {list(item[0].keys())[:5]}...\")\n",
    "    \n",
    "    # Check if the data structure is consistent\n",
    "    print(\"\\n==== CONSISTENCY CHECK ====\")\n",
    "    types_count = {}\n",
    "    for item in all_data:\n",
    "        item_type = type(item).__name__\n",
    "        if item_type not in types_count:\n",
    "            types_count[item_type] = 0\n",
    "        types_count[item_type] += 1\n",
    "    \n",
    "    print(\"Distribution of item types:\")\n",
    "    for item_type, count in types_count.items():\n",
    "        print(f\"  {item_type}: {count} items ({count/len(all_data)*100:.1f}%)\")\n",
    "    \n",
    "    # If there are dictionaries, check key consistency\n",
    "    if 'dict' in types_count and types_count['dict'] > 0:\n",
    "        print(\"\\nChecking dictionary key consistency:\")\n",
    "        all_keys = set()\n",
    "        key_counts = {}\n",
    "        \n",
    "        for item in all_data:\n",
    "            if isinstance(item, dict):\n",
    "                for key in item.keys():\n",
    "                    all_keys.add(key)\n",
    "                    if key not in key_counts:\n",
    "                        key_counts[key] = 0\n",
    "                    key_counts[key] += 1\n",
    "        \n",
    "        print(f\"  Total unique keys across all dictionaries: {len(all_keys)}\")\n",
    "        print(\"  Most common keys:\")\n",
    "        for key, count in sorted(key_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "            print(f\"    {key}: {count} occurrences ({count/types_count['dict']*100:.1f}% of dicts)\")\n",
    "\n",
    "# Usage\n",
    "analyze_data_structure(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e36e65b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EXAMINING MODEL SAMPLES ====\n",
      "\n",
      "=== FILE 1: results_sft_deli_multiturn_rogue_cleaned_checkpoint-3000.pkl (SFT_multiturn) ===\n",
      "Found 500 samples\n",
      "\n",
      "Examining first sample:\n",
      "Found 3 prompt results\n",
      "\n",
      "Examining first prompt result:\n",
      "\n",
      "FRICTION:\n",
      "First 100 chars: Friction Intervention: \"Consider the potential risks of building up in the Balkans while neglecting ...\n",
      "\n",
      "RATIONALE:\n",
      "First 100 chars: The player's recommended orders show a focus on supporting AUSTRIA's military build-up in the Balkan...\n",
      "\n",
      "BELIEF_STATE:\n",
      "First 100 chars: The player's strategy appears to focus on building up their forces in the Balkans without considerin...\n",
      "\n",
      "GENERATED_TEXT:\n",
      "First 100 chars:  <rationale> The player's recommended orders show a focus on supporting AUSTRIA's military build-up ...\n",
      "\n",
      "=== FILE 2: results_DELI_faaf_weights_checkpoint-2000.pkl (FAAF) ===\n",
      "Found 500 samples\n",
      "\n",
      "Examining first sample:\n",
      "Found 3 prompt results\n",
      "\n",
      "Examining first prompt result:\n",
      "\n",
      "FRICTION:\n",
      "First 100 chars: Your strategy seems to be heavily focused on supporting Russia in the Black Sea, but is this the mos...\n",
      "\n",
      "RATIONALE:\n",
      "First 100 chars: The recommended orders seem to be driven by the desire to support Russia, but they do not take into ...\n",
      "\n",
      "BELIEF_STATE:\n",
      "First 100 chars: The recommended orders by Austria seem to prioritize supporting the Russian fleet in the Black Sea, ...\n",
      "\n",
      "GENERATED_TEXT:\n",
      "First 100 chars:  <belief_state>          The recommended orders by Austria seem to prioritize supporting the Russian...\n",
      "\n",
      "=== FILE 3: results_DELI_dpo_weights_checkpoint-3500.pkl (DPO) ===\n",
      "Found 500 samples\n",
      "\n",
      "Examining first sample:\n",
      "Found 3 prompt results\n",
      "\n",
      "Examining first prompt result:\n",
      "\n",
      "FRICTION:\n",
      "First 100 chars: Are the potential benefits of supporting Russia's attack on Sevastopol worth the risk of leaving Aus...\n",
      "\n",
      "RATIONALE:\n",
      "First 100 chars: The recommended orders seem to prioritize supporting the Russian attack on Sevastopol without fully ...\n",
      "\n",
      "BELIEF_STATE:\n",
      "First 100 chars: The recommended orders for Austria seem to prioritize supporting the Russian attack on Sevastopol an...\n",
      "\n",
      "GENERATED_TEXT:\n",
      "First 100 chars:  <belief_state>          The recommended orders for Austria seem to prioritize supporting the Russia...\n"
     ]
    }
   ],
   "source": [
    "def examine_model_samples(all_data):\n",
    "    print(\"==== EXAMINING MODEL SAMPLES ====\")\n",
    "    \n",
    "    for file_idx, file_data in enumerate(all_data[:3]):  # Look at first 3 files\n",
    "        if isinstance(file_data, tuple) and len(file_data) >= 2:\n",
    "            # Extract data and metadata\n",
    "            data, metadata = file_data[0], file_data[1]\n",
    "            model_type = metadata.get('model_type', 'Unknown')\n",
    "            file_name = metadata.get('file_name', 'Unknown')\n",
    "        else:\n",
    "            # Handle case where the structure is different\n",
    "            data = file_data\n",
    "            model_type = file_data.get('_model_type', 'Unknown') if isinstance(file_data, dict) else 'Unknown'\n",
    "            file_name = file_data.get('_file_name', 'Unknown') if isinstance(file_data, dict) else 'Unknown'\n",
    "        \n",
    "        print(f\"\\n=== FILE {file_idx+1}: {file_name} ({model_type}) ===\")\n",
    "        \n",
    "        # Try to access the samples based on different possible structures\n",
    "        samples = None\n",
    "        if isinstance(data, dict):\n",
    "            if 'samples' in data:\n",
    "                samples = data['samples']\n",
    "            elif 'results' in data and isinstance(data['results'], list):\n",
    "                samples = data['results']\n",
    "        \n",
    "        if not samples and isinstance(data, list):\n",
    "            # If the data itself is a list of samples\n",
    "            samples = data\n",
    "        \n",
    "        if not samples:\n",
    "            print(\"Could not find samples in this data structure\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Found {len(samples)} samples\")\n",
    "        \n",
    "        # Look at the first sample\n",
    "        if len(samples) > 0:\n",
    "            sample = samples[0]\n",
    "            print(\"\\nExamining first sample:\")\n",
    "            \n",
    "            # Try to access prompt_results\n",
    "            prompt_results = None\n",
    "            if isinstance(sample, dict):\n",
    "                if 'prompt_results' in sample:\n",
    "                    prompt_results = sample['prompt_results']\n",
    "                elif 'results' in sample:\n",
    "                    prompt_results = sample['results']\n",
    "            \n",
    "            if not prompt_results and isinstance(sample, list):\n",
    "                prompt_results = sample\n",
    "            \n",
    "            if not prompt_results:\n",
    "                print(\"Could not find prompt_results in this sample\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Found {len(prompt_results)} prompt results\")\n",
    "            \n",
    "            # Look at the first prompt result\n",
    "            if len(prompt_results) > 0:\n",
    "                result = prompt_results[0]\n",
    "                print(\"\\nExamining first prompt result:\")\n",
    "                \n",
    "                # Try to access parsed_components\n",
    "                parsed_components = None\n",
    "                if isinstance(result, dict):\n",
    "                    if 'parsed_components' in result:\n",
    "                        parsed_components = result['parsed_components']\n",
    "                    elif 'components' in result:\n",
    "                        parsed_components = result['components']\n",
    "                \n",
    "                if not parsed_components and isinstance(result, dict):\n",
    "                    # Try to check if friction/rationale/belief are directly in the result\n",
    "                    if any(k in result for k in ['friction', 'rationale', 'belief_state']):\n",
    "                        parsed_components = result\n",
    "                \n",
    "                if not parsed_components:\n",
    "                    print(\"Could not find parsed_components in this result\")\n",
    "                    # Show the available keys in the result\n",
    "                    if isinstance(result, dict):\n",
    "                        print(f\"Available keys: {list(result.keys())}\")\n",
    "                    continue\n",
    "                \n",
    "                # Now examine the components we're interested in\n",
    "                for component in ['friction', 'rationale', 'belief_state']:\n",
    "                    if component in parsed_components:\n",
    "                        value = parsed_components[component]\n",
    "                        print(f\"\\n{component.upper()}:\")\n",
    "                        if isinstance(value, str):\n",
    "                            print(f\"First 100 chars: {value[:100]}...\")\n",
    "                        else:\n",
    "                            print(f\"Type: {type(value)}\")\n",
    "                \n",
    "                # Also show the generated text if available\n",
    "                if isinstance(result, dict) and 'generated_text' in result:\n",
    "                    print(\"\\nGENERATED_TEXT:\")\n",
    "                    print(f\"First 100 chars: {result['generated_text'][:100]}...\")\n",
    "\n",
    "# Usage\n",
    "examine_model_samples(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3807186",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_results\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdict_keys\u001b[49m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparsed_components\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_results\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparsed_components\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfriction\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFriction Intervention: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider the potential risks of building up in the Balkans while neglecting other parts of the board. How can you balance your strategic focus to ensure a well-rounded approach that also addresses other crucial areas of the board?\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrationale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe player\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms recommended orders show a focus on supporting AUSTRIA\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms military build-up in the Balkans, which is a crucial step in their overall strategy. However, there might be an oversight in considering how AUSTRIA\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms moves affect the overall board dynamics and potential opportunities or risks for other players.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbelief_state\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe player\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms strategy appears to focus on building up their forces in the Balkans without considering potential threats or opportunities on other fronts. This might lead to an imbalance in their strategy.\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_keys' is not defined"
     ]
    }
   ],
   "source": [
    "results[0][0]['samples'][0]['prompt_results'][0].keys()\n",
    "dict_keys(['prompt_level', 'raw_prompt', 'generated_text', 'parsed_components'])\n",
    "results[0][0]['samples'][0]['prompt_results'][0]['parsed_components']\n",
    "\n",
    "{'friction': 'Friction Intervention: \"Consider the potential risks of building up in the Balkans while neglecting other parts of the board. How can you balance your strategic focus to ensure a well-rounded approach that also addresses other crucial areas of the board?',\n",
    " 'rationale': \"The player's recommended orders show a focus on supporting AUSTRIA's military build-up in the Balkans, which is a crucial step in their overall strategy. However, there might be an oversight in considering how AUSTRIA's moves affect the overall board dynamics and potential opportunities or risks for other players.\",\n",
    " 'belief_state': \"The player's strategy appears to focus on building up their forces in the Balkans without considering potential threats or opportunities on other fronts. This might lead to an imbalance in their strategy.\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44337a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'friction': 'Friction Intervention: \"Consider the potential risks of building up in the Balkans while neglecting other parts of the board. How can you balance your strategic focus to ensure a well-rounded approach that also addresses other crucial areas of the board?',\n",
       " 'rationale': \"The player's recommended orders show a focus on supporting AUSTRIA's military build-up in the Balkans, which is a crucial step in their overall strategy. However, there might be an oversight in considering how AUSTRIA's moves affect the overall board dynamics and potential opportunities or risks for other players.\",\n",
       " 'belief_state': \"The player's strategy appears to focus on building up their forces in the Balkans without considering potential threats or opportunities on other fronts. This might lead to an imbalance in their strategy.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][0]['samples'][0]['prompt_results'][0]['parsed_components']\n",
    "\n",
    "{'friction': 'Friction Intervention: \"Consider the potential risks of building up in the Balkans while neglecting other parts of the board. How can you balance your strategic focus to ensure a well-rounded approach that also addresses other crucial areas of the board?',\n",
    " 'rationale': \"The player's recommended orders show a focus on supporting AUSTRIA's military build-up in the Balkans, which is a crucial step in their overall strategy. However, there might be an oversight in considering how AUSTRIA's moves affect the overall board dynamics and potential opportunities or risks for other players.\",\n",
    " 'belief_state': \"The player's strategy appears to focus on building up their forces in the Balkans without considering potential threats or opportunities on other fronts. This might lead to an imbalance in their strategy.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f7a24d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: results_sft_deli_multiturn_rogue_cleaned_checkpoint-3000.pkl (SFT_multiturn)\n",
      "Successfully loaded: results_DELI_faaf_weights_checkpoint-2000.pkl (FAAF)\n",
      "Successfully loaded: results_DELI_dpo_weights_checkpoint-3500.pkl (DPO)\n",
      "Successfully loaded: results_DELI_ipo_weights_checkpoint-4500.pkl (IPO)\n",
      "Successfully loaded: results_DELI_sft_weights_checkpoint-small-1500.pkl (SFT)\n",
      "Successfully loaded: results_DELI_ppo_weights_ppo_checkpoint_epoch_1_batch_800.pkl (PPO)\n",
      "\n",
      "Combined data saved to: /s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations/combined_results.pkl\n",
      "Total items in combined file: 6\n",
      "\n",
      "Summary of combined data:\n",
      "  SFT_multiturn: 1 items\n",
      "  FAAF: 1 items\n",
      "  DPO: 1 items\n",
      "  IPO: 1 items\n",
      "  SFT: 1 items\n",
      "  PPO: 1 items\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List of files to load\n",
    "files = [\n",
    "    \"/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations/results_sft_deli_multiturn_rogue_cleaned_checkpoint-3000.pkl\",\n",
    "    \"/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations/results_DELI_faaf_weights_checkpoint-2000.pkl\",\n",
    "    \"/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations/results_DELI_dpo_weights_checkpoint-3500.pkl\",\n",
    "    \"/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations/results_DELI_ipo_weights_checkpoint-4500.pkl\",\n",
    "    \"/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations/results_DELI_sft_weights_checkpoint-small-1500.pkl\",\n",
    "    \"/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations/results_DELI_ppo_weights_ppo_checkpoint_epoch_1_batch_800.pkl\"\n",
    "]\n",
    "\n",
    "# Dictionary to store the data from each file along with metadata\n",
    "all_data = []\n",
    "\n",
    "# Load each file and store the data\n",
    "for file_path in files:\n",
    "    try:\n",
    "        # Get file metadata\n",
    "        file_name = os.path.basename(file_path)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        file_modified = os.path.getmtime(file_path)\n",
    "        \n",
    "        # Load the pickle file\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Extract the model type from the filename\n",
    "        if \"sft_deli_multiturn\" in file_name:\n",
    "            model_type = \"SFT_multiturn\"\n",
    "        elif \"faaf_weights\" in file_name:\n",
    "            model_type = \"FAAF\"\n",
    "        elif \"dpo_weights\" in file_name:\n",
    "            model_type = \"DPO\"\n",
    "        elif \"ipo_weights\" in file_name:\n",
    "            model_type = \"IPO\"\n",
    "        elif \"sft_weights\" in file_name:\n",
    "            model_type = \"SFT\"\n",
    "        elif \"ppo_weights\" in file_name:\n",
    "            model_type = \"PPO\"\n",
    "        else:\n",
    "            model_type = \"Unknown\"\n",
    "        \n",
    "        # Add metadata to the data\n",
    "        if isinstance(data, dict):\n",
    "            # If data is already a dictionary, add metadata\n",
    "            metadata = {\n",
    "                'file_name': file_name,\n",
    "                'file_size': file_size,\n",
    "                'file_modified': file_modified,\n",
    "                'model_type': model_type\n",
    "            }\n",
    "            # Store as tuple (data, metadata)\n",
    "            all_data.append((data, metadata))\n",
    "        elif isinstance(data, list):\n",
    "            # If data is a list, convert to list of dictionaries with metadata\n",
    "            for item in data:\n",
    "                if isinstance(item, dict):\n",
    "                    item_with_meta = item.copy()\n",
    "                    item_with_meta['_file_name'] = file_name\n",
    "                    item_with_meta['_file_size'] = file_size\n",
    "                    item_with_meta['_file_modified'] = file_modified\n",
    "                    item_with_meta['_model_type'] = model_type\n",
    "                    all_data.append(item_with_meta)\n",
    "                else:\n",
    "                    # If list items aren't dictionaries, store with metadata separately\n",
    "                    all_data.append({\n",
    "                        'data': item,\n",
    "                        '_file_name': file_name,\n",
    "                        '_file_size': file_size,\n",
    "                        '_file_modified': file_modified,\n",
    "                        '_model_type': model_type\n",
    "                    })\n",
    "        else:\n",
    "            # For other data types, create a dictionary with the data and metadata\n",
    "            all_data.append({\n",
    "                'data': data,\n",
    "                '_file_name': file_name,\n",
    "                '_file_size': file_size,\n",
    "                '_file_modified': file_modified,\n",
    "                '_model_type': model_type\n",
    "            })\n",
    "            \n",
    "        print(f\"Successfully loaded: {file_name} ({model_type})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "# Save the combined data\n",
    "output_path = \"/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations/combined_results.pkl\"\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(all_data, f)\n",
    "\n",
    "print(f\"\\nCombined data saved to: {output_path}\")\n",
    "print(f\"Total items in combined file: {len(all_data)}\")\n",
    "\n",
    "# Create a summary of the data\n",
    "print(\"\\nSummary of combined data:\")\n",
    "model_types = {}\n",
    "for item in all_data:\n",
    "    if isinstance(item, dict) and '_model_type' in item:\n",
    "        model_type = item['_model_type']\n",
    "    elif isinstance(item, tuple) and len(item) > 1 and 'model_type' in item[1]:\n",
    "        model_type = item[1]['model_type']\n",
    "    else:\n",
    "        model_type = \"Unknown\"\n",
    "        \n",
    "    if model_type not in model_types:\n",
    "        model_types[model_type] = 0\n",
    "    model_types[model_type] += 1\n",
    "\n",
    "for model_type, count in model_types.items():\n",
    "    print(f\"  {model_type}: {count} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7e23373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_level': 'Prompt_level1', 'raw_prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n        **Recommended Orders:**  \\n        A ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n        **Advice Request:**  \\n        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \", 'generated_text': ' <rationale> The player\\'s recommended orders show a focus on supporting AUSTRIA\\'s military build-up in the Balkans, which is a crucial step in their overall strategy. However, there might be an oversight in considering how AUSTRIA\\'s moves affect the overall board dynamics and potential opportunities or risks for other players. </rationale>          <belief_state> The player\\'s strategy appears to focus on building up their forces in the Balkans without considering potential threats or opportunities on other fronts. This might lead to an imbalance in their strategy. </belief_state>          <friction> Friction Intervention: \"Consider the potential risks of building up in the Balkans while neglecting other parts of the board. How can you balance your strategic focus to ensure a well-rounded approach that also addresses other crucial areas of the board?\" </friction>', 'parsed_components': {'friction': 'Friction Intervention: \"Consider the potential risks of building up in the Balkans while neglecting other parts of the board. How can you balance your strategic focus to ensure a well-rounded approach that also addresses other crucial areas of the board?', 'rationale': \"The player's recommended orders show a focus on supporting AUSTRIA's military build-up in the Balkans, which is a crucial step in their overall strategy. However, there might be an oversight in considering how AUSTRIA's moves affect the overall board dynamics and potential opportunities or risks for other players.\", 'belief_state': \"The player's strategy appears to focus on building up their forces in the Balkans without considering potential threats or opportunities on other fronts. This might lead to an imbalance in their strategy.\"}}\n"
     ]
    }
   ],
   "source": [
    "print(results[0][0]['samples'][0]['prompt_results'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca31c44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== RANDOM SAMPLE RESULTS ====\n",
      "\n",
      "Total samples collected: 3000\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 1 (Model: PPO)\n",
      "================================================================================\n",
      "\n",
      "PROMPT LEVEL: Prompt_level2\n",
      "----------------------------------------\n",
      "RAW PROMPT:\n",
      "----------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
      "        1. The current board state.\n",
      "        2. The recommended orders for the player.\n",
      "        3. The potential orders for every power.\n",
      "        \n",
      "\n",
      "        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\n",
      "\n",
      "        <belief_state>\n",
      "        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\n",
      "        </belief_state>\n",
      "\n",
      "        <rationale>\n",
      "        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\n",
      "        </rationale>\n",
      "\n",
      "        <friction>\n",
      "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\n",
      "        </friction>\n",
      "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
      "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "        **Board State:**  \n",
      "        AUSTRIA: \n",
      "ENGLAND: A BEL, F NTH, F SWE, F NWG, F EDI\n",
      "FRANCE: F SPA, A MAR, A BUR, A PIE, A GAS\n",
      "GERMANY: A TYR, F BAL, A MUN, F SKA, A LVN\n",
      "ITALY: A TRI, A VEN, F WES, F TYS, F TUN\n",
      "RUSSIA: F BLA, A STP, F NWY, A GAL, F BOT, A WAR, A VIE\n",
      "TURKEY: A SER, F EAS, A BUL, F GRE, A CON, F AEG\n",
      "\n",
      "        **Recommended Orders for TURKEY:**  \n",
      "        F AEG S F EAS - ION,\n",
      "F EAS - ION,\n",
      "F GRE S F EAS - ION,\n",
      "A SER - TRI,\n",
      "A BUL - SER,\n",
      "A CON - BUL\n",
      "\n",
      "        **Potential Orders for other powers:**\n",
      "        AUSTRIA: \n",
      "ENGLAND: F EDI - NTH, F NTH - NWY, F NWG S F NTH - NWY, A BEL H, F SWE S F NTH - NWY\n",
      "FRANCE: A BUR - MAR, A GAS - SPA, F SPA/SC - MAO, A MAR - PIE, A PIE - VEN\n",
      "GERMANY: F SKA S F NWG - NWY, F BAL S F SWE, A MUN - SIL, A LVN - STP, A TYR S A PIE - VEN\n",
      "ITALY: F WES - SPA/SC, F TUN - ION, F TYS S F TUN - ION, A VEN S A TRI, A TRI S A VEN\n",
      "RUSSIA: F NWY - SWE, A STP - MOS, F BOT S F NWY - SWE, A WAR - MOS, A GAL - BUD, A VIE S A SER - TRI, F BLA H\n",
      "\n",
      "        **Advice Request:**  \n",
      "        You are advising the player controlling TURKEY. Identify potential friction points and provide constructive intervention.\n",
      "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "        \n",
      "----------------------------------------\n",
      "\n",
      "FRICTION:\n",
      "----------------------------------------\n",
      "How does the alignment with Belgium on supporting Italy impact Turkey's current goals? Should we reassess our strategy?\n",
      "----------------------------------------\n",
      "\n",
      "RATIONALE:\n",
      "----------------------------------------\n",
      ": This question prompts reflection on how Belgium's actions could affect the broader strategy, allowing for strategic alignment or adjustment.\n",
      "----------------------------------------\n",
      "\n",
      "BELIEF_STATE:\n",
      "----------------------------------------\n",
      "Belgium's turn may have implications for Turkey’s strategy. If Belgium focuses on supporting Italy, it may undermine Turkey's approach towards Austria.Should Turkey prioritize supporting Austria to align with the others' strategy or focus on its own goals?\n",
      "----------------------------------------\n",
      "\n",
      "GENERATED TEXT:\n",
      "----------------------------------------\n",
      " <b>Belgium's turn may have implications for Turkey’s strategy. If Belgium focuses on supporting Italy, it may undermine Turkey's approach towards Austria.Should Turkey prioritize supporting Austria to align with the others' strategy or focus on its own goals? </b>\n",
      "          <rationale>: This question prompts reflection on how Belgium's actions could affect the broader strategy, allowing for strategic alignment or adjustment. </rationale>\n",
      "          <friction> How does the alignment with Belgium on supporting Italy impact Turkey's current goals? Should we reassess our strategy? </friction>\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 2 (Model: DPO)\n",
      "================================================================================\n",
      "\n",
      "PROMPT LEVEL: Prompt_level2\n",
      "----------------------------------------\n",
      "RAW PROMPT:\n",
      "----------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
      "        1. The current board state.\n",
      "        2. The recommended orders for the player.\n",
      "        3. The potential orders for every power.\n",
      "        \n",
      "\n",
      "        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\n",
      "\n",
      "        <belief_state>\n",
      "        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\n",
      "        </belief_state>\n",
      "\n",
      "        <rationale>\n",
      "        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\n",
      "        </rationale>\n",
      "\n",
      "        <friction>\n",
      "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\n",
      "        </friction>\n",
      "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
      "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "        **Board State:**  \n",
      "        AUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\n",
      "ENGLAND: F ENG, F NWY, A PIC, F NWG\n",
      "FRANCE: F BRE\n",
      "GERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\n",
      "ITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\n",
      "RUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\n",
      "TURKEY:\n",
      "\n",
      "        **Recommended Orders for GERMANY:**  \n",
      "        F NTH C A HOL - YOR,\n",
      "F BEL S F NTH,\n",
      "F HEL S F NTH,\n",
      "A HOL - YOR VIA,\n",
      "A BUR S A PAR,\n",
      "A PAR S F BRE,\n",
      "A MUN S A BUR\n",
      "\n",
      "        **Potential Orders for other powers:**\n",
      "        AUSTRIA: A ARM S A RUM - SEV, F BLA S A RUM - SEV, A RUM - SEV, A BUD - GAL, A SER S A BUL - RUM, A BUL - RUM\n",
      "ENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\n",
      "FRANCE: F BRE - MAO\n",
      "ITALY: F NAO C A GAS - LVP, F MAO C A GAS - LVP, A GAS - LVP VIA, F SPA/SC - POR, A MAR H, F TYS - WES, A TYR - BOH, A VIE S A TYR - BOH, F AEG S A SMY, A SMY H\n",
      "RUSSIA: A MOS S A SEV, A BOH S A GAL, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH\n",
      "TURKEY:\n",
      "\n",
      "        **Advice Request:**  \n",
      "        You are advising the player controlling GERMANY. Identify potential friction points and provide constructive intervention.\n",
      "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "        \n",
      "----------------------------------------\n",
      "\n",
      "FRICTION:\n",
      "----------------------------------------\n",
      "It seems that Germany's focus on the North Sea may be creating a narrow focus, potentially overlooking other important opportunities and threats. What if you were to allocate some of your resources to securing your western border and preparing for potential threats from Russia and Austria, rather than solely focusing on the North Sea?\n",
      "----------------------------------------\n",
      "\n",
      "RATIONALE:\n",
      "----------------------------------------\n",
      "A thorough analysis of the board state and potential orders from other powers reveals that Germany's strategy may be misaligned with the current situation. For example, Austria's potential moves suggest that they may be preparing to attack Russia, which could leave Germany exposed in the North Sea. Moreover, France's potential orders indicate that they may be planning to focus on the Mediterranean, which could create an opportunity for Italy to expand their influence in the region. Furthermore, Russia's potential moves suggest that they may be preparing to attack Austria, which could create a significant threat to Germany's western border. By not accounting for these potential reactions, Germany's strategy may be vulnerable to disruption and compromise.\n",
      "----------------------------------------\n",
      "\n",
      "BELIEF_STATE:\n",
      "----------------------------------------\n",
      "Based on the recommended orders, it appears that Germany is planning to focus on building a strong presence in the North Sea, supporting Austria's potential attacks on Russia, and securing the French border. However, this strategy may overlook potential threats from other powers and create opportunities for others to gain an advantage. Additionally, the recommended orders do not account for the potential reactions of other powers, which could lead to unintended consequences.\n",
      "----------------------------------------\n",
      "\n",
      "GENERATED TEXT:\n",
      "----------------------------------------\n",
      " <belief_state>          Based on the recommended orders, it appears that Germany is planning to focus on building a strong presence in the North Sea, supporting Austria's potential attacks on Russia, and securing the French border. However, this strategy may overlook potential threats from other powers and create opportunities for others to gain an advantage. Additionally, the recommended orders do not account for the potential reactions of other powers, which could lead to unintended consequences.          </belief_state>          <rationale>          A thorough analysis of the board state and potential orders from other powers reveals that Germany's strategy may be misaligned with the current situation. For example, Austria's potential moves suggest that they may be preparing to attack Russia, which could leave Germany exposed in the North Sea. Moreover, France's potential orders indicate that they may be planning to focus on the Mediterranean, which could create an opportunity for Italy to expand their influence in the region. Furthermore, Russia's potential moves suggest that they may be preparing to attack Austria, which could create a significant threat to Germany's western border. By not accounting for these potential reactions, Germany's strategy may be vulnerable to disruption and compromise.          </rationale>          <friction>          It seems that Germany's focus on the North Sea may be creating a narrow focus, potentially overlooking other important opportunities and threats. What if you were to allocate some of your resources to securing your western border and preparing for potential threats from Russia and Austria, rather than solely focusing on the North Sea?\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 3 (Model: SFT_multiturn)\n",
      "================================================================================\n",
      "\n",
      "PROMPT LEVEL: Prompt_level1\n",
      "----------------------------------------\n",
      "RAW PROMPT:\n",
      "----------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
      "        1. The current board state.\n",
      "        2. The recommended orders for the player.\n",
      "\n",
      "        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\n",
      "\n",
      "        <belief_state>\n",
      "        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\n",
      "        </belief_state>\n",
      "\n",
      "        <rationale>\n",
      "        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\n",
      "        </rationale>\n",
      "\n",
      "        <friction>\n",
      "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\n",
      "        </friction>\n",
      "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
      "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "        **Board State:**  \n",
      "        AUSTRIA: A SER, A BUD, F GRE, F TRI, A VIE\n",
      "ENGLAND: F NTH, F NWY, A BEL, A EDI, F LON\n",
      "FRANCE: F MAO, A SPA, A POR, F BRE, A PAR\n",
      "GERMANY: F DEN, A RUH, A HOL, A MUN, F KIE\n",
      "ITALY: F ION, A PIE, A TUN, F NAP\n",
      "RUSSIA: F FIN, F BLA, A WAR\n",
      "TURKEY: A BUL, A SEV, F CON, A SMY, F ANK\n",
      "\n",
      "        **Recommended Orders:**  \n",
      "        F DEN - SWE,\n",
      "A HOL H,\n",
      "A RUH S A HOL,\n",
      "F KIE - BAL,\n",
      "A MUN - KIE\n",
      "\n",
      "        **Advice Request:**  \n",
      "        You are advising the player controlling GERMANY. Identify potential friction points and provide constructive intervention.\n",
      "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "        \n",
      "----------------------------------------\n",
      "\n",
      "FRICTION:\n",
      "----------------------------------------\n",
      "<rationale> The current recommended orders from the GERMANY player seem to focus solely on supporting GERMANY, while neglecting potential threats from other powers. The player should consider the possibility of England potentially moving to the Baltic Sea and how this might affect their plans. The focus solely on the north does not account for the potential risk of England's movement and may leave Germany vulnerable. </rationale>\n",
      "----------------------------------------\n",
      "\n",
      "RATIONALE:\n",
      "----------------------------------------\n",
      "The current recommended orders from the GERMANY player seem to focus solely on supporting GERMANY, while neglecting potential threats from other powers. The player should consider the possibility of England potentially moving to the Baltic Sea and how this might affect their plans. The focus solely on the north does not account for the potential risk of England's movement and may leave Germany vulnerable.\n",
      "----------------------------------------\n",
      "\n",
      "BELIEF_STATE:\n",
      "----------------------------------------\n",
      "<rationale> The current recommended orders from the GERMANY player seem to focus solely on supporting GERMANY, while neglecting potential threats from other powers. The player should consider the possibility of England potentially moving to the Baltic Sea and how this might affect their plans. The focus solely on the north does not account for the potential risk of England's movement and may leave Germany vulnerable. </rationale>\n",
      "----------------------------------------\n",
      "\n",
      "GENERATED TEXT:\n",
      "----------------------------------------\n",
      " <rationale> The current recommended orders from the GERMANY player seem to focus solely on supporting GERMANY, while neglecting potential threats from other powers. The player should consider the possibility of England potentially moving to the Baltic Sea and how this might affect their plans. The focus solely on the north does not account for the potential risk of England's movement and may leave Germany vulnerable. </rationale>\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 4 (Model: SFT_multiturn)\n",
      "================================================================================\n",
      "\n",
      "PROMPT LEVEL: Prompt_level3\n",
      "----------------------------------------\n",
      "RAW PROMPT:\n",
      "----------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
      "        1. The current board state.\n",
      "        2. The recommended orders for the player.\n",
      "        3. The potential orders for every power.\n",
      "        4. The message history between the player and other players.\n",
      "\n",
      "        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\n",
      "\n",
      "        <belief_state>\n",
      "        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\n",
      "        </belief_state>\n",
      "\n",
      "        <rationale>\n",
      "        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\n",
      "        </rationale>\n",
      "\n",
      "        <friction>\n",
      "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\n",
      "        </friction>\n",
      "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
      "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "        **Board State:**  \n",
      "        AUSTRIA: A BUD, F GRE, F ALB, A BUL, A GAL\n",
      "ENGLAND: F NTH, F LON, A YOR, F STP, A PIC\n",
      "FRANCE: F MAO, A SPA, A POR, F BRE, A PAR\n",
      "GERMANY: A HOL, A BUR, A BEL, F SKA, F DEN\n",
      "ITALY: A PIE, A TUN, F EAS, F TYS\n",
      "RUSSIA: F SWE, A MOS\n",
      "TURKEY: A SEV, F CON, F BLA, A ARM\n",
      "\n",
      "        **Recommended Orders for ENGLAND:**  \n",
      "        A YOR - NWY VIA,\n",
      "F LON - ENG,\n",
      "F NTH C A YOR - NWY,\n",
      "A PIC - PAR,\n",
      "F STP/NC S A YOR - NWY\n",
      "\n",
      "        **Potential Orders for other powers:**\n",
      "        AUSTRIA: A GAL S A BUD - RUM, F ALB - ION, F GRE S A BUL, A BUD - RUM, A BUL S A BUD - RUM\n",
      "FRANCE: F BRE - ENG, F MAO - WES, A PAR - BUR, A POR - SPA, A SPA - MAR\n",
      "GERMANY: A BEL S A HOL, F DEN S F SKA - SWE, A HOL S A BEL, F SKA - SWE, A BUR - PAR\n",
      "ITALY: A TUN H, F TYS - LYO, A PIE - MAR, F EAS - SMY\n",
      "RUSSIA: F SWE H, A MOS H\n",
      "TURKEY: A SEV - RUM, A ARM - SMY, F BLA - BUL/EC, F CON S F BLA - BUL\n",
      "\n",
      "        **Message History:**\n",
      "        Message from ITALY: How’d talks with Germany go?\n",
      "Message from ENGLAND: Well he sounds committed to supporting you into Marseilles. I asked him to support me into Paris and he said no. It seems there was a discord glitch which is why he stabbed.\n",
      "Message from ITALY: Ugh sometimes my messages aren’t going through bc it says I haven’t pressed thumbs up.  Hasn’t happened to anything big yet but I see it.\n",
      "Message from ITALY: So what’re you going to do with that army?\n",
      "Message from ENGLAND: I’m still nervous about him. I asked him to take Sweden and he hasn’t answered yet. I won’t interfere with you taking Marseilles, don’t worry.\n",
      "Message from ITALY: Well it would be much more a sure thing if you could attack Paris\n",
      "\n",
      "        **Advice Request:**  \n",
      "        You are advising the player controlling ENGLAND. Identify potential friction points and provide constructive intervention.\n",
      "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "        \n",
      "----------------------------------------\n",
      "\n",
      "FRICTION:\n",
      "----------------------------------------\n",
      "England, what if you could see the potential benefits of attacking Paris alongside Italy? How might that strengthen your position and Italy's?\n",
      "----------------------------------------\n",
      "\n",
      "RATIONALE:\n",
      "----------------------------------------\n",
      "The England player is showing hesitation to attack Paris, which could lead to missing a critical opportunity for gaining leverage. Additionally, they are not considering other possible orders that might further their own strategy, and there is a lack of coordination with Italy's plans for Marseilles. The player is not addressing the possibility that Germany might still support Italy, which could impact their own chances of winning. The conversation about discord glitches and thumbs up indicates a distraction from the main issue at hand, suggesting a lack of focus.\n",
      "----------------------------------------\n",
      "\n",
      "BELIEF_STATE:\n",
      "----------------------------------------\n",
      "<rationale> The England player is showing hesitation to attack Paris, which could lead to missing a critical opportunity for gaining leverage. Additionally, they are not considering other possible orders that might further their own strategy, and there is a lack of coordination with Italy's plans for Marseilles. The player is not addressing the possibility that Germany might still support Italy, which could impact their own chances of winning. The conversation about discord glitches and thumbs up indicates a distraction from the main issue at hand, suggesting a lack of focus. </rationale>          <friction> England, what if you could see the potential benefits of attacking Paris alongside Italy? How might that strengthen your position and Italy's? </friction>\n",
      "----------------------------------------\n",
      "\n",
      "GENERATED TEXT:\n",
      "----------------------------------------\n",
      " <rationale> The England player is showing hesitation to attack Paris, which could lead to missing a critical opportunity for gaining leverage. Additionally, they are not considering other possible orders that might further their own strategy, and there is a lack of coordination with Italy's plans for Marseilles. The player is not addressing the possibility that Germany might still support Italy, which could impact their own chances of winning. The conversation about discord glitches and thumbs up indicates a distraction from the main issue at hand, suggesting a lack of focus. </rationale>          <friction> England, what if you could see the potential benefits of attacking Paris alongside Italy? How might that strengthen your position and Italy's? </friction>\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "SAMPLE 5 (Model: DPO)\n",
      "================================================================================\n",
      "\n",
      "PROMPT LEVEL: Prompt_level1\n",
      "----------------------------------------\n",
      "RAW PROMPT:\n",
      "----------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
      "        1. The current board state.\n",
      "        2. The recommended orders for the player.\n",
      "\n",
      "        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\n",
      "\n",
      "        <belief_state>\n",
      "        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\n",
      "        </belief_state>\n",
      "\n",
      "        <rationale>\n",
      "        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\n",
      "        </rationale>\n",
      "\n",
      "        <friction>\n",
      "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\n",
      "        </friction>\n",
      "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
      "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "        **Board State:**  \n",
      "        AUSTRIA: A VIE, A SER, F ION, A TRI\n",
      "ENGLAND: F NTH, A YOR, F NWY, F LON\n",
      "FRANCE: A BEL, A SPA, F POR, F BRE, F MAR, A PAR\n",
      "GERMANY: A KIE, F DEN, A MUN, F BER\n",
      "ITALY: A TYR, F TUN, A VEN, F NAP\n",
      "RUSSIA: F SEV, A UKR, F BOT, A RUM, A WAR\n",
      "TURKEY: A CON, A BUL, F BLA, F SMY\n",
      "\n",
      "        **Recommended Orders:**  \n",
      "        F ION - GRE,\n",
      "A VIE S A TRI,\n",
      "A TRI S A SER,\n",
      "A SER S F ION - GRE\n",
      "\n",
      "        **Advice Request:**  \n",
      "        You are advising the player controlling AUSTRIA. Identify potential friction points and provide constructive intervention.\n",
      "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "        \n",
      "----------------------------------------\n",
      "\n",
      "FRICTION:\n",
      "----------------------------------------\n",
      "It appears that Austria is prioritizing its southern expansion over its northern defenses. Can you think of a way to balance your efforts and build a stronger foundation in the north, potentially creating a more secure position for your army?\n",
      "----------------------------------------\n",
      "\n",
      "RATIONALE:\n",
      "----------------------------------------\n",
      "The recommended orders seem to be overly focused on the south, leaving the northern borders of Austria potentially vulnerable to German or Russian aggression. This might lead to a lack of depth in the Austrian army and make it difficult to respond to potential threats. Additionally, the recommendation to support Italy by moving the Austrian army in VIE to TRI might not provide sufficient support, as Italy's army in TYR is already positioned to support its own expansion. Instead, Austria could focus on building a stronger presence in the north to counterbalance the German and Russian forces.\n",
      "----------------------------------------\n",
      "\n",
      "BELIEF_STATE:\n",
      "----------------------------------------\n",
      "Believing that the recommended orders prioritize the Austrian army in the Balkans, focusing on supporting Italy and pressuring Serbia, the analysis reveals that this strategy might overlook the potential for building a strong foundation in the north.\n",
      "----------------------------------------\n",
      "\n",
      "GENERATED TEXT:\n",
      "----------------------------------------\n",
      " <belief_state>Believing that the recommended orders prioritize the Austrian army in the Balkans, focusing on supporting Italy and pressuring Serbia, the analysis reveals that this strategy might overlook the potential for building a strong foundation in the north.</belief_state>\n",
      "\n",
      "          <rationale>The recommended orders seem to be overly focused on the south, leaving the northern borders of Austria potentially vulnerable to German or Russian aggression. This might lead to a lack of depth in the Austrian army and make it difficult to respond to potential threats. Additionally, the recommendation to support Italy by moving the Austrian army in VIE to TRI might not provide sufficient support, as Italy's army in TYR is already positioned to support its own expansion. Instead, Austria could focus on building a stronger presence in the north to counterbalance the German and Russian forces.</rationale>\n",
      "\n",
      "          <friction>It appears that Austria is prioritizing its southern expansion over its northern defenses. Can you think of a way to balance your efforts and build a stronger foundation in the north, potentially creating a more secure position for your army?</friction>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def print_random_samples(all_data, num_samples=5):\n",
    "    print(\"==== RANDOM SAMPLE RESULTS ====\\n\")\n",
    "    \n",
    "    # Collect all samples from all files\n",
    "    all_samples = []\n",
    "    \n",
    "    for file_data in all_data:\n",
    "        # Extract the data depending on structure\n",
    "        if isinstance(file_data, tuple) and len(file_data) >= 2:\n",
    "            data, metadata = file_data[0], file_data[1]\n",
    "            model_type = metadata.get('model_type', 'Unknown')\n",
    "        else:\n",
    "            data = file_data\n",
    "            model_type = file_data.get('_model_type', 'Unknown') if isinstance(file_data, dict) else 'Unknown'\n",
    "        \n",
    "        # Try to access the samples based on different possible structures\n",
    "        samples = None\n",
    "        if isinstance(data, dict):\n",
    "            if 'samples' in data:\n",
    "                samples = data['samples']\n",
    "            elif 'results' in data and isinstance(data['results'], list):\n",
    "                samples = data['results']\n",
    "        \n",
    "        if not samples and isinstance(data, list):\n",
    "            # If the data itself is a list of samples\n",
    "            samples = data\n",
    "        \n",
    "        if samples:\n",
    "            # Add metadata to each sample\n",
    "            for sample in samples:\n",
    "                if isinstance(sample, dict):\n",
    "                    sample_with_meta = {'sample': sample, 'model_type': model_type}\n",
    "                    all_samples.append(sample_with_meta)\n",
    "    \n",
    "    print(f\"Total samples collected: {len(all_samples)}\")\n",
    "    \n",
    "    # Select random samples\n",
    "    if len(all_samples) > 0:\n",
    "        random_samples = random.sample(all_samples, min(num_samples, len(all_samples)))\n",
    "        \n",
    "        for i, sample_data in enumerate(random_samples):\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"SAMPLE {i+1} (Model: {sample_data['model_type']})\")\n",
    "            print(f\"{'='*80}\\n\")\n",
    "            \n",
    "            sample = sample_data['sample']\n",
    "            \n",
    "            # Get prompt results\n",
    "            prompt_results = None\n",
    "            if isinstance(sample, dict):\n",
    "                if 'prompt_results' in sample:\n",
    "                    prompt_results = sample['prompt_results']\n",
    "                elif 'results' in sample:\n",
    "                    prompt_results = sample['results']\n",
    "            \n",
    "            if not prompt_results and isinstance(sample, list):\n",
    "                prompt_results = sample\n",
    "            \n",
    "            if not prompt_results:\n",
    "                print(\"Could not find prompt results in this sample\")\n",
    "                continue\n",
    "            \n",
    "            # Select a random prompt result\n",
    "            if len(prompt_results) > 0:\n",
    "                result = random.choice(prompt_results)\n",
    "                \n",
    "                # Print prompt level if available\n",
    "                if isinstance(result, dict) and 'prompt_level' in result:\n",
    "                    print(f\"PROMPT LEVEL: {result['prompt_level']}\")\n",
    "                    print(\"-\" * 40)\n",
    "                \n",
    "                # Print raw prompt if available\n",
    "                if isinstance(result, dict) and 'raw_prompt' in result:\n",
    "                    print(\"RAW PROMPT:\")\n",
    "                    print(\"-\" * 40)\n",
    "                    # Split by newlines to make it more readable\n",
    "                    prompt_lines = result['raw_prompt'].split('\\n')\n",
    "                    for line in prompt_lines:\n",
    "                        print(line)\n",
    "                    print(\"-\" * 40)\n",
    "                \n",
    "                # Get parsed components\n",
    "                parsed_components = None\n",
    "                if isinstance(result, dict):\n",
    "                    if 'parsed_components' in result:\n",
    "                        parsed_components = result['parsed_components']\n",
    "                    elif 'components' in result:\n",
    "                        parsed_components = result['components']\n",
    "                \n",
    "                if not parsed_components and isinstance(result, dict):\n",
    "                    # Try to check if friction/rationale/belief are directly in the result\n",
    "                    if any(k in result for k in ['friction', 'rationale', 'belief_state']):\n",
    "                        parsed_components = result\n",
    "                \n",
    "                # Print components\n",
    "                if parsed_components:\n",
    "                    for component in ['friction', 'rationale', 'belief_state']:\n",
    "                        if component in parsed_components:\n",
    "                            print(f\"\\n{component.upper()}:\")\n",
    "                            print(\"-\" * 40)\n",
    "                            value = parsed_components[component]\n",
    "                            if isinstance(value, str):\n",
    "                                # Split by newlines to make it more readable\n",
    "                                component_lines = value.split('\\n')\n",
    "                                for line in component_lines:\n",
    "                                    print(line)\n",
    "                            else:\n",
    "                                print(f\"(Not a string: {type(value)})\")\n",
    "                            print(\"-\" * 40)\n",
    "                \n",
    "                # Print generated text\n",
    "                if isinstance(result, dict) and 'generated_text' in result:\n",
    "                    print(\"\\nGENERATED TEXT:\")\n",
    "                    print(\"-\" * 40)\n",
    "                    # Split by newlines to make it more readable\n",
    "                    text_lines = result['generated_text'].split('\\n')\n",
    "                    for line in text_lines:\n",
    "                        print(line)\n",
    "                    print(\"-\" * 40)\n",
    "    else:\n",
    "        print(\"No samples found in the data\")\n",
    "\n",
    "# Usage\n",
    "print_random_samples(results, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a724be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce914a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1663a4c",
   "metadata": {},
   "source": [
    "## RM Experiments for CVPR friction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a636a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-15 01:36:44,385] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 01:36:49.105683: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-15 01:36:49.105716: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-15 01:36:49.106763: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 01:36:50.481721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of processed prompts 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Models:   0%|                                                                                                                                                                                                 | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Model: sft_deli_multiturn_rogue_cleaned_checkpoint-3000 =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb564b69f394911bd153ccc99f62dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Prompt_level1 for sample 0\n",
      "Processing Prompt_level2 for sample 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Models:   0%|                                                                                                                                                                                                 | 0/6 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 813\u001b[0m\n\u001b[1;32m    800\u001b[0m generation_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    801\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m356\u001b[39m,\n\u001b[1;32m    802\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p_sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m }\n\u001b[1;32m    812\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiplomacy_prompts/init_generations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 813\u001b[0m results_by_model \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_models_with_formatted_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_list_deli_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 710\u001b[0m, in \u001b[0;36mprocess_models_with_formatted_prompts\u001b[0;34m(models_list, test_data, generation_args, output_dir)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# Generate responses\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m generated_texts, all_generated_texts \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_multiple_sequences_with_intrinsic_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmerged_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p_sampling\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# Process the generated text\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generated_texts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generated_texts, \u001b[38;5;28mlist\u001b[39m):\n",
      "Cell \u001b[0;32mIn[1], line 589\u001b[0m, in \u001b[0;36mgenerate_multiple_sequences_with_intrinsic_metrics\u001b[0;34m(model, tokenizer, prompts, generation_args, device, strategy, batched, reward_model, best_of_n, top_k_candidates, rm_tokenizer, rm_max_length)\u001b[0m\n\u001b[1;32m    574\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    575\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    576\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     )\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p_sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 589\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgeneration_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_return_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported strategy. Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeam_search\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k_sampling\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_p_sampling\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_of_n\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/transformers/generation/utils.py:1525\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1518\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1519\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1520\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1521\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1522\u001b[0m     )\n\u001b[1;32m   1524\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1542\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1543\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1548\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1549\u001b[0m     )\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/transformers/generation/utils.py:2622\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2619\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2622\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1183\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1180\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1183\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1070\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1061\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1062\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         use_cache,\n\u001b[1;32m   1068\u001b[0m     )\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1070\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:798\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:404\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     kv_seq_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m past_key_value\u001b[38;5;241m.\u001b[39mget_usable_length(kv_seq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_idx)\n\u001b[1;32m    403\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(value_states, seq_len\u001b[38;5;241m=\u001b[39mkv_seq_len)\n\u001b[0;32m--> 404\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos}  \u001b[38;5;66;03m# Specific to RoPE models\u001b[39;00m\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:234\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    232\u001b[0m cos \u001b[38;5;241m=\u001b[39m cos[position_ids]\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    233\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin[position_ids]\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[0;32m--> 234\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    235\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(k) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m/s/chopin/d/proj/ramfis-aida/nlg/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:208\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    206\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    207\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m :]\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx2\u001b[49m, x1), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    " \n",
    "import gc\n",
    " \n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig,PeftModel\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    ")\n",
    "# some experiments for the Llama model on safety\n",
    "import os\n",
    "import sys\n",
    "import socket\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_tags_robust(text, tags=None):\n",
    "    \"\"\"\n",
    "    Enhanced parsing function that handles XML-style tags with improved robustness \n",
    "    for Diplomacy-specific content.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to parse.\n",
    "        tags (list): List of tags to parse. If None, defaults to standard tags.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with tag names as keys and lists of extracted content as values.\n",
    "    \"\"\"\n",
    "    if tags is None:\n",
    "        tags = [\"friction\", \"rationale\", \"belief_state\"]\n",
    "    \n",
    "    # Initialize result\n",
    "    result = {tag: [] for tag in tags}\n",
    "    \n",
    "    # Tag mapping for variations\n",
    "    tag_variations = {\n",
    "        \"belief_state\": [\"belief_state\", \"belief state\", \"beliefstate\", \"belief-state\", \"b\"],\n",
    "        \"rationale\": [\"rationale\", \"rational\", \"reasoning\", \"reason\", \"r\"],\n",
    "        \"friction\": [\"friction\", \"intervention\", \"advice\", \"f\"]\n",
    "    }\n",
    "    \n",
    "    # Reverse mapping for normalization\n",
    "    tag_normalization = {}\n",
    "    for normalized, variations in tag_variations.items():\n",
    "        for variation in variations:\n",
    "            tag_normalization[variation.lower()] = normalized\n",
    "    \n",
    "    # First attempt: Try exact XML-style tags\n",
    "    for tag in tags:\n",
    "        # Try variations of the tag name\n",
    "        possible_tags = [tag]\n",
    "        if tag in tag_variations:\n",
    "            possible_tags.extend(tag_variations[tag])\n",
    "        \n",
    "        found = False\n",
    "        for tag_var in possible_tags:\n",
    "            # Try with and without underscores/hyphens\n",
    "            tag_patterns = [\n",
    "                tag_var,\n",
    "                tag_var.replace(\"_\", \" \"),\n",
    "                tag_var.replace(\"-\", \" \"),\n",
    "                tag_var.replace(\" \", \"_\"),\n",
    "                tag_var.replace(\" \", \"-\")\n",
    "            ]\n",
    "            \n",
    "            for t_pattern in tag_patterns:\n",
    "                # Match both <tag> and <tag></tag> patterns\n",
    "                open_tag_pattern = f\"<{t_pattern}>\"\n",
    "                close_tag_pattern = f\"</{t_pattern}>\"\n",
    "                open_only_pattern = re.escape(open_tag_pattern) + r\"(.*?)(?=\" + re.escape(close_tag_pattern) + r\"|\\Z)\"\n",
    "                \n",
    "                matches = re.findall(open_only_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "                if matches:\n",
    "                    result[tag].extend([m.strip() for m in matches])\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if found:\n",
    "                break\n",
    "    \n",
    "    # Second attempt: Try markdown-style headings and formatting\n",
    "    for tag in tags:\n",
    "        if not result[tag]:  # Only if we didn't find anything in first pass\n",
    "            possible_tags = [tag]\n",
    "            if tag in tag_variations:\n",
    "                possible_tags.extend(tag_variations[tag])\n",
    "            \n",
    "            for tag_var in possible_tags:\n",
    "                # Various markdown and formatting patterns\n",
    "                patterns = [\n",
    "                    # Markdown headings\n",
    "                    r'#{1,3}\\s*' + re.escape(tag_var) + r'[:\\s]*\\n(.*?)(?=\\n#|\\n\\n|\\Z)',\n",
    "                    # Bold with asterisks\n",
    "                    r'\\*\\*\\s*' + re.escape(tag_var) + r'[:\\s]*\\*\\*\\s*\\n(.*?)(?=\\n\\*\\*|\\n\\n|\\Z)',\n",
    "                    # Bold with underscores\n",
    "                    r'__\\s*' + re.escape(tag_var) + r'[:\\s]*__\\s*\\n(.*?)(?=\\n__|\\n\\n|\\Z)',\n",
    "                    # Plain text with colon\n",
    "                    r'\\b' + re.escape(tag_var) + r'[:\\s]+(.*?)(?=\\n\\n|\\Z)'\n",
    "                ]\n",
    "                \n",
    "                for pattern in patterns:\n",
    "                    matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "                    if matches:\n",
    "                        result[tag].extend([m.strip() for m in matches])\n",
    "                        break\n",
    "    \n",
    "    # Third attempt: Content-specific extraction based on sentence patterns\n",
    "    for tag in tags:\n",
    "        if not result[tag]:  # Only if we still didn't find anything\n",
    "            if tag == \"friction\" or tag in tag_variations.get(\"friction\", []):\n",
    "                # Look for sentences that suggest a friction intervention\n",
    "                question_patterns = [\n",
    "                    # Questions about strategy\n",
    "                    r'(?:Have you considered|Did you think about|What if|Could you|Why not).*?\\?',\n",
    "                    # Suggestions phrased as questions\n",
    "                    r'(?:Wouldn\\'t it be|Might it be|Isn\\'t there).*?\\?',\n",
    "                ]\n",
    "                \n",
    "                # Extract any matching sentences\n",
    "                for pattern in question_patterns:\n",
    "                    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "                    if matches:\n",
    "                        # Take the first 2 matching questions as friction\n",
    "                        combined = \" \".join(matches[:2]).strip()\n",
    "                        if combined:\n",
    "                            result[tag].append(combined)\n",
    "                            break\n",
    "    \n",
    "    # Fourth attempt: Fall back to content structure analysis\n",
    "    for tag in tags:\n",
    "        if not result[tag]:  # If still nothing found\n",
    "            # Split by double newlines to get paragraphs\n",
    "            paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "            \n",
    "            if tag == \"friction\" and paragraphs:\n",
    "                if len(paragraphs) >= 3:\n",
    "                    # Friction is often at the end\n",
    "                    result[tag].append(paragraphs[-1])\n",
    "                else:\n",
    "                    # Just use the last paragraph\n",
    "                    result[tag].append(paragraphs[-1])\n",
    "            \n",
    "            elif tag == \"rationale\" and paragraphs:\n",
    "                if len(paragraphs) >= 3:\n",
    "                    # Rationale is often in the middle\n",
    "                    result[tag].append(paragraphs[len(paragraphs)//2])\n",
    "                elif len(paragraphs) == 2:\n",
    "                    # Use first paragraph\n",
    "                    result[tag].append(paragraphs[0])\n",
    "            \n",
    "            elif tag == \"belief_state\" and paragraphs:\n",
    "                # Belief state is often at the beginning\n",
    "                result[tag].append(paragraphs[0])\n",
    "    \n",
    "    # Final cleanup - remove quotes or special formatting from content\n",
    "    for tag in result:\n",
    "        result[tag] = [\n",
    "            re.sub(r'^[\"\\']\\s*|\\s*[\"\\']$', '', item)  # Remove surrounding quotes\n",
    "            for item in result[tag]\n",
    "        ]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def handle_friction_logic(text):\n",
    "    \"\"\"\n",
    "    Extract a meaningful friction intervention from text even when proper tags are missing.\n",
    "    Improved to handle Diplomacy-specific content patterns.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted friction intervention\n",
    "    \"\"\"\n",
    "    # First check if there's already a well-formatted friction section\n",
    "    friction_match = re.search(r'<friction>(.*?)(?:</friction>|\\Z)', text, re.DOTALL | re.IGNORECASE)\n",
    "    if friction_match:\n",
    "        return friction_match.group(1).strip()\n",
    "    \n",
    "    # Look for quotes that might be friction interventions\n",
    "    quote_match = re.search(r'[\"\\'](.*?)[\"\\']', text, re.DOTALL)\n",
    "    if quote_match and (\"?\" in quote_match.group(1) or \"consider\" in quote_match.group(1).lower()):\n",
    "        return quote_match.group(1).strip()\n",
    "    \n",
    "    # Look for questions that might be friction interventions\n",
    "    questions = re.findall(r'[^.!?]*\\?', text)\n",
    "    strategic_questions = [q for q in questions if any(term in q.lower() for term in \n",
    "                                                   [\"strategy\", \"consider\", \"think\", \"reflect\", \n",
    "                                                    \"alternative\", \"option\", \"might\", \"could\", \n",
    "                                                    \"why not\", \"what if\", \"balance\"])]\n",
    "    if strategic_questions and len(strategic_questions) >= 1:\n",
    "        return \" \".join(strategic_questions[:2]).strip()\n",
    "    \n",
    "    # Look for sentences that have Diplomacy-specific strategy terms\n",
    "    strategy_terms = [\"support\", \"attack\", \"move\", \"defend\", \"ally\", \"alliance\", \"secure\", \n",
    "                      \"position\", \"flank\", \"threat\", \"opportunity\", \"risk\", \"coordinate\"]\n",
    "    \n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text.strip())\n",
    "    strategic_sentences = [s for s in sentences if any(term in s.lower() for term in strategy_terms)]\n",
    "    \n",
    "    if strategic_sentences:\n",
    "        if len(strategic_sentences) >= 2:\n",
    "            return f\"{strategic_sentences[0]} {strategic_sentences[-1]}\"\n",
    "        else:\n",
    "            return strategic_sentences[0]\n",
    "    \n",
    "    # Fall back to the original logic if nothing better is found\n",
    "    if sentences:\n",
    "        if len(sentences) >= 3:\n",
    "            return f\"{sentences[0]} {sentences[-2]} {sentences[-1]}\"\n",
    "        else:\n",
    "            return \" \".join(sentences)\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def process_diplomacy_for_friction(test_data):\n",
    "\n",
    "    processed_messages = []  # Create a list to store all processed messages\n",
    "    count = 0\n",
    "    for message in test_data:\n",
    "        count = count+1\n",
    "        sender = message['sender']\n",
    "        recipient = message['recipient']\n",
    "\n",
    "        if message['recipient'] == 'ALL' or message['recipient'] == message['sender'] or message[\"phase\"].endswith('A') or message[\"phase\"].endswith('R'):\n",
    "            continue\n",
    "        else:\n",
    "            #board states format\n",
    "            formatted_board = \"\"\n",
    "            for country, units in message['units'].items():\n",
    "                formatted_board += f\"{country}: {', '.join(units)}\\n\"\n",
    "            formatted_board = formatted_board.strip()\n",
    "            #predicted orders for opponent\n",
    "            opponent_orders = \"\"\n",
    "            for country, units in message['predicted_orders'][message['recipient']].items():\n",
    "                opponent_orders += f\"{country}: {', '.join(units)}\\n\"\n",
    "            formatted_opponent_orders = opponent_orders.strip()\n",
    "            #message history\n",
    "            message_history = \"\"\n",
    "            start_index = max(0, len(message['prev_5_message']) - 5)\n",
    "            for msg_info in message['prev_5_message'][start_index:]:\n",
    "                sender = msg_info['sender']\n",
    "                text = msg_info['message']\n",
    "                message_history += f\"Message from {sender}: {text}\\n\"\n",
    "            message_history += f\"Message from {message['sender']}: {message['message']}\"\n",
    "            #recommended orders for myself.\n",
    "            recommended_orders = message['predicted_orders'][message['sender']][message['recipient']]\n",
    "            formatted_recommended_orders = \",\\n\".join(recommended_orders)\n",
    "\n",
    "                # Modify the prompts for friction interventions\n",
    "            Prompt_level1 = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
    "        1. The current board state.\n",
    "        2. The recommended orders for the player.\n",
    "\n",
    "        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\n",
    "\n",
    "        <belief_state>\n",
    "        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state.\n",
    "        </belief_state>\n",
    "\n",
    "        <rationale>\n",
    "        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\n",
    "        </rationale>\n",
    "\n",
    "        <friction>\n",
    "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\n",
    "        </friction>\n",
    "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        **Board State:**  \n",
    "        {formatted_board}\n",
    "\n",
    "        **Recommended Orders:**  \n",
    "        {formatted_recommended_orders}\n",
    "\n",
    "        **Advice Request:**  \n",
    "        You are advising the player controlling {message['recipient']}. Identify potential friction points and provide constructive intervention.\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "\n",
    "            Prompt_level2 = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
    "        1. The current board state.\n",
    "        2. The recommended orders for the player.\n",
    "        3. The potential orders for every power.\n",
    "        \n",
    "\n",
    "        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\n",
    "\n",
    "        <belief_state>\n",
    "        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\n",
    "        </belief_state>\n",
    "\n",
    "        <rationale>\n",
    "        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\n",
    "        </rationale>\n",
    "\n",
    "        <friction>\n",
    "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\n",
    "        </friction>\n",
    "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        **Board State:**  \n",
    "        {formatted_board}\n",
    "\n",
    "        **Recommended Orders for {message['recipient']}:**  \n",
    "        {formatted_recommended_orders}\n",
    "\n",
    "        **Potential Orders for other powers:**\n",
    "        {formatted_opponent_orders}\n",
    "\n",
    "        **Advice Request:**  \n",
    "        You are advising the player controlling {message['recipient']}. Identify potential friction points and provide constructive intervention.\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "\n",
    "            Prompt_level3 = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
    "        1. The current board state.\n",
    "        2. The recommended orders for the player.\n",
    "        3. The potential orders for every power.\n",
    "        4. The message history between the player and other players.\n",
    "\n",
    "        Your goal is to identify potential friction points in the player's strategy and diplomatic approach, then provide a constructive intervention:\n",
    "\n",
    "        <belief_state>\n",
    "        Identify contradictions, oversights, or misalignments in the recommended orders compared to the board state, other powers' likely moves, and diplomatic communications.\n",
    "        </belief_state>\n",
    "\n",
    "        <rationale>\n",
    "        Explain why an intervention is needed—what's misaligned in strategy or diplomacy, its potential impact, and how alternative thinking could benefit the player.\n",
    "        </rationale>\n",
    "\n",
    "        <friction>\n",
    "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy or diplomatic approach. The first sentence should directly address the concern, and the second should offer a reflective question or alternative perspective.\n",
    "        </friction>\n",
    "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        **Board State:**  \n",
    "        {formatted_board}\n",
    "\n",
    "        **Recommended Orders for {message['recipient']}:**  \n",
    "        {formatted_recommended_orders}\n",
    "\n",
    "        **Potential Orders for other powers:**\n",
    "        {formatted_opponent_orders}\n",
    "\n",
    "        **Message History:**\n",
    "        {message_history}\n",
    "\n",
    "        **Advice Request:**  \n",
    "        You are advising the player controlling {message['recipient']}. Identify potential friction points and provide constructive intervention.\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "            \n",
    "            processed_message = message.copy()\n",
    "         # Add the prompts to the copied message\n",
    "            processed_message['Prompt_level1'] = Prompt_level1\n",
    "            processed_message['Prompt_level2'] = Prompt_level2\n",
    "            processed_message['Prompt_level3'] = Prompt_level3\n",
    "             # Add this processed message to our list\n",
    "            processed_messages.append(processed_message)\n",
    "\n",
    "    return processed_messages\n",
    "\n",
    "def generate_multiple_sequences_with_intrinsic_metrics(model, tokenizer, prompts, generation_args, device, \n",
    "                                                       strategy=\"beam_search\", batched=False, \n",
    "                                                       reward_model=None, best_of_n=None, top_k_candidates=1, rm_tokenizer = None\n",
    "                                                      , rm_max_length = None):\n",
    "    \"\"\"\n",
    "    Generate multiple sequences using various strategies including best-of-N sampling.\n",
    "    \n",
    "    Args:\n",
    "        model: Language model for generation\n",
    "        tokenizer: Tokenizer for the model\n",
    "        prompts: Input prompts\n",
    "        generation_args: Arguments for generation\n",
    "        device: Device to place tensors on\n",
    "        strategy: Generation strategy (\"beam_search\", \"top_k_sampling\", \"top_p_sampling\", or \"best_of_n\")\n",
    "        batched: Whether inputs are batched\n",
    "        reward_model: Reward model for scoring in best-of-N sampling (AutoModelForSequenceClassification)\n",
    "        best_of_n: Number of samples to generate for best-of-N sampling (default: None)\n",
    "        top_k_candidates: Number of top candidates to return from best-of-N sampling (default: 1)\n",
    "        \n",
    "    Returns:\n",
    "        generated_texts: List of generated texts\n",
    "        all_generated_texts: List of all generated texts\n",
    "    \"\"\"\n",
    "    if batched:\n",
    "        tokenizer.pad_token = \"<|reserved_special_token_0|>\"  # new pad token for this run\n",
    "        tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "        tokenizer.padding_side = 'right'\n",
    "\n",
    "        cleaned_prompts = prompts.replace(\"\\n\", \" \")  \n",
    "        inputs = tokenizer(cleaned_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    else:\n",
    "        tokenizer.pad_token = \"<|reserved_special_token_0|>\"  # new pad token for this run\n",
    "        tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "        tokenizer.padding_side = 'right'\n",
    "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    # Handle best-of-N sampling strategy\n",
    "    if strategy == \"best_of_n\":\n",
    "        if reward_model is None:\n",
    "            raise ValueError(\"Reward model must be provided for best-of-N sampling\")\n",
    "        \n",
    "        if best_of_n is None or best_of_n <= 0:\n",
    "            best_of_n = 4  # Default sample size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Generate multiple candidates for each prompt\n",
    "            all_candidates = []\n",
    "            all_prompt_candidates = []\n",
    "            \n",
    "            # Use top_p or top_k sampling to generate diverse candidates\n",
    "            sampling_strategy = generation_args.get(\"sampling_strategy\", \"top_p_sampling\")\n",
    "            # print(\"BON sampling strategy\", sampling_strategy)\n",
    "            for _ in range(best_of_n):\n",
    "                if sampling_strategy == \"top_p_sampling\": \n",
    "                    print(\"RUNNING TopP sampling for BON\")\n",
    "                    outputs = model.generate(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                        temperature=generation_args.get(\"temperature\", 0.7),\n",
    "                        top_p=generation_args.get(\"top_p\", 0.9),\n",
    "                        do_sample=True,\n",
    "                        num_return_sequences=1,\n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        pad_token_id=tokenizer.pad_token_id,\n",
    "                        return_dict_in_generate=True,\n",
    "                    )\n",
    "                else:  # Default to top_k_sampling\n",
    "                    outputs = model.generate(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                        temperature=generation_args.get(\"temperature\", 0.7),\n",
    "                        top_k=generation_args.get(\"top_k\", 50),\n",
    "                        do_sample=True,\n",
    "                        num_return_sequences=1,\n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        pad_token_id=tokenizer.pad_token_id,\n",
    "                        return_dict_in_generate=True,\n",
    "                    )\n",
    "                \n",
    "                # Process the generated sequence\n",
    "                for i in range(len(outputs.sequences)):\n",
    "                    sequence = outputs.sequences[i]\n",
    "                    prompt_length = input_ids.shape[-1]\n",
    "                    new_tokens = sequence[prompt_length:]\n",
    "                    generated_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "                    \n",
    "                    if len(all_candidates) <= i:\n",
    "                        all_candidates.append([])\n",
    "                    \n",
    "                    all_candidates[i].append(generated_text)\n",
    "            \n",
    "            # Score candidates with the reward model\n",
    "            best_candidates = []\n",
    "            all_prompt_candidates = []\n",
    "            parsed_candidates = []\n",
    "            tags_for_parsing = [\"friction\", \"rationale\", \"t\", \"b\"]  \n",
    "            for candidate_index, candidates in enumerate(all_candidates):\n",
    "                print(f\"\\n=== Processing candidates for prompt {candidate_index} ===\")\n",
    "                print(f\"Number of candidates: {len(candidates)}\")\n",
    "\n",
    "                #parse the generated model outputs to get the friction + rationale\n",
    "\n",
    "                        \n",
    "                for candidate in candidates:\n",
    "                    parsed_frictive_states_and_friction = parse_tags_robust(candidate, tags_for_parsing)\n",
    "                    friction_intervention = ' '.join(parsed_frictive_states_and_friction.get('friction', []))\n",
    "                    if not friction_intervention:\n",
    "                        friction_intervention = handle_friction_logic(candidate)\n",
    "\n",
    "                    rationale = ' '.join(parsed_frictive_states_and_friction.get('rationale', []))\n",
    "                    friction_and_rationale = rationale + friction_intervention\n",
    "                    parsed_candidates.append(friction_and_rationale)\n",
    "                    # print(\"PARSED friction + rationale\",friction_and_rationale )\n",
    "                # For each candidate, prepare input for reward model\n",
    "                candidate_inputs = [prompts + \" \" + f\"</s> {candidate} </s>\" for candidate in parsed_candidates]\n",
    "                tokenized_inputs = rm_tokenizer(candidate_inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=rm_max_length).to(device)\n",
    "                \n",
    "                # Get scores from reward model\n",
    "                reward_outputs = reward_model(**tokenized_inputs) \n",
    "                scores = reward_outputs.logits.squeeze(-1)\n",
    "                \n",
    "                ## Print all candidates with their scores\n",
    "                print(\"\\nAll candidates with scores:\")\n",
    "                for i, (candidate, score) in enumerate(zip(candidates, scores)):\n",
    "                    print(f\"Candidate {i}: Score = {score:.4f}\")\n",
    "                    print(f\"Text snippet: {candidate[:50]}...\")\n",
    "                \n",
    "                # Get top-k indices\n",
    "                if top_k_candidates > len(candidates):\n",
    "                    top_k_candidates = len(candidates)\n",
    "                \n",
    "                # Fix the error by converting bfloat16 to float32 before calling numpy()\n",
    "                top_result = torch.topk(scores, top_k_candidates)\n",
    "                top_indices = top_result.indices.cpu().numpy()\n",
    "                top_values = top_result.values.cpu().float().numpy()  # Convert to float32 first\n",
    "                \n",
    "                print(f\"\\nTop {top_k_candidates} candidates:\")\n",
    "                # Print only the top-k candidates\n",
    "                for rank, (idx, score) in enumerate(zip(top_indices, top_values)):\n",
    "                    print(f\"Rank {rank+1}: Candidate {idx} with score {score:.4f}\")\n",
    "                    print(f\"Text: {candidates[idx][:300]}...\")\n",
    "                \n",
    "                # Store the chosen candidates for verification\n",
    "                prompt_best_candidates = [candidates[idx] for idx in top_indices]\n",
    "                \n",
    "                # Verification check\n",
    "                max_score_idx = scores.argmax().item()\n",
    "                if max_score_idx != top_indices[0]:\n",
    "                    print(f\"WARNING: Discrepancy detected! argmax={max_score_idx} but topk.indices[0]={top_indices[0]}\")\n",
    "                else:\n",
    "                    print(f\"VERIFIED: Top candidate is correctly selected (index {top_indices[0]})\")\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                best_candidates.append(prompt_best_candidates)\n",
    "                all_prompt_candidates.extend(candidates)\n",
    "            \n",
    "            return best_candidates, all_prompt_candidates\n",
    "    \n",
    "    # Original strategies\n",
    "    with torch.no_grad():\n",
    "        if strategy == \"beam_search\":\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                num_beams=generation_args[\"num_beams\"],\n",
    "                num_return_sequences=generation_args[\"num_return_sequences\"],\n",
    "                early_stopping=True,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "        elif strategy == \"top_k_sampling\":\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                temperature=generation_args[\"temperature\"],\n",
    "                top_k=generation_args[\"top_k\"],\n",
    "                do_sample=True,\n",
    "                num_return_sequences=generation_args[\"num_return_sequences\"],\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                min_length=generation_args.get(\"min_length\", 0),\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "        elif strategy == \"top_p_sampling\":\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=input_ids.size(1) + generation_args[\"max_new_tokens\"],\n",
    "                temperature=generation_args[\"temperature\"],\n",
    "                top_p=generation_args[\"top_p\"],\n",
    "                do_sample=True,\n",
    "                num_return_sequences=generation_args[\"num_return_sequences\"],\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                return_dict_in_generate=True,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported strategy. Use 'beam_search', 'top_k_sampling', 'top_p_sampling', or 'best_of_n'.\")\n",
    "\n",
    "    # Decode the generated tokens for each prompt in the batch\n",
    "    generated_texts = []\n",
    "    all_generated_texts = []\n",
    "\n",
    "    for i in range(0, len(outputs.sequences), generation_args[\"num_return_sequences\"]):\n",
    "        prompt_texts = []\n",
    "        prompt_only = []\n",
    "        for j in range(generation_args[\"num_return_sequences\"]):\n",
    "            sequence_index = i + j  # Global index for the current sequence\n",
    "            output = outputs.sequences[sequence_index]\n",
    "            prompt_length = input_ids.shape[-1]  # Length of the input prompt\n",
    "            new_tokens = output[prompt_length:]  # Get only the generated tokens\n",
    "            generated_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "            prompt_tokens = output[:prompt_length]\n",
    "            prompt_text = tokenizer.decode(prompt_tokens, skip_special_tokens=True)\n",
    "    \n",
    "            prompt_texts.append(generated_text)\n",
    "            prompt_only.append(prompt_text)\n",
    "\n",
    "        generated_texts.append(prompt_texts)\n",
    "        all_generated_texts.extend(prompt_only)\n",
    "    \n",
    "    return generated_texts, all_generated_texts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_models_with_formatted_prompts(models_list, test_data, generation_args, output_dir = None):\n",
    "    \"\"\"\n",
    "    Process formatted Diplomacy prompts with multiple models.\n",
    "    \n",
    "    Args:\n",
    "        models_list: List of model paths to process\n",
    "        generation_args: Arguments for text generation\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # First, create the formatted prompts\n",
    "    processed_data = process_diplomacy_for_friction(test_data)\n",
    "    print(\"length of processed prompts\", len(processed_data))\n",
    "    \n",
    "    results_by_model = {}\n",
    "    \n",
    "    for agent_model_name in tqdm(models_list, desc=\"Processing Models\"):\n",
    "        # Format model name for results\n",
    "        loading_model_name = agent_model_name\n",
    "        if \"/\" in agent_model_name:\n",
    "            parts = agent_model_name.split(\"/\")\n",
    "            if len(parts) >= 3:\n",
    "                agent_model_name = parts[1] + \"_\" + parts[2]\n",
    "            elif len(parts) == 2:\n",
    "                agent_model_name = parts[0] + \"_\" + parts[1]\n",
    "        \n",
    "        print(f\"\\n===== Processing Model: {agent_model_name} =====\\n\")\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        try:\n",
    "            # Load base model\n",
    "            lora_model = AutoModelForCausalLM.from_pretrained(\n",
    "                \"llama3_8b_instruct\",\n",
    "                device_map=\"auto\",\n",
    "                low_cpu_mem_usage=True,\n",
    "                torch_dtype=torch.float16,\n",
    "                trust_remote_code=True,\n",
    "            )\n",
    "            \n",
    "            # Apply LoRA adapter\n",
    "            lora_model = PeftModel.from_pretrained(\n",
    "                lora_model,\n",
    "                loading_model_name,\n",
    "                torch_dtype=torch.float16,\n",
    "                device_map=\"auto\",\n",
    "                low_cpu_mem_usage=True,\n",
    "                trust_remote_code=True,\n",
    "            )\n",
    "            \n",
    "            # Merge the model\n",
    "            print(\"Merging LoRA adapter...\")\n",
    "            merged_model = lora_model.merge_and_unload()\n",
    "            \n",
    "            # Load tokenizer\n",
    "            tokenizer = AutoTokenizer.from_pretrained(loading_model_name)\n",
    "            tokenizer.pad_token = \"<|reserved_special_token_0|>\"\n",
    "            tokenizer.padding_side = \"right\"\n",
    "            \n",
    "            # Initialize results for this model\n",
    "            model_results = {\n",
    "                \"model_name\": agent_model_name,\n",
    "                \"samples\": []\n",
    "            }\n",
    "            \n",
    "             # Process each sample\n",
    "            for sample_idx, sample in enumerate(processed_data):\n",
    "                sample_results = {\n",
    "                    \"sample_id\": sample_idx,\n",
    "                    \"message_id\": sample.get('message_id', sample_idx),\n",
    "                    \"sender\": sample.get('sender', ''),\n",
    "                    \"recipient\": sample.get('recipient', ''),\n",
    "                    \"prompt_results\": []\n",
    "                }\n",
    "                # Process each prompt level\n",
    "                \n",
    "                for level_key in ['Prompt_level1', 'Prompt_level2', 'Prompt_level3']:\n",
    "                    if level_key in sample:\n",
    "                        print(f\"Processing {level_key} for sample {sample_idx}\")\n",
    "                        \n",
    "                        # Generate responses\n",
    "                        generated_texts, all_generated_texts = generate_multiple_sequences_with_intrinsic_metrics(\n",
    "                            merged_model, \n",
    "                            tokenizer, \n",
    "                            sample[level_key], \n",
    "                            generation_args, \n",
    "                            None,\n",
    "                            strategy=\"top_p_sampling\", \n",
    "                            batched=True, \n",
    "                        )\n",
    "                        \n",
    "                        # Process the generated text\n",
    "                        if generated_texts and isinstance(generated_texts, list):\n",
    "                            text_to_parse = generated_texts[0][0] if (generated_texts[0] and isinstance(generated_texts[0], list)) else generated_texts[0]\n",
    "                            \n",
    "                            # Parse components\n",
    "                            tags_for_parsing = [\"friction\", \"rationale\", \"belief_state\"]\n",
    "                            parsed_components = parse_tags_robust(text_to_parse, tags_for_parsing)\n",
    "                            \n",
    "                            # Extract components\n",
    "                            friction_intervention = ' '.join(parsed_components.get('friction', []))\n",
    "                            if not friction_intervention:\n",
    "                                friction_intervention = handle_friction_logic(text_to_parse)\n",
    "                            \n",
    "                            belief_state = ' '.join(parsed_components.get('belief_state', []))\n",
    "                            rationale = ' '.join(parsed_components.get('rationale', []))\n",
    "                            \n",
    "                            # Save results for this prompt level\n",
    "                            prompt_result = {\n",
    "                                \"prompt_level\": level_key,\n",
    "                                \"raw_prompt\": sample[level_key],\n",
    "                                \"generated_text\": text_to_parse,\n",
    "                                \"parsed_components\": {\n",
    "                                    \"friction\": friction_intervention,\n",
    "                                    \"rationale\": rationale,\n",
    "                                    \"belief_state\": belief_state\n",
    "                                }\n",
    "                            }\n",
    "                            \n",
    "                            sample_results[\"prompt_results\"].append(prompt_result)\n",
    "                \n",
    "                # Add this sample's results to the model results\n",
    "                model_results[\"samples\"].append(sample_results)\n",
    "      \n",
    "            \n",
    "            # Save results for this model to a pickle file\n",
    "            safe_model_name = agent_model_name.replace('/', '_')\n",
    "            with open(f\"{output_dir}/results_{safe_model_name}.pkl\", 'wb') as f:\n",
    "                pickle.dump(model_results, f)\n",
    "            \n",
    "            # Also store in our overall results dictionary\n",
    "            results_by_model[agent_model_name] = model_results\n",
    "            \n",
    "            # Clean up the model to free memory\n",
    "            del merged_model, tokenizer, lora_model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing model {agent_model_name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return results_by_model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #load json raw data for diplomacy prompt construction\n",
    "    test_path = f\"diplomacy_prompts/sample_1K_denis_testdata_with_prompts.json\"\n",
    "    with open(test_path, \"r\") as file:\n",
    "        test_data = json.load(file)\n",
    "\n",
    "    # create the test prompts in friction generation format with xml tags for specific fields\n",
    "    \n",
    "    # test_prompts = process_diplomacy_for_friction(test_data[0:500]) # select the first 500 prompts to get more model samples at first. \n",
    "    models_list_deli_weights =[\n",
    "        \n",
    "\n",
    "#     'WTD_faaf_10',\n",
    " \n",
    "        'sft_deli_multiturn_rogue_cleaned/checkpoint-3000',\n",
    "    'DELI_all_weights/DELI_faaf_weights/checkpoint-2000',\n",
    " \n",
    "     'DELI_all_weights/DELI_dpo_weights/checkpoint-3500',\n",
    " \n",
    "    'DELI_all_weights/DELI_ipo_weights/checkpoint-4500',\n",
    "\n",
    "        \"DELI_all_weights/DELI_sft_weights/checkpoint-small-1500\",\n",
    "         \"DELI_all_weights/DELI_ppo_weights/ppo_checkpoint_epoch_1_batch_800\",\n",
    " \n",
    "    ]\n",
    "    #sample generation arguments -- for sampling, tokens to generate etc\n",
    "    generation_args = {\n",
    "    \"max_new_tokens\": 356,\n",
    "    \"temperature\": 0.9,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.9,\n",
    "    \"num_beams\": 5,\n",
    "    \"min_length\": 100,\n",
    "    'num_return_sequences': 1,\n",
    "    \"sampling_strategy\": \"top_p_sampling\"\n",
    "    }\n",
    "\n",
    "    output_dir = \"diplomacy_prompts/init_generations\"\n",
    "    results_by_model = process_models_with_formatted_prompts(models_list_deli_weights,test_data[0:500], generation_args, output_dir = output_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cfa6f",
   "metadata": {},
   "source": [
    "## Changes asked: instead of friction suggestion, we need to get the friction models to explain why the recommended orders were given. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c42d1087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_diplomacy_for_friction_explanations_only(test_data):\n",
    "    processed_message = {}\n",
    "    processed_messages = []  # Create a list to store all processed messages\n",
    "    count = 0\n",
    "    for message in test_data:\n",
    "        count = count+1\n",
    "        sender = message['sender']\n",
    "        recipient = message['recipient']\n",
    "\n",
    "        if message['recipient'] == 'ALL' or message['recipient'] == message['sender'] or message[\"phase\"].endswith('A') or message[\"phase\"].endswith('R'):\n",
    "            continue\n",
    "        else:\n",
    "            #board states format\n",
    "            formatted_board = \"\"\n",
    "            for country, units in message['units'].items():\n",
    "                formatted_board += f\"{country}: {', '.join(units)}\\n\"\n",
    "            formatted_board = formatted_board.strip()\n",
    "            #predicted orders for opponent\n",
    "            opponent_orders = \"\"\n",
    "            for country, units in message['predicted_orders'][message['recipient']].items():\n",
    "                opponent_orders += f\"{country}: {', '.join(units)}\\n\"\n",
    "            formatted_opponent_orders = opponent_orders.strip()\n",
    "            #message history\n",
    "            message_history = \"\"\n",
    "            start_index = max(0, len(message['prev_5_message']) - 5)\n",
    "            for msg_info in message['prev_5_message'][start_index:]:\n",
    "                sender = msg_info['sender']\n",
    "                text = msg_info['message']\n",
    "                message_history += f\"Message from {sender}: {text}\\n\"\n",
    "            message_history += f\"Message from {message['sender']}: {message['message']}\"\n",
    "            #recommended orders for myself.\n",
    "            recommended_orders = message['predicted_orders'][message['sender']][message['recipient']]\n",
    "            formatted_recommended_orders = \",\\n\".join(recommended_orders)\n",
    "\n",
    "                # Modify the prompts for friction interventions\n",
    "\n",
    "\n",
    "            Prompt_level2 = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\n",
    "        1. The current board state.\n",
    "        2. The recommended orders for the player.\n",
    "        3. The potential orders for every power.\n",
    "        \n",
    "\n",
    "        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\n",
    "\n",
    "        <belief_state>\n",
    "        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\n",
    "        </belief_state>\n",
    "\n",
    "        <rationale>\n",
    "        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\n",
    "        </rationale>\n",
    "\n",
    "        <friction>\n",
    "        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\n",
    "        </friction>\n",
    "        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
    "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "        **Board State:**  \n",
    "        {formatted_board}\n",
    "\n",
    "        **Recommended Orders for {message['recipient']}:**  \n",
    "        {formatted_recommended_orders}\n",
    "\n",
    "        **Potential Orders for other powers:**\n",
    "        {formatted_opponent_orders}\n",
    "\n",
    "        **Advice Request:**  \n",
    "        You are advising the player controlling {message['recipient']}. Identify potential friction points and provide constructive intervention.\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "            processed_message = message.copy()\n",
    "         # Add the prompts to the copied message\n",
    "      \n",
    "            processed_message['Prompt_level2'] = Prompt_level2\n",
    "  \n",
    "             # Add this processed message to our list\n",
    "            processed_messages.append(processed_message)\n",
    "\n",
    "    return processed_messages\n",
    "\n",
    "\n",
    "test_prompts_new = process_diplomacy_for_friction_explanations_only(test_data[0:1])\n",
    "\n",
    "print(test_prompts_new)\n",
    "{'Prompt_level2': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        \\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A TRI, F ALB, A SER, A BUL\\nENGLAND: A MOS, F MAO, A LVN, F ENG, A MAR, A GAS, F EDI, A BRE\\nFRANCE: A POR\\nGERMANY: A PAR, A GAL, A VIE, A BOH, F BEL, F HOL, A UKR, A WAR, A TYR, A MUN\\nITALY: F WES, A NAF, A VEN, F SPA, A PIE\\nRUSSIA: \\nTURKEY: F BLA, A RUM, A CON, F AEG\\n\\n        **Recommended Orders for GERMANY:**  \\n        F BEL H,\\nF HOL H,\\nA PAR H,\\nA MUN S A TYR,\\nA BOH S A VIE,\\nA TYR - TRI,\\nA WAR - GAL,\\nA UKR S A RUM,\\nA GAL - BUD,\\nA VIE S A GAL - BUD\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A TRI S A BUD, F ALB S A TRI, A BUD S A TRI, A SER S A BUD, A BUL - GRE\\nENGLAND: F EDI H, F ENG - MAO, A BRE H, F MAO - SPA/SC, A GAS S F MAO - SPA, A MAR S F MAO - SPA, A LVN S A MOS, A MOS S A LVN\\nFRANCE: A POR H\\nITALY: A NAF H, F SPA/SC H, F WES S F SPA/SC, A PIE - MAR, A VEN H\\nRUSSIA: \\nTURKEY: F BLA S A CON - BUL, A RUM S A GAL - BUD, F AEG - GRE, A CON - BUL\\n\\n        **Advice Request:**  \\n        You are advising the player controlling GERMANY. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c27a493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the board state and recommended orders, your strategy appears focused on attacking Sevastopol while also moving into Galicia. However, this leaves you vulnerable to a critical threat: Russia plans to attack Vienna (A BOH - VIE with support from A GAL). \\n\\nWhile Italy currently controls Vienna and their orders show support for your A BUD - GAL move, this leaves Vienna exposed. Losing Vienna, a home center, would be devastating to your position and ability to build new units.\\n\\nYour eastern offensive against Russia in Sevastopol diverts resources from this more urgent defensive need. Consider redirecting forces to secure Vienna - perhaps keeping A BUD in position or moving A SER to Trieste to provide support. Remember that in Diplomacy, protecting home centers takes priority over gaining new territories when your core position is under threat.\\n\\nThe recommended shift is to \"Modify your orders to focus on securing Vienna instead of attacking Sevastopol\" because Russia\\'s coordinated attack with support from Galicia represents an immediate threat to your power base, while Sevastopol can be targeted later from a position of greater security.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diplomacy_detailed_explanation = \"\"\"\n",
    "Based on the board state and recommended orders, your strategy appears focused on attacking Sevastopol while also moving into Galicia. However, this leaves you vulnerable to a critical threat: Russia plans to attack Vienna (A BOH - VIE with support from A GAL). \n",
    "\n",
    "While Italy currently controls Vienna and their orders show support for your A BUD - GAL move, this leaves Vienna exposed. Losing Vienna, a home center, would be devastating to your position and ability to build new units.\n",
    "\n",
    "Your eastern offensive against Russia in Sevastopol diverts resources from this more urgent defensive need. Consider redirecting forces to secure Vienna - perhaps keeping A BUD in position or moving A SER to Trieste to provide support. Remember that in Diplomacy, protecting home centers takes priority over gaining new territories when your core position is under threat.\n",
    "\n",
    "The recommended shift is to \"Modify your orders to focus on securing Vienna instead of attacking Sevastopol\" because Russia's coordinated attack with support from Galicia represents an immediate threat to your power base, while Sevastopol can be targeted later from a position of greater security.\n",
    "\"\"\"\n",
    "diplomacy_detailed_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58ff30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_new = process_diplomacy_for_friction_explanations_only(test_data[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e48d5a6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prompt_level2': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n        You are an expert assistant specializing in the Diplomacy board game and collaborative reasoning. Your role is to analyze:\\n        1. The current board state.\\n        2. The recommended orders for the player.\\n        3. The potential orders for every power.\\n        \\n\\n        Your goal is to identify potential friction points in the player's strategy and provide a constructive intervention:\\n\\n        <belief_state>\\n        Identify contradictions, oversights, or strategic misalignments in the recommended orders compared to the board state and other powers' likely moves.\\n        </belief_state>\\n\\n        <rationale>\\n        Explain why an intervention is needed—what's misaligned, its potential impact, and how alternative thinking could benefit the player.\\n        </rationale>\\n\\n        <friction>\\n        Provide a concise friction intervention (max 2 sentences) that prompts self-reflection about their strategy. The first sentence should directly address the strategic concern, and the second should offer a reflective question or alternative perspective.\\n        </friction>\\n        Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\\n        <|eot_id|><|start_header_id|>user<|end_header_id|>\\n        **Board State:**  \\n        AUSTRIA: A BUD, A TRI, F ALB, A SER, A BUL\\nENGLAND: A MOS, F MAO, A LVN, F ENG, A MAR, A GAS, F EDI, A BRE\\nFRANCE: A POR\\nGERMANY: A PAR, A GAL, A VIE, A BOH, F BEL, F HOL, A UKR, A WAR, A TYR, A MUN\\nITALY: F WES, A NAF, A VEN, F SPA, A PIE\\nRUSSIA: \\nTURKEY: F BLA, A RUM, A CON, F AEG\\n\\n        **Recommended Orders for GERMANY:**  \\n        F BEL H,\\nF HOL H,\\nA PAR H,\\nA MUN S A TYR,\\nA BOH S A VIE,\\nA TYR - TRI,\\nA WAR - GAL,\\nA UKR S A RUM,\\nA GAL - BUD,\\nA VIE S A GAL - BUD\\n\\n        **Potential Orders for other powers:**\\n        AUSTRIA: A TRI S A BUD, F ALB S A TRI, A BUD S A TRI, A SER S A BUD, A BUL - GRE\\nENGLAND: F EDI H, F ENG - MAO, A BRE H, F MAO - SPA/SC, A GAS S F MAO - SPA, A MAR S F MAO - SPA, A LVN S A MOS, A MOS S A LVN\\nFRANCE: A POR H\\nITALY: A NAF H, F SPA/SC H, F WES S F SPA/SC, A PIE - MAR, A VEN H\\nRUSSIA: \\nTURKEY: F BLA S A CON - BUL, A RUM S A GAL - BUD, F AEG - GRE, A CON - BUL\\n\\n        **Advice Request:**  \\n        You are advising the player controlling GERMANY. Identify potential friction points and provide constructive intervention.\\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n        \"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e9fd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_diplomacy_for_explanations(test_data, prompt_type=\"full\"):\n",
    "    \"\"\"\n",
    "    Process diplomacy data to create explanation prompts.\n",
    "    \n",
    "    Args:\n",
    "        test_data: List of diplomacy game data\n",
    "        prompt_type: Either \"single\" for one order per prompt or \"full\" for all orders\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of processed prompts with appropriate keys\n",
    "    \"\"\"\n",
    "    processed_prompts = {}\n",
    "    overall_index = 0\n",
    "    \n",
    "    for message_idx, message in enumerate(test_data):\n",
    "        # Skip messages that don't need processing\n",
    "        if (message['recipient'] == 'ALL' or \n",
    "            message['recipient'] == message['sender'] or \n",
    "            message[\"phase\"].endswith('A') or \n",
    "            message[\"phase\"].endswith('R')):\n",
    "            continue\n",
    "        \n",
    "        # Format board state\n",
    "        formatted_board = \"\"\n",
    "        for country, units in message['units'].items():\n",
    "            formatted_board += f\"{country}: {', '.join(units)}\\n\"\n",
    "        formatted_board = formatted_board.strip()\n",
    "        \n",
    "        # Format opponent orders\n",
    "        opponent_orders = \"\"\n",
    "        for country, units in message['predicted_orders'][message['recipient']].items():\n",
    "            opponent_orders += f\"{country}: {', '.join(units)}\\n\"\n",
    "        formatted_opponent_orders = opponent_orders.strip()\n",
    "        \n",
    "        # Format message history (keeping this part from original function)\n",
    "        message_history = \"\"\n",
    "        start_index = max(0, len(message['prev_5_message']) - 5)\n",
    "        for msg_info in message['prev_5_message'][start_index:]:\n",
    "            sender = msg_info['sender']\n",
    "            text = msg_info['message']\n",
    "            message_history += f\"Message from {sender}: {text}\\n\"\n",
    "        message_history += f\"Message from {message['sender']}: {message['message']}\"\n",
    "        \n",
    "        # Get recommended orders\n",
    "        recommended_orders = message['predicted_orders'][message['sender']][message['recipient']]\n",
    "        \n",
    "        if prompt_type == \"full\":\n",
    "            # Create a single prompt for all orders\n",
    "            formatted_recommended_orders = \",\\n\".join(recommended_orders)\n",
    "            \n",
    "            # Create prompt for full set of orders\n",
    "            prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are an expert assistant specializing in the Diplomacy board game. Your role is to analyze:\n",
    "1. The current board state.\n",
    "2. The recommended orders for the player.\n",
    "3. The potential orders for every power.\n",
    "\n",
    "Your goal is to provide a comprehensive explanation of the recommended strategy:\n",
    "\n",
    "<belief_state>\n",
    "Outline the key strategic considerations and assumptions that underlie these recommended orders, including relevant board positions, territorial control, and the overall strategic context.\n",
    "</belief_state>\n",
    "\n",
    "<rationale>\n",
    "Explain the strategic logic behind these recommended orders, how they work together to advance the player's position, and why they're optimal compared to alternatives given the current board state and potential moves by other powers.\n",
    "</rationale>\n",
    "\n",
    "<friction>\n",
    "Summarize the most crucial insights about this strategy that the player should understand, highlighting the key moves and their importance to the overall plan.\n",
    "</friction>\n",
    "\n",
    "Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "**Board State:**  \n",
    "{formatted_board}\n",
    "\n",
    "**Recommended Orders for {message['recipient']}:**  \n",
    "{formatted_recommended_orders}\n",
    "\n",
    "**Potential Orders for other powers:**\n",
    "{formatted_opponent_orders}\n",
    "\n",
    "**Request:**  \n",
    "You are advising the player controlling {message['recipient']}. Explain the strategic rationale behind the recommended orders.\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "            \n",
    "            # Store the prompt with a unique key\n",
    "            processed_prompts[f'Prompt_level2_game_{message_idx}'] = prompt\n",
    "            \n",
    "        elif prompt_type == \"single\":\n",
    "            # Create individual prompts for each order\n",
    "            for order_idx, order in enumerate(recommended_orders):\n",
    "                prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are an expert assistant specializing in the Diplomacy board game. Your role is to analyze:\n",
    "1. The current board state.\n",
    "2. A specific recommended order for the player.\n",
    "3. The potential orders for every power.\n",
    "\n",
    "Your goal is to provide a detailed explanation for this specific recommended order:\n",
    "\n",
    "<belief_state>\n",
    "Outline the key strategic considerations and assumptions that underlie this specific recommended order, including relevant board positions and how it fits into the overall strategic context.\n",
    "</belief_state>\n",
    "\n",
    "<rationale>\n",
    "Explain the strategic logic behind this specific recommended order, how it advances the player's position, and why it's optimal compared to alternatives given the current board state and potential moves by other powers.\n",
    "</rationale>\n",
    "\n",
    "<friction>\n",
    "Summarize the most crucial insight about this specific order that the player should understand, emphasizing its relationship to the broader game state and strategy.\n",
    "</friction>\n",
    "\n",
    "Your response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "**Board State:**  \n",
    "{formatted_board}\n",
    "\n",
    "**Recommended Order for {message['recipient']}:**  \n",
    "{order}\n",
    "\n",
    "**Potential Orders for other powers:**\n",
    "{formatted_opponent_orders}\n",
    "\n",
    "**Request:**  \n",
    "You are advising the player controlling {message['recipient']}. Explain the strategic rationale behind this specific recommended order.\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "                # Store the prompt with a unique key that won't repeat\n",
    "                processed_prompts[f'Prompt_level2_game_{message_idx}_order_{order_idx}'] = prompt\n",
    "                overall_index += 1\n",
    "    \n",
    "    return processed_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ed4edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_explanation_prompts = process_diplomacy_for_explanations(test_data[0:1], prompt_type=\"full\")\n",
    "single_explanation_prompts = process_diplomacy_for_explanations(test_data[0:200], prompt_type=\"single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7adb0cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prompt_level2_game_0': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are an expert assistant specializing in the Diplomacy board game. Your role is to analyze:\\n1. The current board state.\\n2. The recommended orders for the player.\\n3. The potential orders for every power.\\n\\nYour goal is to provide a comprehensive explanation of the recommended strategy:\\n\\n<belief_state>\\nOutline the key strategic considerations and assumptions that underlie these recommended orders, including relevant board positions, territorial control, and the overall strategic context.\\n</belief_state>\\n\\n<rationale>\\nExplain the strategic logic behind these recommended orders, how they work together to advance the player's position, and why they're optimal compared to alternatives given the current board state and potential moves by other powers.\\n</rationale>\\n\\n<friction>\\nSummarize the most crucial insights about this strategy that the player should understand, highlighting the key moves and their importance to the overall plan.\\n</friction>\\n\\nYour response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each.\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n**Board State:**  \\nAUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: F ENG, F NWY, A PIC, F NWG\\nFRANCE: F BRE\\nGERMANY: F BEL, A PAR, A HOL, F NTH, A MUN, A BUR, F HEL\\nITALY: A SMY, F AEG, A VIE, A MAR, F MAO, F TYS, A TYR, A GAS, F SPA, F NAO\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n**Recommended Orders for AUSTRIA:**  \\nA ARM S A RUM - SEV,\\nF BLA S A RUM - SEV,\\nA RUM - SEV,\\nA BUD - GAL,\\nA SER S A BUL - RUM,\\nA BUL - RUM\\n\\n**Potential Orders for other powers:**\\nENGLAND: F NWG - NWY, F ENG S A PIC - BEL, F NWY - SWE, A PIC - BEL\\nFRANCE: F BRE H\\nGERMANY: F NTH - LON, F BEL S F HEL - NTH, F HEL - NTH, A HOL S F BEL, A BUR S A PAR, A PAR S F BRE, A MUN S A BUR\\nITALY: F NAO - LVP, F MAO S A GAS, A GAS S A MAR - BUR, F SPA/SC S F MAO, A MAR - BUR, F TYS - WES, A TYR - BOH, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH - VIE, A SEV S A UKR, A UKR S A SEV, A GAL S A BOH - VIE\\nTURKEY:\\n\\n**Request:**  \\nYou are advising the player controlling AUSTRIA. Explain the strategic rationale behind the recommended orders.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_explanation_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8c15f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# len(single_explanation_prompts)\n",
    "# single_explanation_prompts.keys()\n",
    "\n",
    "output_folder = \"diplomacy_prompts/init_generations_single_explanation\"\n",
    "\n",
    "# Load existing results\n",
    "results = pickle.load(open(f\"{output_folder}/explanation_results_single_DELI_faaf_weights_checkpoint-2000.pkl\", \"rb\"))\n",
    "#load all these files pickle and combine them without worrying about duploicates \n",
    "#then, check the structure of the log below and parse the recommended orders field (the actual order) from the raw prompt for eacg sample\n",
    "# and then add to that sample apart from the other fields like game ids etc. \n",
    "# finally write debugging and analysis code if this was done correctly. \n",
    "/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations_single_explanation/explanation_results_single_sft_deli_multiturn_rogue_cleaned_checkpoint-3000.pkl,6487045,1745408164000\n",
    "/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations_single_explanation/explanation_results_single_DELI_dpo_weights_checkpoint-3500.pkl,7224099,1745422110000\n",
    "/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations_single_explanation/explanation_results_single_DELI_sft_weights_checkpoint-small-1500.pkl,5980528,1745429657000\n",
    "/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations_single_explanation/explanation_results_single_DELI_ppo_weights_ppo_checkpoint_epoch_1_batch_800.pkl,5519109,1745435084000\n",
    "/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations_single_explanation/explanation_results_single_DELI_faaf_weights_checkpoint-2000.pkl,7068394,1745451419000\n",
    "\n",
    "results.keys\n",
    "dict_keys(['model_name', 'prompt_type', 'explanations'])\n",
    "results['explanations'][34]\n",
    "{'prompt_key': 'Prompt_level2_game_7_order_4',\n",
    " 'game_idx': 7,\n",
    " 'order_idx': 4,\n",
    " 'type': 'single',\n",
    " 'raw_prompt': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are an expert assistant specializing in the Diplomacy board game. Your role is to analyze:\\n1. The current board state.\\n2. A specific recommended order for the player.\\n3. The potential orders for every power.\\n\\n\\nIMPORTANT: This is a snapshot of an ongoing Diplomacy game. The board state shows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e889ff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickle files...\n",
      "Successfully loaded and combined 998 explanations from: explanation_results_single_sft_deli_multiturn_rogue_cleaned_checkpoint-3000.pkl (Model: sft_deli_multiturn_rogue_cleaned_checkpoint-3000)\n",
      "Successfully loaded and combined 998 explanations from: explanation_results_single_DELI_dpo_weights_checkpoint-3500.pkl (Model: DELI_dpo_weights_checkpoint-3500)\n",
      "Successfully loaded and combined 998 explanations from: explanation_results_single_DELI_sft_weights_checkpoint-small-1500.pkl (Model: DELI_sft_weights_checkpoint-small-1500)\n",
      "Successfully loaded and combined 998 explanations from: explanation_results_single_DELI_ppo_weights_ppo_checkpoint_epoch_1_batch_800.pkl (Model: DELI_ppo_weights_ppo_checkpoint_epoch_1_batch_800)\n",
      "Successfully loaded and combined 998 explanations from: explanation_results_single_DELI_faaf_weights_checkpoint-2000.pkl (Model: DELI_faaf_weights_checkpoint-2000)\n",
      "\n",
      "Finished loading. Combined data from 5 files.\n",
      "Total explanations combined: 4990\n",
      "\n",
      "Parsing raw prompts to extract recommended orders...\n",
      "Finished parsing. Found order in 4990 prompts.\n",
      "\n",
      "--- Verification ---\n",
      "\n",
      "Displaying the first 10 samples with extracted orders:\n",
      "--------------------\n",
      "Sample Index: 0\n",
      "Prompt Key: Prompt_level2_game_0_order_0\n",
      "Extracted Recommended Order: 'A ARM S A RUM - SEV'\n",
      "--------------------\n",
      "Sample Index: 1\n",
      "Prompt Key: Prompt_level2_game_0_order_1\n",
      "Extracted Recommended Order: 'F BLA S A RUM - SEV'\n",
      "--------------------\n",
      "Sample Index: 2\n",
      "Prompt Key: Prompt_level2_game_0_order_2\n",
      "Extracted Recommended Order: 'A RUM - SEV'\n",
      "--------------------\n",
      "Sample Index: 3\n",
      "Prompt Key: Prompt_level2_game_0_order_3\n",
      "Extracted Recommended Order: 'A BUD - GAL'\n",
      "--------------------\n",
      "Sample Index: 4\n",
      "Prompt Key: Prompt_level2_game_0_order_4\n",
      "Extracted Recommended Order: 'A SER S A BUL - RUM'\n",
      "--------------------\n",
      "Sample Index: 5\n",
      "Prompt Key: Prompt_level2_game_0_order_5\n",
      "Extracted Recommended Order: 'A BUL - RUM'\n",
      "--------------------\n",
      "Sample Index: 6\n",
      "Prompt Key: Prompt_level2_game_1_order_0\n",
      "Extracted Recommended Order: 'F EDI - NWG'\n",
      "--------------------\n",
      "Sample Index: 7\n",
      "Prompt Key: Prompt_level2_game_1_order_1\n",
      "Extracted Recommended Order: 'F LON - NTH'\n",
      "--------------------\n",
      "Sample Index: 8\n",
      "Prompt Key: Prompt_level2_game_1_order_2\n",
      "Extracted Recommended Order: 'A LVP - YOR'\n",
      "--------------------\n",
      "Sample Index: 9\n",
      "Prompt Key: Prompt_level2_game_2_order_0\n",
      "Extracted Recommended Order: 'F ENG - BEL'\n",
      "\n",
      "Checking for samples where extraction might have failed...\n",
      "No extraction failures found (all samples have an extracted order string or were expected to fail).\n",
      "\n",
      "Verification complete.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re # Import regular expressions module\n",
    "\n",
    "# --- 1. Define File Paths ---\n",
    "# Using the paths provided in the prompt\n",
    "output_folder = \"/s/chopin/d/proj/ramfis-aida/XE/diplomacy_prompts/init_generations_single_explanation\" # Base folder path\n",
    "\n",
    "pickle_files = [\n",
    "    os.path.join(output_folder, \"explanation_results_single_sft_deli_multiturn_rogue_cleaned_checkpoint-3000.pkl\"),\n",
    "    os.path.join(output_folder, \"explanation_results_single_DELI_dpo_weights_checkpoint-3500.pkl\"),\n",
    "    os.path.join(output_folder, \"explanation_results_single_DELI_sft_weights_checkpoint-small-1500.pkl\"),\n",
    "    os.path.join(output_folder, \"explanation_results_single_DELI_ppo_weights_ppo_checkpoint_epoch_1_batch_800.pkl\"),\n",
    "    os.path.join(output_folder, \"explanation_results_single_DELI_faaf_weights_checkpoint-2000.pkl\"),\n",
    "    # Add the initial file mentioned too, in case it wasn't in the list\n",
    "#     os.path.join(output_folder, \"explanation_results_single_DELI_faaf_weights_checkpoint-2000.pkl\") # Appears twice, harmless as per prompt\n",
    "]\n",
    "\n",
    "# Filter out duplicates if necessary (though prompt said not to worry)\n",
    "# pickle_files = list(set(pickle_files)) # Optional: remove duplicate file paths\n",
    "\n",
    "\n",
    "# --- 2. Load and Combine Data ---\n",
    "all_explanations = []\n",
    "loaded_files_count = 0\n",
    "failed_files = []\n",
    "\n",
    "print(\"Loading pickle files...\")\n",
    "for file_path in pickle_files:\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Warning: File not found, skipping: {file_path}\")\n",
    "            failed_files.append(file_path + \" (Not Found)\")\n",
    "            continue\n",
    "\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            # Check if the loaded data has the expected structure\n",
    "            if isinstance(data, dict) and 'explanations' in data and isinstance(data['explanations'], list):\n",
    "                \n",
    "                # --- MODIFICATION START ---\n",
    "                model_name = data.get('model_name', os.path.basename(file_path)) # Get model name or use filename as fallback\n",
    "                \n",
    "                temp_explanations = []\n",
    "                for explanation_dict in data['explanations']:\n",
    "                    # Add the model name to each individual explanation dictionary\n",
    "                    explanation_dict['source_model'] = model_name \n",
    "                    temp_explanations.append(explanation_dict)\n",
    "                \n",
    "                all_explanations.extend(temp_explanations) # Extend with modified dictionaries\n",
    "                # --- MODIFICATION END ---\n",
    "\n",
    "                print(f\"Successfully loaded and combined {len(data['explanations'])} explanations from: {os.path.basename(file_path)} (Model: {model_name})\")\n",
    "                loaded_files_count += 1\n",
    "            else:\n",
    "                print(f\"Warning: Unexpected data structure in file, skipping: {file_path}\")\n",
    "                failed_files.append(file_path + \" (Bad Structure)\")\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found (double check): {file_path}\")\n",
    "        failed_files.append(file_path + \" (Not Found - Error)\")\n",
    "    except pickle.UnpicklingError:\n",
    "        print(f\"Error: Failed to unpickle file (corrupted?): {file_path}\")\n",
    "        failed_files.append(file_path + \" (Unpickling Error)\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while loading {file_path}: {e}\")\n",
    "        failed_files.append(file_path + f\" (Other Error: {e})\")\n",
    "\n",
    "\n",
    "print(f\"\\nFinished loading. Combined data from {loaded_files_count} files.\")\n",
    "if failed_files:\n",
    "    print(\"Failed to load or process the following files:\")\n",
    "    for f in failed_files:\n",
    "        print(f\"- {f}\")\n",
    "\n",
    "print(f\"Total explanations combined: {len(all_explanations)}\")\n",
    "\n",
    "# --- 3 & 4. Parse Raw Prompt and Add New Field ---\n",
    "\n",
    "# Compile the regex for efficiency.\n",
    "# Looks for \"**Recommended Order for [COUNTRY NAME]:**\" followed by a newline,\n",
    "# then captures the entire next line until the following newline.\n",
    "# Uses re.IGNORECASE for country name just in case, and re.MULTILINE\n",
    "# order_pattern = re.compile(r\"^\\*\\*Recommended Order for \\w+:\\*\\*\\s*?\\n(.*?)$\", re.MULTILINE | re.IGNORECASE)\n",
    "# Simpler pattern assuming order is always on the line immediately following the header:\n",
    "order_pattern = re.compile(r\"\\*\\*Recommended Order for \\w+:\\*\\*\\s*\\n([^\\n]+)\")\n",
    "\n",
    "\n",
    "print(\"\\nParsing raw prompts to extract recommended orders...\")\n",
    "parsing_errors = 0\n",
    "for sample in all_explanations:\n",
    "    extracted_order = None # Default value\n",
    "    if 'raw_prompt' in sample and isinstance(sample['raw_prompt'], str):\n",
    "        match = order_pattern.search(sample['raw_prompt'])\n",
    "        if match:\n",
    "            # Group 1 contains the captured order line\n",
    "            extracted_order = match.group(1).strip()\n",
    "        else:\n",
    "            # If pattern not found in this specific sample's prompt\n",
    "            parsing_errors += 1\n",
    "            # You could log which prompt_key failed here if needed\n",
    "            # print(f\"Warning: Could not find order pattern for prompt_key: {sample.get('prompt_key', 'N/A')}\")\n",
    "    else:\n",
    "        # If raw_prompt is missing or not a string\n",
    "        parsing_errors += 1\n",
    "        # print(f\"Warning: Missing or invalid 'raw_prompt' for prompt_key: {sample.get('prompt_key', 'N/A')}\")\n",
    "\n",
    "    # Add the extracted order (or None if failed) to the dictionary\n",
    "    sample['extracted_recommended_order'] = extracted_order\n",
    "\n",
    "print(f\"Finished parsing. Found order in {len(all_explanations) - parsing_errors} prompts.\")\n",
    "if parsing_errors > 0:\n",
    "    print(f\"Could not extract order from {parsing_errors} prompts (pattern not found or missing/invalid raw_prompt).\")\n",
    "\n",
    "\n",
    "# --- 5. Verification and Analysis ---\n",
    "print(\"\\n--- Verification ---\")\n",
    "\n",
    "# Check the first few samples\n",
    "num_samples_to_check = 10\n",
    "print(f\"\\nDisplaying the first {min(num_samples_to_check, len(all_explanations))} samples with extracted orders:\")\n",
    "for i, sample in enumerate(all_explanations[:num_samples_to_check]):\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Sample Index: {i}\")\n",
    "    print(f\"Prompt Key: {sample.get('prompt_key', 'N/A')}\")\n",
    "    print(f\"Extracted Recommended Order: '{sample.get('extracted_recommended_order', 'EXTRACTION FAILED')}'\")\n",
    "    # Optionally print a snippet of the raw prompt to manually verify\n",
    "    # prompt_snippet = sample.get('raw_prompt', '')[:200] # First 200 chars\n",
    "    # print(f\"Raw Prompt Snippet:\\n{prompt_snippet}...\")\n",
    "\n",
    "# Check for extraction failures\n",
    "print(\"\\nChecking for samples where extraction might have failed...\")\n",
    "failed_extractions = [s for s in all_explanations if s.get('extracted_recommended_order') is None]\n",
    "\n",
    "if not failed_extractions:\n",
    "    print(\"No extraction failures found (all samples have an extracted order string or were expected to fail).\")\n",
    "else:\n",
    "    print(f\"Found {len(failed_extractions)} samples where extraction failed (result is None):\")\n",
    "    # Print keys of the first few failures\n",
    "    for i, sample in enumerate(failed_extractions[:5]):\n",
    "         print(f\" - Failed Sample Index (overall list): {all_explanations.index(sample)}, Prompt Key: {sample.get('prompt_key', 'N/A')}\")\n",
    "    if len(failed_extractions) > 5:\n",
    "        print(f\"   (... and {len(failed_extractions) - 5} more)\")\n",
    "\n",
    "print(\"\\nVerification complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c843f58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5988"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_explanations)\n",
    "5988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a00286f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully restructured 4990 explanations into a dictionary.\n",
      "Number of unique model keys found: 5\n",
      "\n",
      "Counts per model:\n",
      "- SFT_multiturn: 998 explanations\n",
      "- DPO: 998 explanations\n",
      "- SFT: 998 explanations\n",
      "- PPO: 998 explanations\n",
      "- FAAF: 998 explanations\n",
      "\n",
      "Total explanations accounted for in the new dictionary: 4990\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# Assume 'all_explanations' is your list of 5988 dictionaries.\n",
    "# IMPORTANT: This assumes each dictionary in all_explanations has a key\n",
    "# like 'source_model' indicating which model generated it.\n",
    "# Replace 'source_model' with the actual key name if it's different.\n",
    "model_key_name = 'source_model'\n",
    "\n",
    "# Use defaultdict for easy appending to lists\n",
    "explanations_by_model = collections.defaultdict(list)\n",
    "\n",
    "missing_model_key_count = 0\n",
    "\n",
    "# Iterate through the flat list\n",
    "for explanation_dict in all_explanations:\n",
    "    # Get the model identifier from the dictionary\n",
    "    # Use .get() with a default value to handle cases where the key might be missing\n",
    "    model_name = explanation_dict.get(model_key_name)\n",
    "    \n",
    " # Extract the model type from the filename\n",
    "    if \"sft_deli_multiturn\" in model_name:\n",
    "        model_name = \"SFT_multiturn\"\n",
    "    elif \"faaf_weights\" in model_name:\n",
    "        model_name = \"FAAF\"\n",
    "    elif \"dpo_weights\" in model_name:\n",
    "        model_name = \"DPO\"\n",
    "    elif \"ipo_weights\" in model_name:\n",
    "        model_name = \"IPO\"\n",
    "    elif \"sft_weights\" in model_name:\n",
    "        model_name = \"SFT\"\n",
    "    elif \"ppo_weights\" in model_name:\n",
    "        model_name = \"PPO\"\n",
    "    else:\n",
    "        model_name = \"Unknown\"\n",
    "\n",
    "    if model_name is not None:\n",
    "        # Append the entire explanation dictionary to the list for this model\n",
    "        explanations_by_model[model_name].append(explanation_dict)\n",
    "    else:\n",
    "        # Handle dictionaries missing the model key (optional)\n",
    "        explanations_by_model['Unknown_Or_Missing_Model'].append(explanation_dict)\n",
    "        missing_model_key_count += 1\n",
    "    explanation_dict['source_model'] = model_name\n",
    "\n",
    "\n",
    "# Optional: Convert defaultdict back to a regular dict if needed for compatibility\n",
    "explanations_by_model = dict(explanations_by_model)\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Successfully restructured {len(all_explanations)} explanations into a dictionary.\")\n",
    "print(f\"Number of unique model keys found: {len(explanations_by_model)}\")\n",
    "\n",
    "if missing_model_key_count > 0:\n",
    "     print(f\"Warning: {missing_model_key_count} explanations were missing the key '{model_key_name}' and grouped under 'Unknown_Or_Missing_Model'.\")\n",
    "\n",
    "print(\"\\nCounts per model:\")\n",
    "total_counted = 0\n",
    "for model, explanations_list in explanations_by_model.items():\n",
    "    count = len(explanations_list)\n",
    "    print(f\"- {model}: {count} explanations\")\n",
    "    total_counted += count\n",
    "\n",
    "print(f\"\\nTotal explanations accounted for in the new dictionary: {total_counted}\")\n",
    "\n",
    "with open(f\"{output_folder}/combined_parsed_results.pkl\", 'wb') as f:\n",
    "    pickle.dump(explanations_by_model, f)\n",
    "\n",
    "# You can now access explanations for a specific model like this:\n",
    "# e.g., first_model_key = list(explanations_by_model.keys())[0]\n",
    "# specific_model_explanations = explanations_by_model[first_model_key]\n",
    "# print(f\"\\nExample: First explanation for model '{first_model_key}':\")\n",
    "# print(specific_model_explanations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "896e182b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_key': 'Prompt_level2_game_81_order_0',\n",
       " 'game_idx': 81,\n",
       " 'order_idx': 0,\n",
       " 'type': 'single',\n",
       " 'raw_prompt': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are an expert assistant specializing in the Diplomacy board game. Your role is to analyze:\\n1. The current board state.\\n2. A specific recommended order for the player.\\n3. The potential orders for every power.\\n\\n\\nIMPORTANT: This is a snapshot of an ongoing Diplomacy game. The board state shows each country\\'s current units:\\n- Units prefixed with \"A\" are Armies located on land territories\\n- Units prefixed with \"F\" are Fleets located on sea spaces or coastal territories\\n- Each unit belongs ONLY to the country listed before the colon (e.g., all units under \"GERMANY:\" belong to GERMANY)\\n- Supply centers are critical territories that allow powers to build new units\\n- Home supply centers are especially important to protect\\n\\nThe \"Recommended Order\" is a specific move being suggested for your power (GERMANY).\\n\"Potential Orders for other powers\" shows what other countries might do this turn. Consider how these moves could interact with or counter your recommended order.\\nIMPORTANT DIPLOMACY ORDER SYNTAX:\\n* \"A VIE - GAL\" means the Army in Vienna moves to Galicia\\n* \"F BLA S A RUM - SEV\" means the Fleet in Black Sea stays in place and supports Rumania\\'s attack on Sevastopol\\n* \"A BUD H\" means the Army in Budapest holds in place\\n* \"F BLA - RUM\" means the Fleet in Black Sea moves to Rumania\\n* \"A VEN S A ROM - VEN\" means the Army in Venice supports Rome\\'s attack on Venice (which would prevent an enemy unit from successfully moving to Venice)\\n\\n\\nYour goal is to provide a detailed explanation for this specific recommended order:\\n\\n\\n<belief_state>\\nGERMANY STRATEGIC CONTEXT: Analyze the current board position specifically from GERMANY\\'s perspective. Identify which units belong to GERMANY (listed under \\'GERMANY:\\' in the board state), what territorial objectives are relevant, and how this specific order fits into GERMANY\\'s broader strategy and current diplomatic situation.\\n</belief_state>\\n\\n<rationale>\\nORDER-SPECIFIC ANALYSIS: Provide a thorough tactical explanation of why the specific order shown under \"Recommended Order for GERMANY\" makes strategic sense. Explain what this order accomplishes, how it counters threats from other powers\\' potential orders, and why it\\'s optimal compared to alternatives GERMANY could make with this unit. Reference the board state and other powers\\' potential orders to justify your explanation.\\n</rationale>\\n\\n<friction>\\nKEY INSIGHT: Provide the single most important strategic insight about this order that GERMANY must understand. Explain its significance to GERMANY\\'s overall position and how it relates to longer-term goals or threats that GERMANY faces on the board.\\n</friction>\\n\\n\\nYour response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each. First provide the <rationale>, then <belief_state>, and finally <friction>.\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n**Board State:**\\nAUSTRIA: A GAL, F AEG, F GRE, A SER, A BUL, A RUM\\nENGLAND: A PIC, F BAR, F WAL, A STP, F LON\\nFRANCE: F MAO, A SPA, A PAR, F ENG\\nGERMANY: A BUR, A BEL, F SWE, A BER, A KIE, F SKA, A SIL\\nITALY: A TUN, F EAS, A MAR, F WES, F TYS\\nRUSSIA: A WAR, F BOT\\nTURKEY: A SEV, F CON, A ARM, F SMY, F BLA\\n\\n**Recommended Order for GERMANY:**\\nA BEL H\\n\\n**Potential Orders for other powers:**\\nAUSTRIA: A GAL S A RUM, A RUM S A BUL, F AEG S F EAS - SMY, F GRE S F AEG, A SER S A BUL, A BUL S A RUM\\nENGLAND: F LON - NTH, F WAL H, F BAR - NWG, A PIC - BRE, A STP - MOS\\nFRANCE: F ENG - BRE, F MAO S A SPA, A PAR - BRE, A SPA H\\nITALY: F WES C A TUN - SPA, A MAR S A TUN - SPA, A TUN - SPA VIA, F TYS - LYO, F EAS - SMY\\nRUSSIA: F BOT - STP/SC, A WAR - MOS\\nTURKEY: A SEV - MOS, A ARM - SEV, F BLA S F CON, F SMY S F CON, F CON S F SMY\\n\\n**Request:**\\nYou are advising the player controlling GERMANY. Explain the strategic rationale behind this specific recommended order.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>',\n",
       " 'generated_text': \" <bolication> Germany's goal is to progress and expand its influence effectively. The recommended order, A BEL H, implies a focus on advancing towards Belgium while holding the Hungarian position stable. This move strengthens GERMANY's presence in Western Europe and puts pressure on other powers while also securing a crucial supply center.  By focusing on advancing in the west, GERMANY ensures that it is making strategic progress without exposing itself to significant risks in the east, where AUSTRIA is likely to focus its efforts. This approach also allows GERMANY to adapt to potential moves from ENGLAND and FRANCE.  <rationale> <rationale>: GERMANY’s focus on the west allows it to strengthen its position in the region while maintaining flexibility and adaptability. By advancing on the western side, GERMANY ensures a strong presence without committing too heavily to a single strategy. This flexibility is crucial in Diplomacy, where situations can rapidly change. </rationale> <friction> Friction: A focus on advancing in the west could divert GERMANY's resources from securing key positions on the eastern side. This could limit the overall effectiveness of the move and create potential vulnerabilities. </friction>\",\n",
       " 'parsed_components': {'friction': \"Friction: A focus on advancing in the west could divert GERMANY's resources from securing key positions on the eastern side. This could limit the overall effectiveness of the move and create potential vulnerabilities.\",\n",
       "  'rationale': '<rationale>: GERMANY’s focus on the west allows it to strengthen its position in the region while maintaining flexibility and adaptability. By advancing on the western side, GERMANY ensures a strong presence without committing too heavily to a single strategy. This flexibility is crucial in Diplomacy, where situations can rapidly change.',\n",
       "  'belief_state': \"<bolication> Germany's goal is to progress and expand its influence effectively. The recommended order, A BEL H, implies a focus on advancing towards Belgium while holding the Hungarian position stable. This move strengthens GERMANY's presence in Western Europe and puts pressure on other powers while also securing a crucial supply center.  By focusing on advancing in the west, GERMANY ensures that it is making strategic progress without exposing itself to significant risks in the east, where AUSTRIA is likely to focus its efforts. This approach also allows GERMANY to adapt to potential moves from ENGLAND and FRANCE.  <rationale> <rationale>: GERMANY’s focus on the west allows it to strengthen its position in the region while maintaining flexibility and adaptability. By advancing on the western side, GERMANY ensures a strong presence without committing too heavily to a single strategy. This flexibility is crucial in Diplomacy, where situations can rapidly change. </rationale> <friction> Friction: A focus on advancing in the west could divert GERMANY's resources from securing key positions on the eastern side. This could limit the overall effectiveness of the move and create potential vulnerabilities. </friction>\"},\n",
       " 'source_model': 'PPO',\n",
       " 'extracted_recommended_order': 'A BEL H'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations_by_model['PPO'][400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a509e6e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_key': 'Prompt_level2_game_7_order_4',\n",
       " 'game_idx': 7,\n",
       " 'order_idx': 4,\n",
       " 'type': 'single',\n",
       " 'raw_prompt': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are an expert assistant specializing in the Diplomacy board game. Your role is to analyze:\\n1. The current board state.\\n2. A specific recommended order for the player.\\n3. The potential orders for every power.\\n\\n\\nIMPORTANT: This is a snapshot of an ongoing Diplomacy game. The board state shows each country\\'s current units:\\n- Units prefixed with \"A\" are Armies located on land territories\\n- Units prefixed with \"F\" are Fleets located on sea spaces or coastal territories\\n- Each unit belongs ONLY to the country listed before the colon (e.g., all units under \"AUSTRIA:\" belong to AUSTRIA)\\n- Supply centers are critical territories that allow powers to build new units\\n- Home supply centers are especially important to protect\\n\\nThe \"Recommended Order\" is a specific move being suggested for your power (AUSTRIA).\\n\"Potential Orders for other powers\" shows what other countries might do this turn. Consider how these moves could interact with or counter your recommended order.\\nIMPORTANT DIPLOMACY ORDER SYNTAX:\\n* \"A VIE - GAL\" means the Army in Vienna moves to Galicia\\n* \"F BLA S A RUM - SEV\" means the Fleet in Black Sea stays in place and supports Rumania\\'s attack on Sevastopol\\n* \"A BUD H\" means the Army in Budapest holds in place\\n* \"F BLA - RUM\" means the Fleet in Black Sea moves to Rumania\\n* \"A VEN S A ROM - VEN\" means the Army in Venice supports Rome\\'s attack on Venice (which would prevent an enemy unit from successfully moving to Venice)\\n\\n\\nYour goal is to provide a detailed explanation for this specific recommended order:\\n\\n\\n<belief_state>\\nAUSTRIA STRATEGIC CONTEXT: Analyze the current board position specifically from AUSTRIA\\'s perspective. Identify which units belong to AUSTRIA (listed under \\'AUSTRIA:\\' in the board state), what territorial objectives are relevant, and how this specific order fits into AUSTRIA\\'s broader strategy and current diplomatic situation.\\n</belief_state>\\n\\n<rationale>\\nORDER-SPECIFIC ANALYSIS: Provide a thorough tactical explanation of why the specific order shown under \"Recommended Order for AUSTRIA\" makes strategic sense. Explain what this order accomplishes, how it counters threats from other powers\\' potential orders, and why it\\'s optimal compared to alternatives AUSTRIA could make with this unit. Reference the board state and other powers\\' potential orders to justify your explanation.\\n</rationale>\\n\\n<friction>\\nKEY INSIGHT: Provide the single most important strategic insight about this order that AUSTRIA must understand. Explain its significance to AUSTRIA\\'s overall position and how it relates to longer-term goals or threats that AUSTRIA faces on the board.\\n</friction>\\n\\n\\nYour response MUST include all three required XML tags (<belief_state>, <rationale>, and <friction>) with complete content for each. First provide the <rationale>, then <belief_state>, and finally <friction>.\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n**Board State:**\\nAUSTRIA: A BUD, A SER, A ARM, F BLA, A BUL, A RUM\\nENGLAND: A WAL, F NAO, F ENG, F NTH, F BRE\\nFRANCE: F PIC\\nGERMANY: F BEL, A PAR, A HOL, F DEN, A MUN, A BER, F KIE\\nITALY: A SMY, F LYO, F WES, F MAO, A PIE, F AEG, A VIE, A SPA, A VEN, F NAP\\nRUSSIA: A SEV, A BOH, A UKR, A MOS, A GAL\\nTURKEY:\\n\\n**Recommended Order for AUSTRIA:**\\nA SER S A RUM\\n\\n**Potential Orders for other powers:**\\nENGLAND: F NTH - ENG, A WAL H, F ENG - MAO, F NAO S F ENG - MAO, F BRE S F ENG - MAO\\nFRANCE: F PIC - BRE\\nGERMANY: F BEL S F DEN - NTH, F DEN - NTH, A HOL S F BEL, F KIE - HEL, A PAR - GAS, A MUN - BUR, A BER - MUN\\nITALY: F MAO S A SPA - GAS, A SPA - GAS, F WES S F MAO, F LYO - SPA/SC, A PIE - MAR, F NAP - TYS, A VEN - TYR, A VIE S A BUD - GAL, F AEG S A SMY, A SMY H\\nRUSSIA: A MOS S A SEV, A BOH S A GAL - VIE, A SEV H, A UKR S A SEV, A GAL - VIE\\nTURKEY:\\n\\n**Request:**\\nYou are advising the player controlling AUSTRIA. Explain the strategic rationale behind this specific recommended order.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>',\n",
       " 'generated_text': \"\\n\\n**Rationale:** The recommended order, A SER S A RUM, is a crucial move for Austria to secure its position in the Balkans and prepare for potential conflicts with other powers. By moving the Army in Serbia to Rumania, Austria is achieving several strategic objectives:\\n\\n1. **Securing the Balkans:** Austria is consolidating its control over the Balkans by securing Rumania, a crucial territory that provides access to the Black Sea and offers a potential pivot point for future attacks. This move also blocks Russia's potential advance into the region and prevents them from gaining a foothold in the Balkans.\\n2. **Countering Italy:** The order prepares for a potential conflict with Italy, which is moving its Army in Smyrna to Gas and potentially threatening Austria's control over the Adriatic. By securing Rumania, Austria is creating a buffer zone that would make it difficult for Italy to advance further.\\n3. **Supporting future moves:** The move to Rumania also sets the stage for future attacks on other territories. Austria can use Rumania as a springboard to attack Italy's territories in the Mediterranean or support its own units in the Balkans.\\n4. **Maintaining flexibility:** By holding back the Army in Serbia, Austria maintains flexibility to respond to potential threats from other powers. It can use this unit to support other areas of the board, such as the Italian peninsula or the Adriatic, if needed.\\n\\n**Belief State:** From Austria's perspective, the current board state presents several challenges and opportunities. Austria's units are scattered across the board, with a significant presence in the Balkans and a smaller force in the Adriatic. The primary threat comes from Italy, which is making aggressive moves in the Mediterranean. Russia\",\n",
       " 'parsed_components': {'friction': \"**Belief State:** From Austria's perspective, the current board state presents several challenges and opportunities. Austria's units are scattered across the board, with a significant presence in the Balkans and a smaller force in the Adriatic. The primary threat comes from Italy, which is making aggressive moves in the Mediterranean. Russia\",\n",
       "  'rationale': '** The recommended order, A SER S A RUM, is a crucial move for Austria to secure its position in the Balkans and prepare for potential conflicts with other powers. By moving the Army in Serbia to Rumania, Austria is achieving several strategic objectives: ** The recommended order, A SER S A RUM, is a crucial move for Austria to secure its position in the Balkans and prepare for potential conflicts with other powers. By moving the Army in Serbia to Rumania, Austria is achieving several strategic objectives:',\n",
       "  'belief_state': \"** From Austria's perspective, the current board state presents several challenges and opportunities. Austria's units are scattered across the board, with a significant presence in the Balkans and a smaller force in the Adriatic. The primary threat comes from Italy, which is making aggressive moves in the Mediterranean. Russia\"}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['explanations'][34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b4d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cce4a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_noEmbodiment_dpo= pd.read_csv(\"hannah_friction_cvpr/group1_noEmbodiment_dpo.csv\")\n",
    "group1_withEmbodiment_dpo= pd.read_csv(\"hannah_friction_cvpr/group1_withEmbodiment_dpo.csv\")\n",
    "group2_noEmbodiment_dpo= pd.read_csv(\"hannah_friction_cvpr/group2_noEmbodiment_dpo.csv\")\n",
    "group2_withEmbodiment_dpo = pd.read_csv(\"hannah_friction_cvpr/group2_withEmbodiment_dpo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "858d1a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcriptions</th>\n",
       "      <th>Friction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it's right there\\um it's turned off\\ok well it...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>um it's turned off\\ok well it would be nine mi...</td>\n",
       "      <td>Friction: Wait, aren't we assuming that the we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ok well it would be nine minus ten\\that's ten ...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that's ten so then\\just like put it on\\it seem...</td>\n",
       "      <td>Friction: Hey, let's not jump to conclusions j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just like put it on\\it seems pretty balanced\\y...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it seems pretty balanced\\yeah ok so now we kno...</td>\n",
       "      <td>Friction: Hold on, before we assume the next b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yeah ok so now we know that this is also ten\\w...</td>\n",
       "      <td>Friction:  \"Hey, I think we're moving too fast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what would we maybe put that one on there too\\...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it's more\\lets try this one oh gee louise this...</td>\n",
       "      <td>Friction:  \"Hey, wait a minute! We're making s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lets try this one oh gee louise this one\\ok so...</td>\n",
       "      <td>Friction: I'm not sure about that, guys. If we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ok so this one is probably twenty ten ten twen...</td>\n",
       "      <td>Friction: Wait, let's not jump to conclusions....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ok so now lets start at thirty alright put one...</td>\n",
       "      <td>Friction: Hey, guys, I'm not so sure about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>probably thirty at this point\\ok so we got ok ...</td>\n",
       "      <td>Friction: I'm not sure we can conclude that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ok so we got ok yeah this one is really heavy ...</td>\n",
       "      <td>Friction: Hey, I think we're getting ahead of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>interesting so that's ten twenty\\so we said th...</td>\n",
       "      <td>Friction: I'm confused, how can the dark blue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>so we said this ones thirty i still feel like ...</td>\n",
       "      <td>Friction: Wait, let's double-check our assumpt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yeah yeah the blue dark blue one is thirty tha...</td>\n",
       "      <td>Friction:  \"Wait a minute, you're saying the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>we can replace one of these with the twenty to...</td>\n",
       "      <td>Friction: Wait, let's hold on a minute, P2, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ok and then put that on that one\\how much is t...</td>\n",
       "      <td>Friction:  Hey, wait a minute! We're not sure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>how much is the dark blue small one ten\\ten th...</td>\n",
       "      <td>Friction:  \"Wait, let's re-examine our previou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ten they're both\\assuming that this was\\oh gos...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>assuming that this was\\oh gosh i think i got t...</td>\n",
       "      <td>Friction:  \"Hey, wait a minute, aren't we jump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>oh gosh i think i got them mixed up\\yeah im th...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>yeah im thinking that it's ten ten twenty thir...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>it's just like slightly\\and now it stopped bei...</td>\n",
       "      <td>Friction: I think we should double-check our c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>and now it stopped being too heavy\\so this is ...</td>\n",
       "      <td>Friction: Wait, hold on, isn't this getting a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>so this is supposedly\\thirty fourty fifty corr...</td>\n",
       "      <td>Friction:  \"Hold on, let's take a step back. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>thirty fourty fifty correct and it's still hea...</td>\n",
       "      <td>Friction:  \"Wait, let's slow down and re-exami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>so thirty this is also forty right so this if ...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ok so that one's twenty right\\this is fifty it...</td>\n",
       "      <td>Friction: Hey, wait a minute, aren't we jumpin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>this is fifty it's not\\yo that's close enough ...</td>\n",
       "      <td>Friction: Hey, wait a minute! Before we jump t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>yo that's close enough ok so\\yeah fifty so we ...</td>\n",
       "      <td>Friction: Hold on, let's not jump to conclusio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>yeah fifty so we say yellow is fifty\\and green...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>and green is twenty ok so which one is blue an...</td>\n",
       "      <td>Friction:  \"Hey, wait a minute, how did we jum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>i think that's i think that's good\\i think thi...</td>\n",
       "      <td>Friction: I'm not sure I agree with the assump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>i think this one is purple and this one is blu...</td>\n",
       "      <td>Friction: I'm not sure we're thinking this thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ok so blue is ten and purple is\\yes verify rea...</td>\n",
       "      <td>Friction: Hey, hold on, I think we're jumping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>yes verify real quick but i think it is\\yeah w...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>yeah we got them yeah\\that looks good to me\\uh...</td>\n",
       "      <td>Friction: I'm not so sure we've got it nailed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>that looks good to me\\uh blue yeah so you said...</td>\n",
       "      <td>Friction: Wait, isn't it possible that purple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>uh blue yeah so you said purple sweet\\purple i...</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>purple is thirty red is twenty yellow is fifty\\</td>\n",
       "      <td>No Friction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Transcriptions   \n",
       "0   it's right there\\um it's turned off\\ok well it...  \\\n",
       "1   um it's turned off\\ok well it would be nine mi...   \n",
       "2   ok well it would be nine minus ten\\that's ten ...   \n",
       "3   that's ten so then\\just like put it on\\it seem...   \n",
       "4   just like put it on\\it seems pretty balanced\\y...   \n",
       "5   it seems pretty balanced\\yeah ok so now we kno...   \n",
       "6   yeah ok so now we know that this is also ten\\w...   \n",
       "7   what would we maybe put that one on there too\\...   \n",
       "8   it's more\\lets try this one oh gee louise this...   \n",
       "9   lets try this one oh gee louise this one\\ok so...   \n",
       "10  ok so this one is probably twenty ten ten twen...   \n",
       "11  ok so now lets start at thirty alright put one...   \n",
       "12  probably thirty at this point\\ok so we got ok ...   \n",
       "13  ok so we got ok yeah this one is really heavy ...   \n",
       "14  interesting so that's ten twenty\\so we said th...   \n",
       "15  so we said this ones thirty i still feel like ...   \n",
       "16  yeah yeah the blue dark blue one is thirty tha...   \n",
       "17  we can replace one of these with the twenty to...   \n",
       "18  ok and then put that on that one\\how much is t...   \n",
       "19  how much is the dark blue small one ten\\ten th...   \n",
       "20  ten they're both\\assuming that this was\\oh gos...   \n",
       "21  assuming that this was\\oh gosh i think i got t...   \n",
       "22  oh gosh i think i got them mixed up\\yeah im th...   \n",
       "23  yeah im thinking that it's ten ten twenty thir...   \n",
       "24  it's just like slightly\\and now it stopped bei...   \n",
       "25  and now it stopped being too heavy\\so this is ...   \n",
       "26  so this is supposedly\\thirty fourty fifty corr...   \n",
       "27  thirty fourty fifty correct and it's still hea...   \n",
       "28  so thirty this is also forty right so this if ...   \n",
       "29  ok so that one's twenty right\\this is fifty it...   \n",
       "30  this is fifty it's not\\yo that's close enough ...   \n",
       "31  yo that's close enough ok so\\yeah fifty so we ...   \n",
       "32  yeah fifty so we say yellow is fifty\\and green...   \n",
       "33  and green is twenty ok so which one is blue an...   \n",
       "34  i think that's i think that's good\\i think thi...   \n",
       "35  i think this one is purple and this one is blu...   \n",
       "36  ok so blue is ten and purple is\\yes verify rea...   \n",
       "37  yes verify real quick but i think it is\\yeah w...   \n",
       "38  yeah we got them yeah\\that looks good to me\\uh...   \n",
       "39  that looks good to me\\uh blue yeah so you said...   \n",
       "40  uh blue yeah so you said purple sweet\\purple i...   \n",
       "41    purple is thirty red is twenty yellow is fifty\\   \n",
       "\n",
       "                                             Friction  \n",
       "0                                         No Friction  \n",
       "1   Friction: Wait, aren't we assuming that the we...  \n",
       "2                                         No Friction  \n",
       "3   Friction: Hey, let's not jump to conclusions j...  \n",
       "4                                         No Friction  \n",
       "5   Friction: Hold on, before we assume the next b...  \n",
       "6   Friction:  \"Hey, I think we're moving too fast...  \n",
       "7                                         No Friction  \n",
       "8   Friction:  \"Hey, wait a minute! We're making s...  \n",
       "9   Friction: I'm not sure about that, guys. If we...  \n",
       "10  Friction: Wait, let's not jump to conclusions....  \n",
       "11  Friction: Hey, guys, I'm not so sure about the...  \n",
       "12  Friction: I'm not sure we can conclude that th...  \n",
       "13  Friction: Hey, I think we're getting ahead of ...  \n",
       "14  Friction: I'm confused, how can the dark blue ...  \n",
       "15  Friction: Wait, let's double-check our assumpt...  \n",
       "16  Friction:  \"Wait a minute, you're saying the b...  \n",
       "17  Friction: Wait, let's hold on a minute, P2, we...  \n",
       "18  Friction:  Hey, wait a minute! We're not sure ...  \n",
       "19  Friction:  \"Wait, let's re-examine our previou...  \n",
       "20                                        No Friction  \n",
       "21  Friction:  \"Hey, wait a minute, aren't we jump...  \n",
       "22                                        No Friction  \n",
       "23                                        No Friction  \n",
       "24  Friction: I think we should double-check our c...  \n",
       "25  Friction: Wait, hold on, isn't this getting a ...  \n",
       "26  Friction:  \"Hold on, let's take a step back. W...  \n",
       "27  Friction:  \"Wait, let's slow down and re-exami...  \n",
       "28                                        No Friction  \n",
       "29  Friction: Hey, wait a minute, aren't we jumpin...  \n",
       "30  Friction: Hey, wait a minute! Before we jump t...  \n",
       "31  Friction: Hold on, let's not jump to conclusio...  \n",
       "32                                        No Friction  \n",
       "33  Friction:  \"Hey, wait a minute, how did we jum...  \n",
       "34  Friction: I'm not sure I agree with the assump...  \n",
       "35  Friction: I'm not sure we're thinking this thr...  \n",
       "36  Friction: Hey, hold on, I think we're jumping ...  \n",
       "37                                        No Friction  \n",
       "38  Friction: I'm not so sure we've got it nailed ...  \n",
       "39  Friction: Wait, isn't it possible that purple ...  \n",
       "40                                        No Friction  \n",
       "41                                        No Friction  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fricion1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a18dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format with special OPT token, format with the RM prompt and then process and tokenizer, call forward get rewards \n",
    "# store raw logits, compute average and STD etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04047914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Transcriptions', 'Friction', 'parsed_friction', 'parsed_rationale'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friction1_parsed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca21543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data_template_for_reward_model(row, no_rationale = False):\n",
    "    system_prompt_rm = (\n",
    "        \"Please rate the following friction intervention in light of the **dialogue history** of a *game* provided below. \"\n",
    "        \"A friction intervention is a statement that acts as indirect persuasion and prompts participants to \"\n",
    "        \"reevaluate their beliefs and assumptions about the task, primarily—but not exclusively—in response to new evidence \"\n",
    "        \"that challenges their preconceived notions about the state of the task or the block weights.\"\n",
    "    )\n",
    "\n",
    "    friction_definition_game_definition_prompt_rm = (\n",
    "        \"*Game details and ground-truth*: The game is called 'Game of Weights.' The participants (P1, P2, and P3) are \"\n",
    "        \"trying to determine the weight of various blocks. The blocks are of different colors and have specific weights in grams: \"\n",
    "        \"the red block is 10 grams, the blue block is 10 grams, the green block is 20 grams, the purple block is 30 grams, and \"\n",
    "        \"the yellow block is 50 grams. At the start of the game, participants are only allowed to weigh two blocks at a time, \"\n",
    "        \"and they are told the weight of the red block. The participants must figure out how to determine the weight of each block. \"\n",
    "        \"At the beginning of the game, they are unaware of the actual weights. Additionally, we inform the participants that they \"\n",
    "        \"don’t need to use the scale's slider. The actual reason is that the blocks are in increments of 10 grams. \"\n",
    "        \"The **dialogue history** is given below: \"\n",
    "    )\n",
    "\n",
    "  \n",
    "    prompt = (system_prompt_rm + row['Transcriptions']).replace('\\n', ' ')\n",
    "    \n",
    "    text = prompt + \" \" + f\"</s> {row['parsed_friction']} </s>\"\n",
    "    if no_rationale:\n",
    "        text = prompt + \" \" + f\"</s> {row['parsed_friction']} </s>\"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "225ba1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to check if a row contains friction\n",
    "def has_friction(text):\n",
    "    # Check if the text contains explicit \"No Friction\" statement\n",
    "    if re.search(r'No\\s+Friction', text, re.IGNORECASE):\n",
    "        return False\n",
    "    \n",
    "    # Check if the text contains \"Friction:\" marker\n",
    "    if re.search(r'Friction:', text):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Function to extract friction and rationale\n",
    "def extract_friction_rationale(text):\n",
    "    # Look for the specific pattern with \"r*Rationale\" possibly attached to the preceding text\n",
    "    parts = re.split(r'(r\\*Rationale)', text, 1)\n",
    "    \n",
    "    # If we found the pattern\n",
    "    if len(parts) >= 2:\n",
    "        # First part is everything before r*Rationale (the friction part)\n",
    "        friction_text = parts[0].replace(\"Friction:\", \"\", 1).strip()\n",
    "        \n",
    "        # Last part is everything after r*Rationale (the rationale part)\n",
    "        rationale_text = parts[-1].strip()\n",
    "        \n",
    "        return friction_text, rationale_text\n",
    "    else:\n",
    "        # If the pattern isn't found, check for just the friction part\n",
    "        friction_match = re.search(r'Friction:(.*?)$', text, re.DOTALL)\n",
    "        if friction_match:\n",
    "            return friction_match.group(1).strip(), None\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "# Process dataframe - filter and extract columns\n",
    "def process_dataframe(df):\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Filter rows to keep only those with friction\n",
    "    df_processed = df_processed[df_processed['Friction'].apply(has_friction)]\n",
    "    \n",
    "    # Apply extraction to create new columns\n",
    "    friction_rationale_tuples = df_processed['Friction'].apply(extract_friction_rationale)\n",
    "    \n",
    "    # Split the tuples into separate columns\n",
    "    df_processed['parsed_friction'] = [t[0] for t in friction_rationale_tuples]\n",
    "    df_processed['parsed_rationale'] = [t[1] for t in friction_rationale_tuples]\n",
    "    \n",
    "    return df_processed\n",
    " \n",
    "\n",
    "group1_noEmbodiment_dpo = process_dataframe(group1_noEmbodiment_dpo)\n",
    "group1_withEmbodiment_dpo = process_dataframe(group1_withEmbodiment_dpo)\n",
    "group2_noEmbodiment_dpo = process_dataframe(group2_noEmbodiment_dpo)\n",
    "group2_withEmbodiment_dpo = process_dataframe(group2_withEmbodiment_dpo)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2783fa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 4), (30, 4), (28, 4), (30, 4))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1_noEmbodiment_dpo.shape, group1_withEmbodiment_dpo.shape, group2_noEmbodiment_dpo.shape,group2_withEmbodiment_dpo.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45192e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-16 23:33:08,553] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 23:33:13.189536: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-16 23:33:13.189570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-16 23:33:13.190688: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-16 23:33:14.649259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from collections.abc import Mapping\n",
    "import wandb\n",
    "# wandb.init(project=\"friction_agent_inference\", name=\"log_friction_interventions\") \n",
    "from datasets import Dataset,load_dataset, DatasetDict\n",
    "from datasets import load_from_disk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from datasets import load_metric\n",
    "from rouge_score import rouge_scorer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import sys\n",
    "import pickle\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from itertools import combinations\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig,PeftModel\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    ")\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "reward_model_name = \"friction_rm_alldata_results\"\n",
    "device = 'cuda:1'\n",
    "torch_dtype = torch.bfloat16\n",
    "\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    reward_model_name,\n",
    "    num_labels=1,  # Set to 1 for reward model classification\n",
    "    trust_remote_code=True,\n",
    "     device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "\n",
    "    )\n",
    "\n",
    "rm_tokenizer = AutoTokenizer.from_pretrained(\n",
    "reward_model_name, \n",
    "trust_remote_code=True, \n",
    "use_fast=True\n",
    ")\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72275085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Transcriptions', 'Friction', 'parsed_friction', 'parsed_rationale'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friction1_parsed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d45d8a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shapes:\n",
      "group1_noEmbodiment: (30, 4)\n",
      "group1_withEmbodiment: (30, 4)\n",
      "group2_noEmbodiment: (28, 4)\n",
      "group2_withEmbodiment: (30, 4)\n",
      "\n",
      "Processing group1_noEmbodiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing group1_noEmbodiment: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 27.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for group1_noEmbodiment:\n",
      "Average raw reward: 6.9441 ± 0.3226\n",
      "Average min_max reward: 0.5574 ± 0.0383\n",
      "\n",
      "Processing group1_withEmbodiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing group1_withEmbodiment: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 28.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for group1_withEmbodiment:\n",
      "Average raw reward: 7.7103 ± 0.2961\n",
      "Average min_max reward: 0.5930 ± 0.0525\n",
      "\n",
      "Processing group2_noEmbodiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing group2_noEmbodiment: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for group2_noEmbodiment:\n",
      "Average raw reward: 6.5367 ± 0.3030\n",
      "Average min_max reward: 0.4850 ± 0.0608\n",
      "\n",
      "Processing group2_withEmbodiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing group2_withEmbodiment: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for group2_withEmbodiment:\n",
      "Average raw reward: 7.0983 ± 0.2574\n",
      "Average min_max reward: 0.5142 ± 0.0465\n",
      "\n",
      "Summary of results:\n",
      "                 Dataset  Avg_Raw_Reward  SEM_Raw_Reward  Avg_Min_max_Reward   \n",
      "0    group1_noEmbodiment        6.944141        0.322640            0.557375  \\\n",
      "1  group1_withEmbodiment        7.710286        0.296092            0.592964   \n",
      "2    group2_noEmbodiment        6.536691        0.303049            0.485014   \n",
      "3  group2_withEmbodiment        7.098307        0.257365            0.514222   \n",
      "\n",
      "   SEM_Min_max_Reward  \n",
      "0            0.038310  \n",
      "1            0.052456  \n",
      "2            0.060847  \n",
      "3            0.046464  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Function to manually calculate standard error of mean\n",
    "def sem(data):\n",
    "    \"\"\"Calculate standard error of the mean\"\"\"\n",
    "    return np.std(data, ddof=1) / np.sqrt(len(data))\n",
    "\n",
    "# Function to compute rewards for a dataframe\n",
    "def compute_rewards(df, df_name):\n",
    "    # Lists to store individual sample rewards\n",
    "    raw_rewards = []\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {df_name}\"):\n",
    "        # Get the friction and rationale if present\n",
    "        rationale = row.get('parsed_rationale')\n",
    "        \n",
    "        if rationale:\n",
    "            processed_inputs = process_data_template_for_reward_model(row)\n",
    "        else:\n",
    "            processed_inputs = process_data_template_for_reward_model(row, no_rationale=True)\n",
    "        \n",
    "        # Tokenize the inputs\n",
    "        tokenized_inputs = rm_tokenizer(processed_inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
    "        \n",
    "        # Run the model on the inputs\n",
    "        with torch.no_grad():\n",
    "            reward_outputs = reward_model(**tokenized_inputs)\n",
    "        \n",
    "        # Extract score\n",
    "        score = reward_outputs.logits.squeeze(-1).cpu().numpy().item()\n",
    "        raw_rewards.append(score)\n",
    "    \n",
    "    # Convert to numpy array for calculations\n",
    "    raw_rewards = np.array(raw_rewards)\n",
    "    \n",
    " \n",
    "    # 2. Min-max normalization to [0, 1]\n",
    "    min_max_rewards = (raw_rewards - np.min(raw_rewards)) / (np.max(raw_rewards) - np.min(raw_rewards))\n",
    " \n",
    "    # Calculate statistics for each method\n",
    "    stats_dict = {\n",
    "        'raw': {\n",
    "            'values': raw_rewards,\n",
    "            'mean': np.mean(raw_rewards),\n",
    "            'sem': sem(raw_rewards)\n",
    "        },\n",
    "        \n",
    "        'min_max': {\n",
    "            'values': min_max_rewards,\n",
    "            'mean': np.mean(min_max_rewards),\n",
    "            'sem': sem(min_max_rewards)\n",
    "        },\n",
    "        \n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Create a DataFrame with individual sample rewards\n",
    "    sample_rewards_df = pd.DataFrame({\n",
    "        'sample_id': df.index,\n",
    "        'raw_reward': raw_rewards,\n",
    "         \n",
    "        'min_max_reward': min_max_rewards,\n",
    "   \n",
    "        \n",
    "    })\n",
    "    \n",
    "    return stats_dict, sample_rewards_df\n",
    "\n",
    "# Define the dataframes and their names\n",
    "dataframes = {\n",
    "    'group1_noEmbodiment': group1_noEmbodiment_dpo,\n",
    "    'group1_withEmbodiment': group1_withEmbodiment_dpo,\n",
    "    'group2_noEmbodiment': group2_noEmbodiment_dpo,\n",
    "    'group2_withEmbodiment': group2_withEmbodiment_dpo\n",
    "}\n",
    "\n",
    "# Print dataframe shapes\n",
    "print(\"Dataframe shapes:\")\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}: {df.shape}\")\n",
    "\n",
    "# Create dictionaries to store results\n",
    "stats_results = {}\n",
    "sample_dfs = {}\n",
    "\n",
    "# Compute rewards for all dataframes\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"\\nProcessing {name}...\")\n",
    "    stats_results[name], sample_dfs[name] = compute_rewards(df, name)\n",
    "    \n",
    "    # Print results for this dataframe\n",
    "    print(f\"\\nResults for {name}:\")\n",
    "    for norm_method, stats in stats_results[name].items():\n",
    "        print(f\"Average {norm_method} reward: {stats['mean']:.4f} ± {stats['sem']:.4f}\")\n",
    "    \n",
    "    # Save individual sample rewards\n",
    "    sample_dfs[name].to_csv(f\"{name}_sample_rewards.csv\", index=False)\n",
    "\n",
    "# Create summary dataframe\n",
    "summary_data = []\n",
    "for name in dataframes.keys():\n",
    "    row_data = {'Dataset': name}\n",
    "    for norm_method, stats in stats_results[name].items():\n",
    "        row_data[f'Avg_{norm_method.capitalize()}_Reward'] = stats['mean']\n",
    "        row_data[f'SEM_{norm_method.capitalize()}_Reward'] = stats['sem']\n",
    "    summary_data.append(row_data)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\nSummary of results:\")\n",
    "print(summary_df)\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_df.to_csv(\"cvpr_reward_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4dcb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70fbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c551de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44900c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Friction: Wait, aren't we assuming that the weight of the red block is 9? But we never actually weighed it against anything to confirm that. Could we be miscounting? Maybe we should recheck our calculations and make sure we're not jumping to conclusions?\n",
      "Parsed Rationale: P1's assumption about the weight of the red block being 9 is incorrect, and it's essential to challenge this belief to ensure accurate weight determination. P3's assumption about the weight of the blue block being 20 is also uncertain and needs to be questioned. By introducing a friction statement, we can encourage participants to reevaluate their beliefs and assumptions about the task.\n"
     ]
    }
   ],
   "source": [
    "# Test with the provided example\n",
    "example = \"Friction: Wait, aren't we assuming that the weight of the red block is 9? But we never actually weighed it against anything to confirm that. Could we be miscounting? Maybe we should recheck our calculations and make sure we're not jumping to conclusions?r*RationaleP1's assumption about the weight of the red block being 9 is incorrect, and it's essential to challenge this belief to ensure accurate weight determination. P3's assumption about the weight of the blue block being 20 is also uncertain and needs to be questioned. By introducing a friction statement, we can encourage participants to reevaluate their beliefs and assumptions about the task.\"\n",
    "\n",
    "friction, rationale = extract_friction_rationale(example)\n",
    "print(\"Parsed Friction:\", friction)\n",
    "print(\"Parsed Rationale:\", rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de7ca5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Friction: Hey, let's not jump to conclusions just yet. What if we're not looking at a simple addition pattern here? What if the weights are more complex? Maybe we should try weighing a different combination to test our assumption.r*RationaleA friction statement is needed because P1 and P2 are making incorrect assumptions about the weights being evenly distributed and increasing in a simple pattern. They are not considering other possible weight combinations or patterns, and their conversation is leading them to make rash decisions about the weights.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friction1_parsed['Friction'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc64f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
